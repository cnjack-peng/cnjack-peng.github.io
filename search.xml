<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CQRS模式]]></title>
    <url>%2F2018%2F01%2F25%2Farch-cqrs%2F</url>
    <content type="text"><![CDATA[介绍CQRS模式之前我们先了解一下传统的系统设计中CRUD存在的问题。 传统模式传统的CRUD方法有一些问题： 使用同一个对象实体来进行数据库读写可能会太粗糙，大多数情况下，比如编辑的时候可能只需要更新个别字段，但是却需要将整个对象都穿进去，有些字段其实是不需要更新的。在查询的时候在表现层可能只需要个别字段，但是需要查询和返回整个实体对象; 使用同一实体对象对同一数据进行读写操作的时候，可能会遇到资源竞争的情况，经常要处理的锁的问题，在写入数据的时候，需要加锁。读取数据的时候需要判断是否允许脏读。这样使得系统的逻辑性和复杂性增加，并且会对系统吞吐量的增长会产生影响; 同步的，直接与数据库进行交互在大数据量同时访问的情况下可能会影响性能和响应性，并且可能会产生性能瓶颈. 由于同一实体对象都会在读写操作中用到，所以对于安全和权限的管理会变得比较复杂. CQRSCQRS最早来自于Betrand Meyer（Eiffel语言之父，开-闭原则OCP提出者）在 Object-Oriented Software Construction 这本书中提到的一种 命令查询分离 (Command Query Separation,CQS) 的概念。其基本思想在于，任何一个对象的方法可以分为两大类： 命令(Command):不返回任何结果(void)，但会改变对象的状态。 查询(Query):返回结果，但是不会改变对象的状态，对系统没有副作用。 根据CQS的思想，任何一个方法都可以拆分为命令和查询两部分。 CQRS模式（Command-Query Responsibility Segregation）是对CQS模式的进一步改进成的一种简单模式 。在讨论CQRS模式的细节之前，我们首先需要理解这个模式产生背后的两股推动力：协同操作和数据过时。 协同操作指的是，在某种场景下多个用户可能会针对同一个数据集进行读写操作，不论主观上这些用户是否真的期望与其他人进行协同。通常情况下会有一些规则来规定哪些用户可以进行哪些操作以及一个操作在何种场景下是允许的而在其他场景中就不被允许。我们会简单的举一些例子来说明。注意：这里的用户可以是自然人，也可以是自动化的软件。 数据过时指的是，在协同操作的场景下，一个数据被展示给某个用户后，它可能就被其他用户修改了，—刚刚展示的数据就过时了。基本上所有使用了缓存的系统都遇到了数据过时的问题。通常情况下用缓存是为了解决系统的性能问题。这说明我们不能完全相信用户做出的决定，因为这些决定可能是基于已经过时的数据做出来的。 标准的分层架构并未对上面的问题提出明确的方案。传统分层架构中，通常通过将所有数据放入统一的数据库中，以此作为一种解决协同操作的思路。但此时为解决性能而引进的缓存，却使数据过时成了个副作用，而且愈演愈烈。 名为AC的盒子指的是自治组件。在讨论命令（Commands）的时候我们会描述它是如何自治的。但在此之前，我们先来看下查询（Queries）。 查询如果我们将要展示给用户的数据是过时的，那么是否真的有必要重新从数据库中去读取一遍？我们仅仅需要数据（没有任何行为约束规则），为什么非要将第三范式的数据转换成领域对象？又为什么要将领域对象转换成DTO来通过网络进行传输？要知道网络并不总是可靠的。我们又为什么要再把DTO转换成视图模型对象？ 简而言之，我们在基于一个假设：重用已有的代码会比为解决手头的这个问题新写点代码更简单。而基于此假设，我们做了很多无用的工作。我们不妨换个思路： 我们为什么不新创建一个数据容器，并允许这个数据容器中的数据和数据库中有点不同步—。我的意思是，既然我们展示给用户的数据总是要过时的，那为什么不直接在数据容器中反映出来这个变化？后面我们会给出一个保持这个数据容器与数据库同步的方案。 现在的问题是，这个数据容器中数据的正确结构应该是啥样的？直接和视图对象的结构一样怎么样？假设每个视图有一个对应结构的数据容器，那么客户端在展现数据的时候就可以简单的通过Select * from MyViewTable这种方式（或者在where语句中加个ID）来完成。如果有需要，你可以通过一个很薄的façade来包装查询的过程，或者用个存储过程，抑或是用个自动映射对象将数据映射到视图模型对象中。这样做的关键，是视图模型对象是网络友好的（wire-friendly），因此你不再需要将他转换成其他的东西。你甚至可以考虑将这个数据容器放在Web层。这就像Web层的缓存一样安全。然后只允许Web服务器进行SELECT操作，这样就OK了。 查询的数据容器你可以使用传统的数据库作为查询的数据容器，但这不是唯一的选择。考虑下这个问题，实际上查询的schema和你的视图模型对象的结构是一样的。而在不同的模型视图对象之间通常也没有任何的联系，所以在不同的查询数据容器之间也不需要任何的关联。 那么，你真的想要传统的数据库么？ 答案是否定的。但在实际过程中出于组织惯性，这却往往又是最好的选择。 分割查询反正现在查询是通过一个独立的数据容器而非数据库，同时也并没有假设数据容器中的数据必须100%和数据库一致的，那么你就可以轻松的添加更多的数据容器实例且不必为他们的数据一致性担忧。针对一个数据容器进行更新的机制同样可以被用到其他的数据容器上，我们稍后会看到这个。这样，我们就可以非常便捷的水平切割我们的查询了。同时，因为在查询时没有做过多的无用的数据转换，单次查询的速度也提升上来了。简单的就是快的。 数据修改因为我们的用户是基于过时的数据做出决策的，所以我们更加需要明确哪些操作是可以通过的而哪些不行。下面有个简单的例子： 假设有一个正在和客户通电话的客户服务代理人。这位老兄正盯着电脑屏幕上的客户的信息看，同时修改客户的住址，修改称呼为先生/小姐，修改他的姓氏并表明他的婚姻状况为已婚，并将这个客户设置为“优质的”客户。然而这位老兄不知道的是，在他打开网页后，一个订单部门发出的信息显示这个客户并没有及时支付拖欠的订单——他欠债了。我们的客户服务代表提交了他的修改。 我们是否应该接受这些修改？说实话，我们应该接受其中的部分，但不应该包括设置为“优质的”客户这部分，因为他欠帐了。但是要实现这些校验是个头疼的任务，我们需要对数据做一个差异比较，找到哪些部分被修改或者是过时了，搞清楚改变的含义，哪些数据是相互关联的（例如姓名的改变和称呼的改变），哪些是独立的，然后确定哪些修改违反了校验规则——不仅要比较用户提交的数据，还要和数据库中的数据比较，然后决定通过还是返回。 不幸的是，对于我们的用户，提交的数据哪怕只有一部分没通过校验也会整体返回。此时，用户不得不刷新页面来获取最新的数据，然后重新修改重新提交，祈祷这次不要再因为一个乐观锁冲突而再次失败。 当实体变的越来越大的时候，它所包含的字段也越来越多。此时也会有越来越多的用户在对实体进行协同操作。在任意给定的时间内，对该实体某些字段操作的可能性越大，触发锁冲突的可能性也就越大。 如果在修改数据时，有方法能够让用户提供操作的准确目的和粒度就好了。而这就是命令解决的问题。 命令CQRS的一个核心元素，是对用户界面进行重新设计，来让我们能够分辨出用户操作的真实意图，例如设置一个客户为优质客户是不同于重置用户的住址或者修改用户的婚姻状态的操作。用类似Excel表格方式的界面是无法准确捕获用户意图的，就如上文所见。 我们甚至可以考虑即使用户上一个命令尚未执行完成时也允许用户提交下一个新命令。我们可以用一个小部件放在页面旁边，用来展示命令的状态，通过异步的方式获取命令执行结果。如果命令成功了就显示通过，否则显示失败并出现红叉叉。用户通过双击失败的命令可以看到错误信息。 请注意命令是发送而非发布，这是有区别的。命令是发送的，事件是发布的。当事件被发布后，发布者只是声明了一个状态，它的工作就此结束。至于接受者要拿事件做什么处理，发布者并不关心。 命令和校验在考虑什么东西可能会让命令执行失败时，跳出来的一个元素是数据合法性校验。数据合法性校验和业务规则不同，它针对命令声明了一些上下文无关的要求。一个命令是合法的，抑或相反。与此相对，业务规则是上下文相关的。 在我们上面提的例子中，用户提交的数据的数据合法性是通过的，它被拒绝的唯一原因是账单事件比提交操作早到达。假如账单事件没到，那么操作就通过了。 这说明即便一个操作的合法性校验通过了，也可能有其他原因会拒绝掉。因此，数据合法性可以放在客户端完成。在客户端校验必填的数据都填了，格式是不是正确。服务器端仍然会校验所有的命令，对客户端采用不信任策略。 根据合法性校验重新审视界面和命令设计客户端在校验命令合法性的时候会去了解数据容器里的数据。举个例子，在提交一个用户住址修改的命令前，我们要检查数据容器中是否已存在这个街道数据。此时，我们会考虑将地址栏设计成为一个自动填充的输入组件，以此保证我们通过命令传输的地址是合法的。但是，为什么不能更近一步，干脆将街道的ID传过去而不是名称字符串呢？ 在服务器端看，也许不这么做的唯一理由是这样会因为数据被并发操作而导致命令执行失败，此时其他人将这个街道数据删除了但刚好还未同步到数据容器中。当然这个场景非常少见。 合法的命令执行失败的原因及处理方案这个时候我们的客户端已经能够传输合法的命令，但是服务器还是可能会拒绝掉命令。出现这种场景的原因，最常见的就是其他人并行的修改了命令处理过程中需要使用的其他数据。 在上面的CRM系统的例子里，命令执行失败仅仅是因为账单事件比操作早到达了。但“早”的概念甚至可能只有几毫秒。假如用户提早几毫秒按下了发送键呢？这点差距是否应该导致最终截然不同的业务结果？我们难道不该期望我们的系统在用户看来应该是“行为一致”的么？ 那么，假如账单事件确实晚来了一步，那么它是否应该撤销掉刚刚设置用户为优质用户的操作呢？不仅如此，是否还应该通知我们的用户，比如发个电子邮件给他？抑或，在账单事件早到达的情况下难道就不应该这么做么？还有如果我们已经有了一套完整的异步通知模型，我们是否还需要同步的在用户操作时返回错误呢？我的意思是，其实没啥区别，同步返回一样也就是告诉用户结果而已。 所以，如果我们不在操作时同步返回错误信息（假设命令的数据是合法的），我们所需要做的可能就是在发送命令后告诉用户“谢谢操作。结果确认将稍后通过Email发出”。这样，我们就连在页面小挂件上告诉用户你有几个命令没执行完都省了。 命令和自治在这个模型里，命令不需要马上被执行掉—，他们可以放在队列里异步执行。至于命令能够多快的被执行，这是服务层该关心的问题而非一个整体架构问题。而这，就是运行时自主处理命令节点的一个设计要素我们不需要和客户端保持链接。 与此同时，我们也不应该在执行命令时显式的去操作查询用的数据容器，任何操作都应该交给自治组件组件完成，这也是自治定义的一部分。 另一个要关心的问题应该是数据库宕掉或者遇到死锁时的处理方案。此时抛出的错误肯定不能直接扔到客户端去—，我们完全可以回滚并重试。当系统管理员把数据库恢复后，所有在队列里等待的命令都将顺利的执行，而用户也可以收到结果反馈，此时系统就健壮多了。 另外，由于这个数据库不会再服务于查询的场景，它就可以为命令执行提供更好的性能支撑，比如保留更多用于写的行/页缓存数据在内存里。而当数据库既要负责查询又要负责写入的时候，内存里的数据也往往在支撑查询和支撑更新的缓存数据间来回切换。 自治组件虽然在上文的图中，所有的命令都集中到一个自治组件里，但实际上我们可以让每个命令被不同的自治组件来处理，且每个组件都有自己独立的等待队列。这个做法可以让我们轻而易举的发现哪个等待队列是最长的，从而发现系统的瓶颈。这对开发很友好，但对系统管理员而言则没那么友好。 由于等待队列里有较多的命令，我们完全可以针对这些队列增加处理节点（使用服务总线的分发器完成），从而轻松的扩展系统性能较慢的处理部分。其他部分则完全不会浪费资源。 服务层自治组件中用于处理命令的各种对象实际上就组成了我们的服务层。你之所以没有在CQRS中明显的看到这一层的原因，是因为它并非像常规的相关对象聚合在一起形成的层那样具有识别性。 在传统的分层架构中并没有显示的声明一层对象间需要有各种依赖关系，甚至都没有暗示应该有这回事。然而，当我们以面向命令的视角去看整个服务层的时候，我们看到的是处理不同命令的各种对象。由于每个命令都是独立的，那么为什么处理命令的对象需要相互依赖呢？ 实际上应该尽量避免依赖，除非有明确的理由使用他们。保持处理命令的对象间相互独立对于我们来说非常有益。当我们升级系统时，每次根据一个命令来，而不需要将整个系统停下来，并让新的版本对老版本进行向前兼容。因此，尽量保持每个命令处理器在一个他自己相对的环境中，甚至是一套完全独立的解决方案中，以此引导用户不要已重用之名引入依赖关系（这是个谬论）。如果你的的确确想把它们全都放到一个流程里来处理同一个命令队列，那么你就要接受许多自治组件带来的优势的被抵消。 领域模型何去何从尽管在上面的图中领域模型就放在处理命令的自治组件的旁边，它实际上只是一个实现的细节。实际上并没有规定说所有的命令都需要通过一个领域模型来处理。实际上你可以使用业务脚本来处理一部分命令，表模块模式处理另一部分命令，或者是用领域模型。事件溯源是另一种实现方式。 另一个需要说明的是现在领域模型不再需要支撑查询。那么问题来了：我们还是否需要在领域模型中存在那么多的关联关系呢？（你可能需要深入理解下）你真的需要在用户实体中持有一个订单集合？在哪个命令中我们需要对这个集合进行导航？哪种命令又需要一对多的数据关系？假如一对多是必需的，那么多对多实际上也就有需要。是多数命令其实只持有1到2个引用ID。 任何需要通过循环处理子实体来计算的聚合操作实际上都可以通过提前处理并将数据作为属性存储在父实体中来实现。通过对所有的实体进行上面的预处理操作可以得到已经将ID替换为属性的完全独立的实体——子实体则持有父实体的ID，和数据库中一样。在这种模式下，命令可以完全通过一个领域模型来处理—，一个聚合的根对象就是一个一致性边界。 命令处理的持久化之前已经确认用于命令处理的数据库是不会用来做数据查询的，而绝大部分（如果不是所有）的命令都持有着他们要更新的行数据的ID，那么给领域模型对象里的每一个属性分配一个数据库列字段是否真的还有必要？如果我们把整个对象都序列化后存到一个字段里，然后另一个字段用来存ID会怎样？这种做法听起来有点像很多云服务提供商的K-V存储方式。在这种情况下，你是否有需要用对象关系映射来存储数据？ 当你需要强制某列数据的唯一性的时候，可以从每个数据行中拉出一列出来来实现。我并不是想让你在每个场景中都用这套方式，我只是想让你重新对一些最基本的假设和设计进行思考。我需要重申，你如何处理命令实际上是CQRS的一个实现细节。 保持查询数据容器的数据同步在自治组件通过了一个命令的处理，将数据库中的数据进行更新后，接下来要做的就是发出事件，告诉全世界这件事。这个事件通常是命令执行的“过去式”： 设置用户为优质的命令 –&gt; 用户已被设置为优质的事件 发布事件这个动作和处理命令以及更新数据库应该放在同一个事务中完成。这种情况下，任何原因导致的命令提交失败都会使得最终的事件未被发布。事件发布应该是由你所使用的消息总线来默认实现的。如果你用了MQ来作为底层传输的实现，那么就需要使用事务型队列。 用于收听事件并更新查询数据容器的自治组件实际上比较简单，它只需要将事件转换成持久化的视图模型结构。我的建议是每个视图模型类都有一个对应的事件处理自治组件。 下面再来看一次所有结构的图： 使用场景的边界尽管CQRS涉及了很多软件架构方式，它也并非站在食物链的顶端（各种通吃）。如果使用了CQRS，那么它应该是在一个有边界的上下文（领域驱动设计）或者一个业务组件（SOA）、一个高内聚的问题领域中的。一个业务组件发布出来的事件被其他的业务组件收听，然后收听的组件各自根据需要更新自己的查询数据容器。 CQRS中各个业务组件的UI可以被揉到一个单独的应用中，给用户提供一个一站化的可以俯视领域中所有部分的复合视图。因此复合视图框架也往往很有必要。 CQRS是用来解决多用户协同操作的一种架构。它非常明确的考虑了数据过时和易变等特性，并以此创造出了一个更加简单和可扩展的架构方式。如果没有考虑用户界面的设计，就无法准确掌握用户的意图，自然也无法充分发挥CQRS的优势。当把客户端的数据合法性校验纳入考虑的时候，命令也就可能做出一些调整。在通盘考虑过命令和事件是如何处理的场景和顺序后，能够弱化错误及时返回必要性的通知模式也就自然而然的出来了。 使用CQRS可以给项目带来一个更具可维护性和高性能的代码基础。这种简便和可扩展性并非来源于任何技术的“完美实践”，而是通过对业务需求细节的完全了解得来的。如果说有任何对于相似问题的多种解决方案被明显的放到一起使用，那就是数据读取器和领域模型，单向消息传递和同步调用。 CQRS与Event Sourcing的关系在CQRS中，查询方面，直接通过方法查询数据库，然后通过DTO将数据返回。在操作(Command)方面，是通过发送Command实现，由CommandBus处理特定的Command，然后由Command将特定的Event发布到EventBus上，然后EventBus使用特定的Handler来处理事件，执行一些诸如，修改，删除，更新等操作。这里，所有与Command相关的操作都通过Event实现。这样我们可以通过记录Event来记录系统的运行历史记录，并且能够方便的回滚到某一历史状态。Event Sourcing就是用来进行存储和管理事件的。]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java - ThreadPoolExecutor]]></title>
    <url>%2F2018%2F01%2F22%2Fjava-threadpoolexecutor%2F</url>
    <content type="text"><![CDATA[概述 ThreadPoolExecutor作为java.util.concurrent包对外提供基础实现，以内部线程池的形式对外提供管理任务执行，线程调度，线程池管理等等服务； Executors方法提供的线程服务，都是通过参数设置来实现不同的线程池机制； 先来了解其线程池管理的机制，有助于正确使用，避免错误使用导致严重故障。同时可以根据自己的需求实现自己的线程池； 核心构造方法讲解下面是ThreadPoolExecutor最核心的构造方法：123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 构造方法参数讲解: 参数名 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true)使得核心线程有效时间 TimeUnit keepAliveTime时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时，任务会交给RejectedExecutionHandler来处理 重点讲解：其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行 当workQueue已满，且maximumPoolSize&gt;corePoolSize时，新提交任务会创建新线程执行任务 当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理 当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程 当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭 线程管理机制图示： Executors提供的线程池配置方案1、构造一个固定线程数目的线程池，配置的corePoolSize与maximumPoolSize大小相同，同时使用了一个无界LinkedBlockingQueue存放阻塞任务，因此多余的任务将存在再阻塞队列，不会由RejectedExecutionHandler处理12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 2、构造一个缓冲功能的线程池，配置corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE，keepAliveTime=60s,以及一个无容量的阻塞队列 SynchronousQueue，因此任务提交之后，将会创建新的线程执行；线程空闲超过60s将会销毁12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 3、构造一个只支持一个线程的线程池，配置corePoolSize=maximumPoolSize=1，无界阻塞队列LinkedBlockingQueue；保证任务由一个线程串行执行123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 4、构造有定时功能的线程池，配置corePoolSize，无界延迟阻塞队列DelayedWorkQueue；有意思的是：maximumPoolSize=Integer.MAX_VALUE，由于DelayedWorkQueue是无界队列，所以这个值是没有意义的1234567891011121314public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); &#125; public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), threadFactory); &#125; 定制属于自己的非阻塞线程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.RejectedExecutionHandler; import java.util.concurrent.ThreadFactory; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; public class CustomThreadPoolExecutor &#123; private ThreadPoolExecutor pool = null; /** * 线程池初始化方法 * * corePoolSize 核心线程池大小----10 * maximumPoolSize 最大线程池大小----30 * keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间----30+单位TimeUnit * TimeUnit keepAliveTime时间单位----TimeUnit.MINUTES * workQueue 阻塞队列----new ArrayBlockingQueue&lt;Runnable&gt;(10)====10容量的阻塞队列 * threadFactory 新建线程工厂----new CustomThreadFactory()====定制的线程工厂 * rejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时, * 即当提交第41个任务时(前面线程都没有执行完,此测试方法中用sleep(100)), * 任务会交给RejectedExecutionHandler来处理 */ public void init() &#123; pool = new ThreadPoolExecutor( 10, 30, 30, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(10), new CustomThreadFactory(), new CustomRejectedExecutionHandler()); &#125; public void destory() &#123; if(pool != null) &#123; pool.shutdownNow(); &#125; &#125; public ExecutorService getCustomThreadPoolExecutor() &#123; return this.pool; &#125; private class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); String threadName = CustomThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; &#125; &#125; private class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 记录异常 // 报警处理等 System.out.println("error............."); &#125; &#125; // 测试构造的线程池 public static void main(String[] args) &#123; CustomThreadPoolExecutor exec = new CustomThreadPoolExecutor(); // 1.初始化 exec.init(); ExecutorService pool = exec.getCustomThreadPoolExecutor(); for(int i=1; i&lt;100; i++) &#123; System.out.println("提交第" + i + "个任务!"); pool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("running====="); &#125; &#125;); &#125; // 2.销毁----此处不能销毁,因为任务没有提交执行完,如果销毁线程池,任务也就无法执行了 // exec.destory(); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 方法中建立一个核心线程数为30个，缓冲队列有10个的线程池。每个线程任务，执行时会先睡眠3秒，保证提交10任务时，线程数目被占用完，再提交30任务时，阻塞队列被占用完，，这样提交第41个任务是，会交给CustomRejectedExecutionHandler 异常处理类来处理。 提交任务的代码如下：123456789101112131415161718192021222324252627282930313233343536373839public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 注意：41以后提交的任务就不能正常处理了，因为，execute中提交到任务队列是用的offer方法，如上面代码，这个方法是非阻塞的，所以就会交给CustomRejectedExecutionHandler 来处理，所以对于大数据量的任务来说，这种线程池，如果不设置队列长度会OOM，设置队列长度，会有任务得不到处理，接下来我们构建一个阻塞的自定义线程池 定制属于自己的阻塞线程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.RejectedExecutionHandler; import java.util.concurrent.ThreadFactory; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; public class CustomThreadPoolExecutor &#123; private ThreadPoolExecutor pool = null; /** * 线程池初始化方法 * * corePoolSize 核心线程池大小----1 * maximumPoolSize 最大线程池大小----3 * keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间----30+单位TimeUnit * TimeUnit keepAliveTime时间单位----TimeUnit.MINUTES * workQueue 阻塞队列----new ArrayBlockingQueue&lt;Runnable&gt;(5)====5容量的阻塞队列 * threadFactory 新建线程工厂----new CustomThreadFactory()====定制的线程工厂 * rejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时, * 即当提交第41个任务时(前面线程都没有执行完,此测试方法中用sleep(100)), * 任务会交给RejectedExecutionHandler来处理 */ public void init() &#123; pool = new ThreadPoolExecutor( 1, 3, 30, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(5), new CustomThreadFactory(), new CustomRejectedExecutionHandler()); &#125; public void destory() &#123; if(pool != null) &#123; pool.shutdownNow(); &#125; &#125; public ExecutorService getCustomThreadPoolExecutor() &#123; return this.pool; &#125; private class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); String threadName = CustomThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; &#125; &#125; private class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; try &#123; // 核心改造点，由blockingqueue的offer改成put阻塞方法 executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; // 测试构造的线程池 public static void main(String[] args) &#123; CustomThreadPoolExecutor exec = new CustomThreadPoolExecutor(); // 1.初始化 exec.init(); ExecutorService pool = exec.getCustomThreadPoolExecutor(); for(int i=1; i&lt;100; i++) &#123; System.out.println("提交第" + i + "个任务!"); pool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println("&gt;&gt;&gt;task is running====="); TimeUnit.SECONDS.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; // 2.销毁----此处不能销毁,因为任务没有提交执行完,如果销毁线程池,任务也就无法执行了 // exec.destory(); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 解释：当提交任务被拒绝时，进入拒绝机制，我们实现拒绝方法，把任务重新用阻塞提交方法put提交，实现阻塞提交任务功能，防止队列过大，OOM，提交被拒绝方法在下面123456789101112131415161718192021public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) // 进入拒绝机制， 我们把runnable任务拿出来，重新用阻塞操作put，来实现提交阻塞功能 reject(command); &#125; 总结： 1、用ThreadPoolExecutor自定义线程池，看线程是的用途，如果任务量不大，可以用无界队列，如果任务量非常大，要用有界队列，防止OOM2、如果任务量很大，还要求每个任务都处理成功，要对提交的任务进行阻塞提交，重写拒绝机制，改为阻塞提交。保证不抛弃一个任务3、最大线程数一般设为2N+1最好，N是CPU核数4、核心线程数，看应用，如果是任务，一天跑一次，设置为0，合适，因为跑完就停掉了，如果是常用线程池，看任务量，是保留一个核心还是几个核心线程数5、如果要获取任务执行结果，用CompletionService，但是注意，获取任务的结果的要重新开一个线程获取，如果在主线程获取，就要等任务都提交后才获取，就会阻塞大量任务结果，队列过大OOM，所以最好异步开个线程获取结果]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java堆外内存]]></title>
    <url>%2F2018%2F01%2F16%2Fjava-directbytebuffer%2F</url>
    <content type="text"><![CDATA[Java中不需要手动的申请和释放内存，JVM会自动进行垃圾回收；而使用的内存是由JVM控制的。那么，什么时机会进行垃圾回收，如何避免过度频繁的垃圾回收？如果JVM给的内存不够用，怎么办？此时可以利用堆外内存，不仅可以随意操控内存，还能提高网络交互的速度。 背景JVM内存的分配新生代：一般来说新创建的对象都分配在这里。年老代：经过几次垃圾回收，新生代的对象就会放在年老代里面。年老代中的对象保存的时间更久。永久代：这里面存放的是class相关的信息，一般是不会进行垃圾回收的。 JVM垃圾回收由于JVM会替我们执行垃圾回收，因此开发者根本不需要关心对象的释放。但是如果不了解其中的原委，很容易内存泄漏，只能两眼望天了。垃圾回收，大致可以分为下面几种： Minor GC:当新创建对象，内存空间不够的时候，就会执行这个垃圾回收。由于执行最频繁，因此一般采用复制回收机制。 Major GC:清理年老代的内存，这里一般采用的是标记清除+标记整理机制。 Full GC:有的说与Major GC差不多，有的说相当于执行minor+major回收，那么我们暂且可以认为Full GC就是全面的垃圾回收吧。 堆外内存优缺点堆外内存，其实就是不受JVM控制的内存。相比于堆内内存有几个优势： 减少了垃圾回收的工作，因为垃圾回收会暂停其他的工作（可能使用多线程或者时间片的方式，根本感觉不到） 加快了复制的速度。因为堆内在flush到远程时，会先复制到直接内存（非堆内存），然后在发送；而堆外内存相当于省略掉了这个工作; 堆外内存的缺点有： 堆外内存难以控制，如果内存泄漏，那么很难排查; 堆外内存相对来说，不适合存储很复杂的对象。一般简单的对象或者扁平化的比较适合; 堆外内存可以通过java.nio的ByteBuffer来创建，调用allocateDirect方法申请即可。此外，默认的情况下堆外内存是有一定的限制的（64M），可以通过设置-XX:MaxDirectMemorySize=10M控制堆外内存的大小。 堆外内存的垃圾回收]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[非阻塞同步算法与CAS无锁算法]]></title>
    <url>%2F2018%2F01%2F16%2Fjava-compare-and-swap%2F</url>
    <content type="text"><![CDATA[锁（lock）的代价锁是用来做并发最简单的方式，当然其代价也是最高的。内核态的锁的时候需要操作系统进行一次上下文切换，加锁、释放锁会导致比较多的上下文切换和调度延时，等待锁的线程会被挂起直至锁释放。在上下文切换的时候，cpu之前缓存的指令和数据都将失效，对性能有很大的损失。操作系统对多线程的锁进行判断就像两姐妹在为一个玩具在争吵，然后操作系统就是能决定他们谁能拿到玩具的父母，这是很慢的。用户态的锁虽然避免了这些问题，但是其实它们只是在没有真实的竞争时才有效。 Java在JDK1.5之前都是靠synchronized关键字保证同步的，这种通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有守护变量的锁，都采用独占的方式来访问这些变量，如果出现多个线程同时访问锁，那第一些线线程将被挂起，当线程恢复执行时，必须等待其它线程执行完他们的时间片以后才能被调度执行，在挂起和恢复执行过程中存在着很大的开销。锁还存在着其它一些缺点，当一个线程正在等待锁时，它不能做任何事。如果一个线程在持有锁的情况下被延迟执行，那么所有需要这个锁的线程都无法执行下去。如果被阻塞的线程优先级高，而持有锁的线程优先级低，将会导致优先级反转(Priority Inversion)。 乐观锁与悲观锁独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。 volatile的问题与锁相比，volatile变量是一和更轻量级的同步机制，因为在使用这些变量时不会发生上下文切换和线程调度等操作，但是volatile变量也存在一些局限：不能用于构建原子的复合操作，因此当一个变量依赖旧值时就不能使用volatile变量。（参考：谈谈volatiile） volatile只能保证变量对各个线程的可见性，但不能保证原子性。为什么？在Sun的JDK官方文档是这样形容volatile的： The Java programming language provides a second mechanism, volatile fields, that is more convenient than locking for some purposes. A field may be declared volatile, in which case the Java Memory Model ensures that all threads see a consistent value for the variable. 意思就是说，如果一个变量加了volatile关键字，就会告诉编译器和JVM的内存模型：这个变量是对所有线程共享的、可见的，每次jvm都会读取最新写入的值并使其最新值在所有CPU可见。volatile似乎是有时候可以代替简单的锁，似乎加了volatile关键字就省掉了锁。但又说volatile不能保证原子性（java程序员很熟悉这句话：volatile仅仅用来保证该变量对所有线程的可见性，但不保证原子性）。这不是互相矛盾吗？ 不要将volatile用在getAndOperate场合（这种场合不原子，需要再加锁），仅仅set或者get的场景是适合volatile的。 volatile没有原子性举例：AtomicInteger自增例如你让一个volatile的integer自增（i++），其实要分成3步： 读取volatile变量值到local； 增加变量的值； 把local的值写回，让其它的线程可见。 这3步的jvm指令为：1234mov 0xc(%r10),%r8d ; Loadinc %r8d ; Incrementmov %r8d,0xc(%r10) ; Storelock addl $0x0,(%rsp) ; StoreLoad Barrier 注意最后一步是内存屏障。 什么是内存屏障（Memory Barrier）内存屏障（memory barrier）是一个CPU指令。基本上，它是这样一条指令： 确保一些特定操作执行的顺序； 影响一些数据的可见性(可能是某些指令执行后的结果)。 编译器和CPU可以在保证输出结果一样的情况下对指令重排序，使性能得到优化。插入一个内存屏障，相当于告诉CPU和编译器先于这个命令的必须先执行，后于这个命令的必须后执行。内存屏障另一个作用是强制更新一次不同CPU的缓存。例如，一个写屏障会把这个屏障前写入的数据刷新到缓存，这样任何试图读取该数据的线程将得到最新值，而不用考虑到底是被哪个cpu核心或者哪颗CPU执行的。 内存屏障（memory barrier）和volatile什么关系？上面的虚拟机指令里面有提到，如果你的字段是volatile，Java内存模型将在写操作后插入一个写屏障指令，在读操作前插入一个读屏障指令。这意味着如果你对一个volatile字段进行写操作，你必须知道： 一旦你完成写入，任何访问这个字段的线程将会得到最新的值。 在你写入前，会保证所有之前发生的事已经发生，并且任何更新过的数据值也是可见的，因为内存屏障会把之前的写入值都刷新到缓存。 volatile为什么没有原子性明白了内存屏障（memory barrier）这个CPU指令，回到前面的JVM指令：从Load到store到内存屏障，一共4步，其中最后一步jvm让这个最新的变量的值在所有线程可见，也就是最后一步让所有的CPU内核都获得了最新的值，但中间的几步（从Load到Store）是不安全的，中间如果其他的CPU修改了值将会丢失。下面的测试代码可以实际测试voaltile的自增没有原子性： 12345678910111213141516171819202122232425262728293031323334353637383940private static volatile long _longVal = 0; private static class LoopVolatile implements Runnable &#123; public void run() &#123; long val = 0; while (val &lt; 10000000L) &#123; _longVal++; val++; &#125; &#125; &#125; private static class LoopVolatile2 implements Runnable &#123; public void run() &#123; long val = 0; while (val &lt; 10000000L) &#123; _longVal++; val++; &#125; &#125; &#125; private void testVolatile()&#123; Thread t1 = new Thread(new LoopVolatile()); t1.start(); Thread t2 = new Thread(new LoopVolatile2()); t2.start(); while (t1.isAlive() || t2.isAlive()) &#123; &#125; System.out.println("final val is: " + _longVal); &#125; Output:------------- final val is: 11223828final val is: 17567127final val is: 12912109 volatile没有原子性举例：singleton单例模式实现这是一段线程不安全的singleton（单例模式）实现，尽管使用了volatile：1234567891011121314public class wrongsingleton &#123; private static volatile wrongsingleton _instance = null; private wrongsingleton() &#123;&#125; public static wrongsingleton getInstance() &#123; if (_instance == null) &#123; _instance = new wrongsingleton(); &#125; return _instance; &#125;&#125; 下面的测试代码可以测试出是线程不安全的：123456789101112131415161718192021222324252627282930313233public class wrongsingleton &#123; private static volatile wrongsingleton _instance = null; private wrongsingleton() &#123;&#125; public static wrongsingleton getInstance() &#123; if (_instance == null) &#123; _instance = new wrongsingleton(); System.out.println("--initialized once."); &#125; return _instance; &#125;&#125; private static void testInit()&#123; Thread t1 = new Thread(new LoopInit()); Thread t2 = new Thread(new LoopInit2()); Thread t3 = new Thread(new LoopInit()); Thread t4 = new Thread(new LoopInit2()); t1.start(); t2.start(); t3.start(); t4.start(); while (t1.isAlive() || t2.isAlive() || t3.isAlive()|| t4.isAlive()) &#123; &#125; &#125;// 输出：有时输出"--initialized once."一次，有时输出好几次 原因自然和上面的例子是一样的。因为volatile保证变量对线程的可见性，但不保证原子性。 附：正确线程安全的单例模式写法：123456789@ThreadSafepublic class SafeLazyInitialization &#123; private static Resource resource; public synchronized static Resource getInstance() &#123; if (resource == null) resource = new Resource(); return resource; &#125; &#125; 另外一种写法：12345@ThreadSafepublic class EagerInitialization &#123; private static Resource resource = new Resource(); public static Resource getResource() &#123; return resource; &#125; &#125; 延迟初始化的写法：123456789@ThreadSafepublic class ResourceFactory &#123; private static class ResourceHolder &#123; public static Resource resource = new Resource(); &#125; public static Resource getResource() &#123; return ResourceHolder.resource ; &#125; &#125; 二次检查锁定/Double Checked Locking的写法（反模式）:12345678910111213141516public class SingletonDemo &#123; private static volatile SingletonDemo instance = null;//注意需要volatile private SingletonDemo() &#123; &#125; public static SingletonDemo getInstance() &#123; if (instance == null) &#123; //二次检查，比直接用独占锁效率高 synchronized (SingletonDemo .class)&#123; if (instance == null) &#123; instance = new SingletonDemo (); &#125; &#125; &#125; return instance; &#125;&#125; 讨论下volatile关键字的必要性,如果没有volatile关键字,问题可能会出在singleton = new Singleton();这句,用伪代码表示：123inst = allocat()； // 分配内存 sSingleton = inst; // 赋值constructor(inst); // 真正执行构造函数 如果不加volatile，可能会由于虚拟机的优化等导致赋值操作先执行,而构造函数还没完成,导致其他线程访问得到singleton变量不为null,但初始化还未完成,导致程序崩溃。 为什么AtomicXXX具有原子性和可见性就拿AtomicLong来说，它既解决了上述的volatile的原子性没有保证的问题，又具有可见性。它是利用CAS（比较并交换）指令实现的。 其实AtomicLong的源码里也用到了volatile，但只是用来读取或写入，见源码：1234567891011121314151617public class AtomicLong extends Number implements java.io.Serializable &#123; private volatile long value; /** * Creates a new AtomicLong with the given initial value. * * @param initialValue the initial value */ public AtomicLong(long initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicLong with initial value &#123;@code 0&#125;. */ public AtomicLong() &#123; &#125; 其CAS源码核心代码为：123456789int compare_and_swap (int* reg, int oldval, int newval) &#123; ATOMIC(); int old_reg_val = *reg; if (old_reg_val == oldval) *reg = newval; END_ATOMIC(); return old_reg_val;&#125; 虚拟机指令为：1234mov 0xc(%r11),%eax ; Loadmov %eax,%r8d inc %r8d ; Incrementlock cmpxchg %r8d,0xc(%r11) ; Compare and exchange 因为CAS是基于乐观锁的，也就是说当写入的时候，如果寄存器旧值已经不等于现值，说明有其他CPU在修改，那就继续尝试。所以这就保证了操作的原子性。 Java中的原子操作(atomic operations)原子操作指的是在一步之内就完成而且不能被中断。原子操作在多线程环境中是线程安全的，无需考虑同步的问题。在java中，下列操作是原子操作： all assignments of primitive types except for long and double all assignments of references all operations of java.concurrent.Atomic* classes all assignments to volatile longs and doubles 问题来了，为什么long型赋值不是原子操作呢？例如：1long foo = 65465498L; 实时上java会分两步写入这个long变量，先写32位，再写后32位。这样就线程不安全了。如果改成下面的就线程安全了：1private volatile long foo; 因为volatile内部已经做了synchronized. CAS无锁算法要实现无锁（lock-free）的非阻塞算法有多种实现方法，其中CAS（比较与交换，Compare and swap）是一种有名的无锁算法。CAS, CPU指令，在大多数处理器架构，包括IA32、Space中采用的都是CAS指令，CAS的语义是“我认为V的值应该为A，如果是，那么将V的值更新为B，否则不修改并告诉V的值实际为多少”，CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。CAS无锁算法的C实现如下：123456789int compare_and_swap (int* reg, int oldval, int newval) &#123; ATOMIC(); int old_reg_val = *reg; if (old_reg_val == oldval) *reg = newval; END_ATOMIC(); return old_reg_val;&#125; CAS（乐观锁算法）的基本假设前提CAS比较与交换的伪代码可以表示为：1234do&#123; 备份旧数据； 基于旧数据构造新数据； &#125;while(!CAS( 内存地址，备份的旧数据，新数据 )) 就是指当两者进行比较时，如果相等，则证明共享数据没有被修改，替换成新值，然后继续往下运行；如果不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作。容易看出 CAS 操作是基于共享数据不会被修改的假设，采用了类似于数据库的 commit-retry 的模式。当同步冲突出现的机会很少时，这种假设能带来较大的性能提升。 CAS的开销（CPU Cache Miss problem）前面说过了，CAS（比较并交换）是CPU指令级的操作，只有一步原子操作，所以非常快。而且CAS避免了请求操作系统来裁定锁的问题，不用麻烦操作系统，直接在CPU内部就搞定了。但CAS就没有开销了吗？不！有cache miss的情况。这个问题比较复杂，首先需要了解CPU的硬件体系结构： 上图可以看到一个8核CPU计算机系统，每个CPU有cache（CPU内部的高速缓存，寄存器），管芯内还带有一个互联模块，使管芯内的两个核可以互相通信。在图中央的系统互联模块可以让四个管芯相互通信，并且将管芯与主存连接起来。数据以“缓存线”为单位在系统中传输，“缓存线”对应于内存中一个 2 的幂大小的字节块，大小通常为 32 到 256 字节之间。当 CPU 从内存中读取一个变量到它的寄存器中时，必须首先将包含了该变量的缓存线读取到 CPU 高速缓存。同样地，CPU 将寄存器中的一个值存储到内存时，不仅必须将包含了该值的缓存线读到 CPU 高速缓存，还必须确保没有其他 CPU 拥有该缓存线的拷贝。 比如，如果 CPU0 在对一个变量执行“比较并交换”（CAS）操作，而该变量所在的缓存线在 CPU7 的高速缓存中，就会发生以下经过简化的事件序列： CPU0 检查本地高速缓存，没有找到缓存线。 请求被转发到 CPU0 和 CPU1 的互联模块，检查 CPU1 的本地高速缓存，没有找到缓存线。 请求被转发到系统互联模块，检查其他三个管芯，得知缓存线被 CPU6和 CPU7 所在的管芯持有。 请求被转发到 CPU6 和 CPU7 的互联模块，检查这两个 CPU 的高速缓存，在 CPU7 的高速缓存中找到缓存线。 CPU7 将缓存线发送给所属的互联模块，并且刷新自己高速缓存中的缓存线。 CPU6 和 CPU7 的互联模块将缓存线发送给系统互联模块。 系统互联模块将缓存线发送给 CPU0 和 CPU1 的互联模块。 CPU0 和 CPU1 的互联模块将缓存线发送给 CPU0 的高速缓存。 CPU0 现在可以对高速缓存中的变量执行 CAS 操作了 以上是刷新不同CPU缓存的开销。最好情况下的 CAS 操作消耗大概 40 纳秒，超过 60 个时钟周期。这里的“最好情况”是指对某一个变量执行 CAS 操作的 CPU 正好是最后一个操作该变量的CPU，所以对应的缓存线已经在 CPU 的高速缓存中了，类似地，最好情况下的锁操作（一个“round trip 对”包括获取锁和随后的释放锁）消耗超过 60 纳秒，超过 100 个时钟周期。这里的“最好情况”意味着用于表示锁的数据结构已经在获取和释放锁的 CPU 所属的高速缓存中了。锁操作比 CAS 操作更加耗时，是因深入理解并行编程为锁操作的数据结构中需要两个原子操作。缓存未命中消耗大概 140 纳秒，超过 200 个时钟周期。需要在存储新值时查询变量的旧值的 CAS 操作，消耗大概 300 纳秒，超过 500 个时钟周期。想想这个，在执行一次 CAS 操作的时间里，CPU 可以执行 500 条普通指令。这表明了细粒度锁的局限性。 以下是cache miss cas 和lock的性能对比： JVM对CAS的支持：AtomicInt, AtomicLong.incrementAndGet()在JDK1.5之前，如果不编写明确的代码就无法执行CAS操作，在JDK1.5中引入了底层的支持，在int、long和对象的引用等类型上都公开了CAS的操作，并且JVM把它们编译为底层硬件提供的最有效的方法，在运行CAS的平台上，运行时把它们编译为相应的机器指令，如果处理器/CPU不支持CAS指令，那么JVM将使用自旋锁。因此，值得注意的是，CAS解决方案与平台/编译器紧密相关（比如x86架构下其对应的汇编指令是lock cmpxchg，如果想要64Bit的交换，则应使用lock cmpxchg8b。在.NET中我们可以使用Interlocked.CompareExchange函数）。 在原子类变量中，如java.util.concurrent.atomic中的AtomicXXX，都使用了这些底层的JVM支持为数字类型的引用类型提供一种高效的CAS操作，而在java.util.concurrent中的大多数类在实现时都直接或间接的使用了这些原子变量类。 Java 1.6中AtomicLong.incrementAndGet()的实现源码为：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322/* * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */package java.util.concurrent.atomic;import java.util.function.LongUnaryOperator;import java.util.function.LongBinaryOperator;import sun.misc.Unsafe;/** * A &#123;@code long&#125; value that may be updated atomically. See the * &#123;@link java.util.concurrent.atomic&#125; package specification for * description of the properties of atomic variables. An * &#123;@code AtomicLong&#125; is used in applications such as atomically * incremented sequence numbers, and cannot be used as a replacement * for a &#123;@link java.lang.Long&#125;. However, this class does extend * &#123;@code Number&#125; to allow uniform access by tools and utilities that * deal with numerically-based classes. * * @since 1.5 * @author Doug Lea */public class AtomicLong extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 1927816293512124184L; // setup to use Unsafe.compareAndSwapLong for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; /** * Records whether the underlying JVM supports lockless * compareAndSwap for longs. While the Unsafe.compareAndSwapLong * method works in either case, some constructions should be * handled at Java level to avoid locking user-visible locks. */ static final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8(); /** * Returns whether underlying JVM supports lockless CompareAndSet * for longs. Called only once and cached in VM_SUPPORTS_LONG_CAS. */ private static native boolean VMSupportsCS8(); static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicLong.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile long value; /** * Creates a new AtomicLong with the given initial value. * * @param initialValue the initial value */ public AtomicLong(long initialValue) &#123; value = initialValue; &#125; /** * Creates a new AtomicLong with initial value &#123;@code 0&#125;. */ public AtomicLong() &#123; &#125; /** * Gets the current value. * * @return the current value */ public final long get() &#123; return value; &#125; /** * Sets to the given value. * * @param newValue the new value */ public final void set(long newValue) &#123; value = newValue; &#125; /** * Eventually sets to the given value. * * @param newValue the new value * @since 1.6 */ public final void lazySet(long newValue) &#123; unsafe.putOrderedLong(this, valueOffset, newValue); &#125; /** * Atomically sets to the given value and returns the old value. * * @param newValue the new value * @return the previous value */ public final long getAndSet(long newValue) &#123; return unsafe.getAndSetLong(this, valueOffset, newValue); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that * the actual value was not equal to the expected value. */ public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update); &#125; /** * Atomically sets the value to the given updated value * if the current value &#123;@code ==&#125; the expected value. * * &lt;p&gt;&lt;a href="package-summary.html#weakCompareAndSet"&gt;May fail * spuriously and does not provide ordering guarantees&lt;/a&gt;, so is * only rarely an appropriate alternative to &#123;@code compareAndSet&#125;. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful */ public final boolean weakCompareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update); &#125; /** * Atomically increments by one the current value. * * @return the previous value */ public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L); &#125; /** * Atomically decrements by one the current value. * * @return the previous value */ public final long getAndDecrement() &#123; return unsafe.getAndAddLong(this, valueOffset, -1L); &#125; /** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */ public final long getAndAdd(long delta) &#123; return unsafe.getAndAddLong(this, valueOffset, delta); &#125; /** * Atomically increments by one the current value. * * @return the updated value */ public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L; &#125; /** * Atomically decrements by one the current value. * * @return the updated value */ public final long decrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, -1L) - 1L; &#125; /** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the updated value */ public final long addAndGet(long delta) &#123; return unsafe.getAndAddLong(this, valueOffset, delta) + delta; &#125; /** * Atomically updates the current value with the results of * applying the given function, returning the previous value. The * function should be side-effect-free, since it may be re-applied * when attempted updates fail due to contention among threads. * * @param updateFunction a side-effect-free function * @return the previous value * @since 1.8 */ public final long getAndUpdate(LongUnaryOperator updateFunction) &#123; long prev, next; do &#123; prev = get(); next = updateFunction.applyAsLong(prev); &#125; while (!compareAndSet(prev, next)); return prev; &#125; /** * Atomically updates the current value with the results of * applying the given function, returning the updated value. The * function should be side-effect-free, since it may be re-applied * when attempted updates fail due to contention among threads. * * @param updateFunction a side-effect-free function * @return the updated value * @since 1.8 */ public final long updateAndGet(LongUnaryOperator updateFunction) &#123; long prev, next; do &#123; prev = get(); next = updateFunction.applyAsLong(prev); &#125; while (!compareAndSet(prev, next)); return next; &#125; /** * Atomically updates the current value with the results of * applying the given function to the current and given values, * returning the previous value. The function should be * side-effect-free, since it may be re-applied when attempted * updates fail due to contention among threads. The function * is applied with the current value as its first argument, * and the given update as the second argument. * * @param x the update value * @param accumulatorFunction a side-effect-free function of two arguments * @return the previous value * @since 1.8 */ public final long getAndAccumulate(long x, LongBinaryOperator accumulatorFunction) &#123; long prev, next; do &#123; prev = get(); next = accumulatorFunction.applyAsLong(prev, x); &#125; while (!compareAndSet(prev, next)); return prev; &#125; /** * Atomically updates the current value with the results of * applying the given function to the current and given values, * returning the updated value. The function should be * side-effect-free, since it may be re-applied when attempted * updates fail due to contention among threads. The function * is applied with the current value as its first argument, * and the given update as the second argument. * * @param x the update value * @param accumulatorFunction a side-effect-free function of two arguments * @return the updated value * @since 1.8 */ public final long accumulateAndGet(long x, LongBinaryOperator accumulatorFunction) &#123; long prev, next; do &#123; prev = get(); next = accumulatorFunction.applyAsLong(prev, x); &#125; while (!compareAndSet(prev, next)); return next; &#125; /** * Returns the String representation of the current value. * @return the String representation of the current value */ public String toString() &#123; return Long.toString(get()); &#125; /** * Returns the value of this &#123;@code AtomicLong&#125; as an &#123;@code int&#125; * after a narrowing primitive conversion. * @jls 5.1.3 Narrowing Primitive Conversions */ public int intValue() &#123; return (int)get(); &#125; /** * Returns the value of this &#123;@code AtomicLong&#125; as a &#123;@code long&#125;. */ public long longValue() &#123; return get(); &#125; /** * Returns the value of this &#123;@code AtomicLong&#125; as a &#123;@code float&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public float floatValue() &#123; return (float)get(); &#125; /** * Returns the value of this &#123;@code AtomicLong&#125; as a &#123;@code double&#125; * after a widening primitive conversion. * @jls 5.1.2 Widening Primitive Conversions */ public double doubleValue() &#123; return (double)get(); &#125;&#125; 由此可见，AtomicLong.incrementAndGet的实现用了乐观锁技术，调用了sun.misc.Unsafe类库里面的 CAS算法，用CPU指令来实现无锁自增。所以，AtomicLong.incrementAndGet的自增比用synchronized的锁效率倍增。123456789101112public final int getAndIncrement() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return current; &#125; &#125; public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; 下面是测试代码：可以看到用AtomicLong.incrementAndGet的性能比用synchronized高出几倍。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227import java.util.concurrent.atomic.AtomicLong; public class main &#123; /** * @param args */ public static void main(String[] args) &#123; System.out.println("START -- "); calc(); calcSynchro(); calcAtomic(); testThreadsSync(); testThreadsAtomic(); testThreadsSync2(); testThreadsAtomic2(); System.out.println("-- FINISHED "); &#125; private static void calc() &#123; stopwatch sw = new stopwatch(); sw.start(); long val = 0; while (val &lt; 10000000L) &#123; val++; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" calc() elapsed (ms): " + milSecds); &#125; private static void calcSynchro() &#123; stopwatch sw = new stopwatch(); sw.start(); long val = 0; while (val &lt; 10000000L) &#123; synchronized (main.class) &#123; val++; &#125; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" calcSynchro() elapsed (ms): " + milSecds); &#125; private static void calcAtomic() &#123; stopwatch sw = new stopwatch(); sw.start(); AtomicLong val = new AtomicLong(0); while (val.incrementAndGet() &lt; 10000000L) &#123; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" calcAtomic() elapsed (ms): " + milSecds); &#125; private static void testThreadsSync()&#123; stopwatch sw = new stopwatch(); sw.start(); Thread t1 = new Thread(new LoopSync()); t1.start(); Thread t2 = new Thread(new LoopSync()); t2.start(); while (t1.isAlive() || t2.isAlive()) &#123; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" testThreadsSync() 1 thread elapsed (ms): " + milSecds); &#125; private static void testThreadsAtomic()&#123; stopwatch sw = new stopwatch(); sw.start(); Thread t1 = new Thread(new LoopAtomic()); t1.start(); Thread t2 = new Thread(new LoopAtomic()); t2.start(); while (t1.isAlive() || t2.isAlive()) &#123; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" testThreadsAtomic() 1 thread elapsed (ms): " + milSecds); &#125; private static void testThreadsSync2()&#123; stopwatch sw = new stopwatch(); sw.start(); Thread t1 = new Thread(new LoopSync()); t1.start(); Thread t2 = new Thread(new LoopSync()); t2.start(); while (t1.isAlive() || t2.isAlive()) &#123; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" testThreadsSync() 2 threads elapsed (ms): " + milSecds); &#125; private static void testThreadsAtomic2()&#123; stopwatch sw = new stopwatch(); sw.start(); Thread t1 = new Thread(new LoopAtomic()); t1.start(); Thread t2 = new Thread(new LoopAtomic()); t2.start(); while (t1.isAlive() || t2.isAlive()) &#123; &#125; sw.stop(); long milSecds = sw.getElapsedTime(); System.out.println(" testThreadsAtomic() 2 threads elapsed (ms): " + milSecds); &#125; private static class LoopAtomic implements Runnable &#123; public void run() &#123; AtomicLong val = new AtomicLong(0); while (val.incrementAndGet() &lt; 10000000L) &#123; &#125; &#125; &#125; private static class LoopSync implements Runnable &#123; public void run() &#123; long val = 0; while (val &lt; 10000000L) &#123; synchronized (main.class) &#123; val++; &#125; &#125; &#125; &#125;&#125; public class stopwatch &#123; private long startTime = 0; private long stopTime = 0; private boolean running = false; public void start() &#123; this.startTime = System.currentTimeMillis(); this.running = true; &#125; public void stop() &#123; this.stopTime = System.currentTimeMillis(); this.running = false; &#125; public long getElapsedTime() &#123; long elapsed; if (running) &#123; elapsed = (System.currentTimeMillis() - startTime); &#125; else &#123; elapsed = (stopTime - startTime); &#125; return elapsed; &#125; public long getElapsedTimeSecs() &#123; long elapsed; if (running) &#123; elapsed = ((System.currentTimeMillis() - startTime) / 1000); &#125; else &#123; elapsed = ((stopTime - startTime) / 1000); &#125; return elapsed; &#125; // sample usage // public static void main(String[] args) &#123; // StopWatch s = new StopWatch(); // s.start(); // //code you want to time goes here // s.stop(); // System.out.println("elapsed time in milliseconds: " + // s.getElapsedTime()); // &#125;&#125; CAS的例子：非阻塞堆栈下面是比非阻塞自增稍微复杂一点的CAS的例子：非阻塞堆栈/ConcurrentStack 。ConcurrentStack 中的 push() 和 pop() 操作在结构上与NonblockingCounter 上相似，只是做的工作有些冒险，希望在 “提交” 工作的时候，底层假设没有失效。push() 方法观察当前最顶的节点，构建一个新节点放在堆栈上，然后，如果最顶端的节点在初始观察之后没有变化，那么就安装新节点。如果 CAS 失败，意味着另一个线程已经修改了堆栈，那么过程就会重新开始。123456789101112131415161718192021222324252627public class ConcurrentStack&lt;E&gt; &#123; AtomicReference&lt;Node&lt;E&gt;&gt; head = new AtomicReference&lt;Node&lt;E&gt;&gt;(); public void push(E item) &#123; Node&lt;E&gt; newHead = new Node&lt;E&gt;(item); Node&lt;E&gt; oldHead; do &#123; oldHead = head.get(); newHead.next = oldHead; &#125; while (!head.compareAndSet(oldHead, newHead)); &#125; public E pop() &#123; Node&lt;E&gt; oldHead; Node&lt;E&gt; newHead; do &#123; oldHead = head.get(); if (oldHead == null) return null; newHead = oldHead.next; &#125; while (!head.compareAndSet(oldHead,newHead)); return oldHead.item; &#125; static class Node&lt;E&gt; &#123; final E item; Node&lt;E&gt; next; public Node(E item) &#123; this.item = item; &#125; &#125;&#125; 在轻度到中度的争用情况下，非阻塞算法的性能会超越阻塞算法，因为 CAS 的多数时间都在第一次尝试时就成功，而发生争用时的开销也不涉及线程挂起和上下文切换，只多了几个循环迭代。没有争用的 CAS 要比没有争用的锁便宜得多（这句话肯定是真的，因为没有争用的锁涉及 CAS 加上额外的处理），而争用的 CAS 比争用的锁获取涉及更短的延迟。 在高度争用的情况下（即有多个线程不断争用一个内存位置的时候），基于锁的算法开始提供比非阻塞算法更好的吞吐率，因为当线程阻塞时，它就会停止争用，耐心地等候轮到自己，从而避免了进一步争用。但是，这么高的争用程度并不常见，因为多数时候，线程会把线程本地的计算与争用共享数据的操作分开，从而给其他线程使用共享数据的机会。 CAS的例子：非阻塞链表以上的示例（自增计数器和堆栈）都是非常简单的非阻塞算法，一旦掌握了在循环中使用 CAS，就可以容易地模仿它们。对于更复杂的数据结构，非阻塞算法要比这些简单示例复杂得多，因为修改链表、树或哈希表可能涉及对多个指针的更新。CAS 支持对单一指针的原子性条件更新，但是不支持两个以上的指针。所以，要构建一个非阻塞的链表、树或哈希表，需要找到一种方式，可以用 CAS 更新多个指针，同时不会让数据结构处于不一致的状态。 在链表的尾部插入元素，通常涉及对两个指针的更新：“尾” 指针总是指向列表中的最后一个元素，“下一个” 指针从过去的最后一个元素指向新插入的元素。因为需要更新两个指针，所以需要两个 CAS。在独立的 CAS 中更新两个指针带来了两个需要考虑的潜在问题：如果第一个 CAS 成功，而第二个 CAS 失败，会发生什么？如果其他线程在第一个和第二个 CAS 之间企图访问链表，会发生什么？ 对于非复杂数据结构，构建非阻塞算法的 “技巧” 是确保数据结构总处于一致的状态（甚至包括在线程开始修改数据结构和它完成修改之间），还要确保其他线程不仅能够判断出第一个线程已经完成了更新还是处在更新的中途，还能够判断出如果第一个线程走向 AWOL，完成更新还需要什么操作。如果线程发现了处在更新中途的数据结构，它就可以 “帮助” 正在执行更新的线程完成更新，然后再进行自己的操作。当第一个线程回来试图完成自己的更新时，会发现不再需要了，返回即可，因为 CAS 会检测到帮助线程的干预（在这种情况下，是建设性的干预）。 这种 “帮助邻居” 的要求，对于让数据结构免受单个线程失败的影响，是必需的。如果线程发现数据结构正处在被其他线程更新的中途，然后就等候其他线程完成更新，那么如果其他线程在操作中途失败，这个线程就可能永远等候下去。即使不出现故障，这种方式也会提供糟糕的性能，因为新到达的线程必须放弃处理器，导致上下文切换，或者等到自己的时间片过期（而这更糟）。 123456789101112131415161718192021222324252627282930public class LinkedQueue &lt;E&gt; &#123; private static class Node &lt;E&gt; &#123; final E item; final AtomicReference&lt;Node&lt;E&gt;&gt; next; Node(E item, Node&lt;E&gt; next) &#123; this.item = item; this.next = new AtomicReference&lt;Node&lt;E&gt;&gt;(next); &#125; &#125; private AtomicReference&lt;Node&lt;E&gt;&gt; head = new AtomicReference&lt;Node&lt;E&gt;&gt;(new Node&lt;E&gt;(null, null)); private AtomicReference&lt;Node&lt;E&gt;&gt; tail = head; public boolean put(E item) &#123; Node&lt;E&gt; newNode = new Node&lt;E&gt;(item, null); while (true) &#123; Node&lt;E&gt; curTail = tail.get(); Node&lt;E&gt; residue = curTail.next.get(); if (curTail == tail.get()) &#123; if (residue == null) /* A */ &#123; if (curTail.next.compareAndSet(null, newNode)) /* C */ &#123; tail.compareAndSet(curTail, newNode) /* D */ ; return true; &#125; &#125; else &#123; tail.compareAndSet(curTail, residue) /* B */; &#125; &#125; &#125; &#125;&#125; Java的ConcurrentHashMap的实现原理Java5中的ConcurrentHashMap，线程安全，设计巧妙，用桶粒度的锁，避免了put和get中对整个map的锁定，尤其在get中，只对一个HashEntry做锁定操作，性能提升是显而易见的。具体实现中使用了锁分离机制。 Java的ConcurrentLinkedQueue实现方法ConcurrentLinkedQueue也是同样使用了CAS指令，但其性能并不高因为太多CAS操作。 高并发环境下优化锁或无锁（lock-free）的设计思路服务端编程的3大性能杀手：1、大量线程导致的线程切换开销。2、锁。3、非必要的内存拷贝。在高并发下,对于纯内存操作来说,单线程是要比多线程快的, 可以比较一下多线程程序在压力测试下cpu的sy和ni百分比。高并发环境下要实现高吞吐量和线程安全，两个思路：一个是用优化的锁实现，一个是lock-free的无锁结构。但非阻塞算法要比基于锁的算法复杂得多。开发非阻塞算法是相当专业的训练，而且要证明算法的正确也极为困难，不仅和具体的目标机器平台和编译器相关，而且需要复杂的技巧和严格的测试。虽然Lock-Free编程非常困难，但是它通常可以带来比基于锁编程更高的吞吐量。所以Lock-Free编程是大有前途的技术。它在线程中止、优先级倒置以及信号安全等方面都有着良好的表现。 优化锁实现的例子：Java中的ConcurrentHashMap，设计巧妙，用桶粒度的锁和锁分离机制，避免了put和get中对整个map的锁定，尤其在get中，只对一个HashEntry做锁定操作，性能提升是显而易见的（详细分析见《探索 ConcurrentHashMap 高并发性的实现机制》）。 Lock-free无锁的例子：CAS（CPU的Compare-And-Swap指令）的利用和LMAX的disruptor无锁消息队列数据结构等。 另外，在设计思路上除了尽量减少资源争用以外，还可以借鉴nginx/node.js等单线程大循环的机制，用单线程或CPU数相同的线程开辟大的队列，并发的时候任务压入队列，线程轮询然后一个个顺序执行。由于每个都采用异步I/O，没有阻塞线程。这个大队列可以使用RabbitMQ，或是JDK的同步队列（性能稍差），或是使用Disruptor无锁队列(Java)。任务处理可以全部放在内存（多级缓存、读写分离、ConcurrentHashMap、甚至分布式缓存Redis）中进行增删改查。最后用Quarz维护定时把缓存数据同步到DB中。当然，这只是中小型系统的思路，如果是大型分布式系统会非常复杂，需要分而治理，用SOA的思路。（注：Redis是单线程的纯内存数据库，单线程无需锁，而Memcache是多线程的带CAS算法，两者都使用epoll，no-blocking io） 深入JVM的OS的无锁非阻塞算法如果深入 JVM 和操作系统，会发现非阻塞算法无处不在。垃圾收集器使用非阻塞算法加快并发和平行的垃圾搜集；调度器使用非阻塞算法有效地调度线程和进程，实现内在锁。在 Mustang（Java 6.0）中，基于锁的 SynchronousQueue 算法被新的非阻塞版本代替。很少有开发人员会直接使用 SynchronousQueue，但是通过 Executors.newCachedThreadPool() 工厂构建的线程池用它作为工作队列。比较缓存线程池性能的对比测试显示，新的非阻塞同步队列实现提供了几乎是当前实现 3 倍的速度。在 Mustang 的后续版本（代码名称为 Dolphin）中，已经规划了进一步的改进。]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[分布式事务]]></title>
    <url>%2F2018%2F01%2F15%2Fdistributed-transactions%2F</url>
    <content type="text"><![CDATA[基础知识2PC协议二阶段提交协议(Two-phaseCommit)是分布式系统中较为经典的处理数据一致性的解决方案。在大型的集群环境中，对于单体微服务本身而言虽然能够通过代码质量、Mock测试等方法来确保自身服务的可用性，但是无法能够保证其他服务的可用性。当一个全链路的端到端业务操作，常常会跨多个节点、多个应用，为了能够保证全局事务的ACID特性，需要引入一个协调组件(这里称之为TM)来控制所有服务参与者(这里称之为RM)的操作结果，根据所有参与者的反馈结果来决定整个分布式事务究竟是提交还是回滚的结果。 第一阶段：称为准备(prepare)阶段。事务协调者向各个服务应用发送prepare请求，服务应用在得到请求后做预处理操作，预处理可能是做预检查，也可能是把请求临时存储，可以理解为是一种试探性地提交。下面是一般的步骤： 事务协调者会问所有的参与者服务，是否可以提交操作。 各个参与者开始事务执行的准备工作：如资源上锁，预留资源，写回滚/重试的log。 参与者响应协调者，如果事务准备工作成功，则回应“可以提交”，否则回应拒绝提交。 第二阶段：称为提交(commit)/回滚(rollback)阶段。是指事务真正提交或者回滚的阶段。如果事务协调者发现事务参与者有一个在prepare阶段出现失败，则会要求所有的参与者进行回滚。如果协调者发现所有的参与者都prepare操作都是成功，那么他将向所有的参与者发出提交请求，这时所有参与者才会正式提交。由此保证了要求全部提交成功，要么全部失败。下面是具体步骤： 如果所有的参与者都回应“可以提交”，那么协调者向所有参与者发送“正式提交”的命令。参与者完成正式提交，并释放所有资源，然后回应“完成”，协调者收集各个服务的“完成”回应后结束事务。 如果有一个参与者回应“拒绝提交”，那么协调者向所有的参与者发送“回滚操作”，并释放所有的资源，然后回应“回滚完成”，协调者收集各个服务应用的“回滚”返回后，取消整体的分布式事务。 下图为二阶段的成功和失败示例图： 二阶段提交协议解决的是分布式系统/微服务架构中数据强一致性的问题，其原理简单，但缺点也是存在，主要缺点如下： 单点问题：协调者在整个二阶段中的作用非常重要，一旦部署协调者组件服务的节点出现不可用宕机情况，那么会影响整个分布式系统的正常运行。 同步阻塞：二阶段提交执行过程中，所有服务参与者需要服从协调者的统一调度，期间处于阻塞状态，会一定程度上影响整个系统的效率。 这里暂且不谈2PC存在的同步阻塞、单点问题、脑裂等问题（上篇文章中有具体介绍），我们只讨论下数据一致性问题。作为一个分布式的一致性协议，我们主要关注他可能带来的一致性问题的。2PC在执行过程中可能发生协调者或者参与者突然宕机的情况，在不同时期宕机可能有不同的现象。 情况一：协调者挂了，参与者没挂 这种情况其实比较好解决，只要找一个协调者的替代者。当他成为新的协调者的时候，询问所有参与者的最后那条事务的执行情况，他就可以知道是应该做什么样的操作了。所以，这种情况不会导致数据不一致。 情况二：参与者挂了，协调者没挂 这种情况其实也比较好解决。如果协调者挂了。那么之后的事情有两种情况： 第一个是挂了就挂了，没有再恢复。那就挂了呗，反正不会导致数据一致性问题。 第二个是挂了之后又恢复了，这时如果他有未执行完的事务操作，直接取消掉，然后询问协调者目前我应该怎么做，协调者就会比对自己的事务执行记录和该参与者的事务执行记录，告诉他应该怎么做来保持数据的一致性。 情况三：参与者挂了，协调者也挂了 这种情况比较复杂，我们分情况讨论。 协调者和参与者在第一阶段挂了。 由于这时还没有执行commit操作，新选出来的协调者可以询问各个参与者的情况，再决定是进行commit还是roolback。因为还没有commit，所以不会导致数据一致性问题。 第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前并没有接收到协调者的指令，或者接收到指令之后还没来的及做commit或者roolback操作。 这种情况下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况。只要有机器执行了abort（roolback）操作或者第一阶段返回的信息是No的话，那就直接执行roolback操作。如果没有人执行abort操作，但是有机器执行了commit操作，那么就直接执行commit操作。这样，当挂掉的参与者恢复之后，只要按照协调者的指示进行事务的commit还是roolback操作就可以了。因为挂掉的机器并没有做commit或者roolback操作，而没有挂掉的机器们和新的协调者又执行了同样的操作，那么这种情况不会导致数据不一致现象。 第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。这种情况下，新的协调者被选出来之后，如果他想负起协调者的责任的话他就只能按照之前那种情况来执行commit或者roolback操作。这样新的协调者和所有没挂掉的参与者就保持了数据的一致性，我们假定他们执行了commit。但是，这个时候，那个挂掉的参与者恢复了怎么办，因为他之前已经执行完了之前的事务，如果他执行的是commit那还好，和其他的机器保持一致了，万一他执行的是roolback操作那？这不就导致数据的不一致性了么？虽然这个时候可以再通过手段让他和协调者通信，再想办法把数据搞成一致的，但是，这段时间内他的数据状态已经是不一致的了。 所以，2PC协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。为了解决这个问题，衍生除了3PC。 3PC协议3PC(Three-phaseCommit)最关键要解决的就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。在第一阶段，只是询问所有参与者是否可可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback。 举一个生活中类似三阶段提交的例子： 班长要组织全班同学聚餐，由于大家毕业多年，所以要逐个打电话敲定时间，时间初定10.1日。然后开始逐个打电话。班长：小A，我们想定在10.1号聚会，你有时间嘛？有时间你就说YES，没有你就说NO，然后我还会再去问其他人，具体时间地点我会再通知你，这段时间你可先去干你自己的事儿，不用一直等着我。（协调者询问事务是否可以执行，这一步不会锁定资源）小A：好的，我有时间。（参与者反馈）班长：小B，我们想定在10.1号聚会……不用一直等我。班长收集完大家的时间情况了，一看大家都有时间，那么就再次通知大家。（协调者接收到所有YES指令）班长：小A，我们确定了10.1号聚餐，你要把这一天的时间空出来，这一天你不能再安排其他的事儿了。然后我会逐个通知其他同学，通知完之后我会再来和你确认一下，还有啊，如果我没有特意给你打电话，你就10.1号那天来聚餐就行了。对了，你确定能来是吧？（协调者发送事务执行指令，这一步锁住资源。如果由于网络原因参与者在后面没有收到协调者的命令，他也会执行commit）小A顺手在自己的日历上把10.1号这一天圈上了，然后跟班长说，我可以去。（参与者执行事务操作，反馈状态）班长：小B，我们觉得了10.1号聚餐……你就10.1号那天来聚餐就行了。班长通知完一圈之后。所有同学都跟他说：”我已经把10.1号这天空出来了”。于是，他在10.1号这一天又挨个打了一遍电话告诉他们：嘿，现在你们可以出门拉。。。。（协调者收到所有参与者的ACK响应，通知所有参与者执行事务的commit）小A，小B：我已经出门拉。（执行commit操作，反馈状态） 3PC为什么比2PC好？ 直接分析协调者和参与者都挂的情况。第二阶段协调者和参与者挂了，挂了的这个参与者在挂之前已经执行了操作。但是由于他挂了，没有人知道他执行了什么操作。这种情况下，当新的协调者被选出来之后，他同样是询问所有的参与者的情况来觉得是commit还是roolback。这看上去和二阶段提交一样啊？他是怎么解决一致性问题的呢？看上去和二阶段提交的那种数据不一致的情况的现象是一样的，但仔细分析所有参与者的状态的话就会发现其实并不一样。我们假设挂掉的那台参与者执行的操作是commit。那么其他没挂的操作者的状态应该是什么？他们的状态要么是prepare-commit要么是commit。因为3PC的第三阶段一旦有机器执行了commit，那必然第一阶段大家都是同意commit。所以，这时，新选举出来的协调者一旦发现未挂掉的参与者中有人处于commit状态或者是prepare-commit的话，那就执行commit操作。否则就执行rollback操作。这样挂掉的参与者恢复之后就能和其他机器保持数据一致性了。（为了简单的让大家理解，笔者这里简化了新选举出来的协调者执行操作的具体细节，真实情况比我描述的要复杂） 简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。所以，再多引入一个阶段之后，3PC解决了2PC中存在的那种由于协调者和参与者同时挂掉有可能导致的数据一致性问题。 3PC存在的问题 在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 最终一致最终一致依赖于可靠消息系统。 最大努力通知型TCCTCC(Try-Confirm-Cancle)是一种处理分布式事务的解决方案。通过将操作分为Try、Confirm、Cancle三个步骤来控制分布式系统的一致性。 SAGA]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程通识]]></title>
    <url>%2F2018%2F01%2F15%2Fjava-concurrent-sense%2F</url>
    <content type="text"><![CDATA[基本概念什么是并发并发(Concurrency)在我们的现实世界中随处可见，以至于我们常常忽略了它的存在，比方说你在工作（假设你是一名程序员，你的工作就是编程）的时候也可以听听自己喜欢的音乐，并且你的耳朵并不会因为手头的工作而忽略了声音的存在（当然，除非你自己有意的去忽略它，但你还是能够听得见声音，只是你的大脑可能不会去感受音乐的节奏），此时你的大脑既要控制你的双手敲击键盘，也要控制你的耳朵去感受音乐。因此，在一定程度上，你的大脑就在并发地处理不同的事情，并且每个时刻都可能会侧重处理某件事情，比如某个时刻音乐达到高潮并且是你喜欢的旋律，你可能会放慢或者停止手边的工作，但在另外一个时刻你正在编写关键代码，需要全神贯注来避免 Bug 的出现，你可能会把声音调小一点或者干脆摘掉耳机。所以，我们的大脑就在并发地指导我们完成各种任务，或者换一种说法，我们需要处理的任务并发地征用我们的大脑，大脑就相当于计算机的 CPU，而待处理的任务就相当于计算机程序（更确切地说应该是进程或线程等执行实体）。 不过在现实世界中，我们并不会严格定义什么是并发。而在计算机程序世界中，为了编写高性能的代码，我们应该理解什么是并发，并发的基本特性是什么，哪些问题可以使用并发编程来（高效地）解决，哪些情况下又应该尽量避免使用并发编程，我们在使用并发编程时需要注意一些什么问题，本章的将会给大家介绍并发的基本概念，带领大家学习并发编程的基本技巧。 并发与并行的联系和区别与并发相近的另一个概念是并行(Parallel)。和并发所描述的情况一样，并行也是指两个或多个任务被同时执行。但是严格来讲，并发和并行的概念并是不等同的，两者存在很大的差别。下面我们来看看计算机科学家们是怎么区分并发和并行的。 Erlang的发明者Joe Armstrong在他的一篇博文中提到如何向一个 5 岁的小孩去介绍并发和并行的区别，并给出了下面一幅图： 直观来讲，并发是两个等待队列中的人同时去竞争一台咖啡机（当然，人是有理性懂礼貌的动物（也不排除某些很霸道的人插队的可能），两队列中的排队者也可能约定交替使用咖啡机，也可能是大家同时竞争咖啡机，谁先竞争到咖啡机谁使用，不过后一种的方法可能引发冲突，因为两个队列里面排在队列首位的人可能同时使用咖啡机），每个等待者在使用咖啡机之前不仅需要知道排在他前面那个人是否已经使用完了咖啡机，还需知道另一个队列中排在首位的人是否也正准备使用咖啡机；而并行是每个队列拥有自己的咖啡机，两个队列之间并没有竞争的关系，队列中的某个排队者只需等待队列前面的人使用完咖啡机，然后再轮到自己使用咖啡机。 因此，并发意味着多个执行实体（比方说上面例子中的人）可能需要竞争资源（咖啡机），因此就不可避免带来竞争和同步的问题；而并行则是不同的执行实体拥有各自的资源，相互之间可能互不干扰。 Go发明者之一Rob Pike认为并发是程序本身的一种特性，程序被分为多个可独立执行的部分，而各个可独立执行的片段通过通信手段进行协调，而并行则是程序的计算过程（不同的计算过程可能相关联）同时执行。Rob Pike 的观点是： 并发是一次处理(dealing with)很多事情，而并行是一次做(doing)很多事情.(注: 英文词汇的表达也很微妙)原文是如下： Concurrency is about dealing with lots of things at once.Parallelism is about doing lots of things at once. 前者是关于程序结构的，而后者是关于程序执行的,Rob认为： Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable. 即我们可以利用并发的手段去构建一种解决方案来解决那些有可能被并行处理的问题。作者在本文中还提到，设计并发程序时应该将程序分为多个执行片段，使得每个片段可以独立执行。不同执行片段通过通信(Communication )来进行协调。因此Go的并发模型基于CSP: C. A. R. Hoare: Communicating Sequential Processes (CACM 1978) Intel中文网站的一篇文章曾这样写道: 并发（Concurrence）：指两个或两个以上的事件或活动在同一时间间隔内发生。并发的实质是单个物理 CPU(也可以多个物理CPU) 在若干道程序之间多路复用，并发可以对有限物理资源强制行使多用户共享以提高效率，如下图所示： 并行（Parallelism）指两个或两个以上事件或活动在同一时刻发生。在多道程序环境下，并行性使多个程序同一时刻可在不同CPU上同时执行，如下图所示： 此，该文认为并发与并行的区别是：并发是一个处理器同时处理多个任务，而并行多个处理器或者是多核的处理器同时处理多个不同的任务。前者是逻辑上的同时发生（simultaneous），而后者是物理上的同时发生。而两者的联系是：并行的事件或活动一定是并发的，但反之并发的事件或活动未必是并行的。并行性是并发性的特例，而并发性是并行性的扩展。 互联网的高并发高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。 概念 说明 响应时间 系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。 吞吐量 单位时间内处理的请求数量。 请求数 QPS（Query Per Second）/RPS（Request Per Second）每秒响应请求数。请求数指的是客户端在建立完连接后，向HTTP服务发出GET/POST/HEAD数据包。在互联网领域，这个指标和吞吐量区分的没有这么明显。 并发用户数 同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。 并发连接数 SBC（Simultaneous Browser Connections）指的是客户端向服务器发起请求，并建立了TCP连接。每秒钟服务器链接的总TCP数量，就是并发连接数。 面对互联网高并发的场景，常见的架构思路有负载均衡、异步处理、 限流阀（throttle）、批量处理、数据分区、数据镜像、缓存系统、CDN、排队系统等。]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开放接口API安全性]]></title>
    <url>%2F2018%2F01%2F15%2Finformation-safety-api%2F</url>
    <content type="text"><![CDATA[服务端对外开放API接口，尤其对移动应用开放接口的时候，更需要关注接口安全性的问题，要确保应用APP与API之间的安全通信，防止数据被恶意篡改等攻击。 安全考量点Token机制开放接口时最基本需要考虑到接口不应该被别人随意访问，而我也不能随意访问到其他用户的数据，从而保证用户与用户之间的数据隔离。这个时候我们就有必要引入Token机制了。具体的做法： 在用户成功登录时，系统可以返回客户端一个Token，后续客户端调用服务端的接口，都需要带上Token，而服务端需要校验客户端Token的合法性。Token不一致的情况下，服务端需要拦截该请求。 对数据进行校验服务端从某种层面来说需要验证接受到数据是否和客户端发来的数据是否一致，要验证数据在传输过程中有没有被注入攻击。这时候客户端和服务端就有必要做签名和验签。具体做法： 客户端对所有请求服务端接口参数做加密生成签名，并将签名作为请求参数一并传到服务端，服务端接受到请求同时要做验签的操作，对称加密对请求参数生成签名，并与客户端传过来的签名进行比对，如签名不一致，服务端需要拦截该请求 过载保护服务端仍然需要识别一些恶意请求，防止接口被一些丧心病狂的人玩坏。对接口访问频率设置一定阈值，对超过阈值的请求进行屏蔽及预警。 异常封装服务端需要构建异常统一处理框架，将服务可能出现的异常做统一封装，返回固定的code与msg，防止程序堆栈信息暴露。 HTTPSHTTPS能够有效防止中间人攻击，有效保证接口不被劫持，对数据窃取篡改做了安全防范。但HTTP升级HTTPS会带来更多的握手，而握手中的运算会带来更多的性能消耗。这也是不得不考虑的问题。 总得来说，我们非常有必要在设计接口的同时考虑安全性的问题，根据业务特点，采用的安全策略也不全相同。当然大多数安全策略更多的都是提高安全门槛，并不能保证100%的安全，但该做的还是不能少。 Token签名sign的设计与实现对于敏感的api接口，需使用https协议,https是在http超文本传输协议加入SSL层，它在网络间通信是加密的，所以需要加密证书。https协议需要ca证书，一般需要交费。 签名的设计原理：用户登录后向服务器提供用户认证信息（如账户和密码），服务器认证完后给客户端返回一个Token令牌，用户再次获取信息时，带上此令牌，如果令牌正取，则返回数据。对于获取Token信息后，访问用户相关接口，客户端请求的url需要带上如下参数： 时间戳: timestampToken令牌: token 然后将所有用户请求的参数按照字母排序（包括timestamp，token），然后使用MD5（可以加点盐）或者SHA1加密，全部大写，生成sign签名，这就是所说的url签名算法。然后登陆后每次调用用户信息时，带上sign，timestamp，token参数。例如：原请求https://www.andy.cn/api/user/update/info.shtml?city=北京 （post和get都一样，对所有参数排序加密），加上时间戳和token后https://www.andy.cn/api/user/update/info.shtml?city=北京&amp;timestamp=12445323134&amp;token=wefkfjdskfjewfjkjfdfnc，然后根据url参数生成sign，最终的请求如https://www.andy.cn/api/user/update/info.shtml?city=北京×tamp=12445323134&amp;token=wefkfjdskfjewfjkjfdfnc&amp;sign=FDK2434JKJFD334FDF2，其最终的原理是减小明文的暴露次数，保证数据安全的访问。 具体实现API请求客户端想服务器端第一次发送用用户认证信息（用户名和密码），服务器端请求到改请求后，验证用户信息是否正确。如果正确：则返回一个唯一不重复的字符串（一般为UUID），然后在Redis（任意缓存服务器）中维护Token —&gt; Uid的用户信息关系，以便其他API对token的校验。如果错误：则返回错误码。 服务器设计一个url请求拦截规则: 判断是否包含timestamp，token，sign参数，如果不含有返回错误码。 判断服务器接到请求的时间和参数中的时间戳是否相差很长一段时间（时间自定义如半个小时），如果超过则说明该url已经过期（如果url被盗，他改变了时间戳，但是会导致sign签名不相等）。 判断token是否有效，根据请求过来的token，查询redis缓存中的uid，如果获取不到这说明该token已过期。 根据用户请求的url参数，服务器端按照同样的规则生成sign签名，对比签名看是否相等，相等则放行。（url签名也无法100%保证其安全，也可以通过公钥AES对数据和url加密，但这样如果无法确保公钥丢失，所以签名只是很大程 度上保证安全）。 此url拦截只需对获取身份认证的url放行（如登陆url），剩余所有的url都需拦截。 对于用户登录我们需要创建token–uid的关系，用户退出时需要需删除token –&gt; uid的关系。]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java - ConcurrentHashMap]]></title>
    <url>%2F2018%2F01%2F15%2Fjava-concurrenthashmap%2F</url>
    <content type="text"><![CDATA[方法getOrDefault如果指定的key存在，则返回该key对应的value，如果不存在，则返回指定的值。例子如下1System.out.println(map.getOrDefault(4, "d")); forEach遍历Map中的所有Entry, 对key, value进行处理， 接收参数 (K, V) -&gt; void, 例子如下12// 输出1a, 2b, 3cmap.forEach((key, value) -&gt; System.out.println(key + value)); replaceAll替换Map中所有Entry的value值，这个值由旧的key和value计算得出，接收参数 (K, V) -&gt; V, 类似如下代码12for (Map.Entry&lt;K, V&gt; entry : map.entrySet()) entry.setValue(function.apply(entry.getKey(), entry.getValue())); 示例如下：123map.replaceAll((key, value) -&gt; (key + 1) + value);// 输出 12a 23b 34cmap.forEach((key, value) -&gt; System.out.println(key + value)); putIfAbsentputIfAbsent用来原子性的获取键值，如果键值存在则返回原来的值，不存在设置为给定的值后返回null，类似如下代码：1234V v = map.get(key);if (v == null) v = map.put(key, value);return v; 这里需要注意的是，如果改key已经有值，则总是返回旧的值，并不会将你调用时传入的第二个参数set进去，这个方法通常用来初始化键值。示例代码如下：123456map.putIfAbsent(3, "d");map.putIfAbsent(4, "d");// 输出 cSystem.out.println(map.get(3));// 输出 dSystem.out.println(map.get(4)); remove接收2个参数，key和value，如果key关联的value值与指定的value值相等（equals)，则删除这个元素，类似代码如下：12345if (map.containsKey(key) &amp;&amp; Objects.equals(map.get(key), value)) &#123; map.remove(key); return true;&#125; else return false; 示例代码如下：123456map.remove(1, "b");// 未删除成功， 输出 aSystem.out.println(map.get(1));map.remove(2, "b");// 删除成功，输出 nullSystem.out.println(map.get(2)); 在多线程编程中，可以根据remove的结果（boolean）判断是否删除成功，从而进行业务处理，这个删除方法是线程安全的。 replace(K key, V oldValue, V newValue)如果key关联的值与指定的oldValue的值相等，则替换成新的newValue，类似代码如下：12345if (map.containsKey(key) &amp;&amp; Objects.equals(map.get(key), value)) &#123; map.put(key, newValue); return true;&#125; else return false; 示例代码如下123456map.replace(3, "a", "z");// 未替换成功，输出 cSystem.out.println(map.get(3));map.replace(1, "a", "z");// 替换成功， 输出 zSystem.out.println(map.get(1)); replace(K key, V value)如果map中存在key，则替换成value值，否则返回null, 类似代码如下:1234if (map.containsKey(key)) &#123; return map.put(key, value);&#125; else return null; 示例代码如下：12345678// 输出旧的值， aSystem.out.println(map.replace(1, "aa"));// 替换成功，输出新的值， aaSystem.out.println(map.get(1));// 不存在key为4， 输出 nullSystem.out.println(map.replace(4, "d"));// 不存在key为4， 输出 nullSystem.out.println(map.get(4)); computeIfAbsent如果指定的key不存在，则通过指定的K -&gt; V计算出新的值设置为key的值，类似代码如下：12345if (map.get(key) == null) &#123; V newValue = mappingFunction.apply(key); if (newValue != null) map.put(key, newValue);&#125; 示例代码如下：123456map.computeIfAbsent(1, key -&gt; key + " computed");// 存在key为1，则不进行计算，输出值 aSystem.out.println(map.get(1));map.computeIfAbsent(4, key -&gt; key + " computed");// 不存在key为4，则进行计算，输出值 4 computedSystem.out.println(map.get(4)); computeIfPresent如果指定的key存在，则根据旧的key和value计算新的值newValue, 如果newValue不为null，则设置key新的值为newValue, 如果newValue为null, 则删除该key的值，类似代码如下：12345678if (map.get(key) != null) &#123; V oldValue = map.get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) map.put(key, newValue); else map.remove(key);&#125; 示例代码如下：123456map.computeIfPresent(1, (key, value) -&gt; (key + 1) + value);// 存在key为1， 则根据旧的key和value计算新的值，输出 2aSystem.out.println(map.get(1));map.computeIfPresent(2, (key, value) -&gt; null);// 存在key为2， 根据旧的key和value计算得到null，删除该值，输出 nullSystem.out.println(map.get(2)); computecompute方法是computeIfAbsent与computeIfPresent的综合体。 merge(K key, V value, BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction)如果指定的key不存在，则设置指定的value值，否则根据key的旧的值oldvalue，value计算出新的值newValue, 如果newValue为null, 则删除该key，否则设置key的新值newValue。类似如下代码：1234567V oldValue = map.get(key);V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value);if (newValue == null) map.remove(key);else map.put(key, newValue); 示例代码如下： 123456// 存在key为1， 输出 a mergeSystem.out.println(map.merge(1, " merge", (oldValue, newValue) -&gt; oldValue + newValue));// 新值为null，删除key，输出 nullSystem.out.println(map.merge(1, " merge", (oldValue, newValue) -&gt; null));// 输出 " merge"System.out.println(map.merge(4, " merge", (oldValue, newValue) -&gt; oldValue + newValue));]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[正则表达式必知必会]]></title>
    <url>%2F2018%2F01%2F11%2Fregular-expressions%2F</url>
    <content type="text"><![CDATA[正则表达式是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。正则表达式的语法中的关键概念有：元字符、量词、字符边界、选择表达式、分组与引用等。 元字符 代码 说明 . 匹配除换行符以外的任意字符 \w 匹配字母或数字或下划线或汉字 \s 匹配任意的空白符 \d 匹配数字 \b 匹配单词的开始或结束 ^ 匹配字符串的开始 $ 匹配字符串的结束 转义字符\是转义字符，其后面的字符会代表不同的意思，转义字符主要有三个作用： 是为了匹配不方便显示的特殊字符，比如换行，tab符号等 正则中预先定义了一些代表特殊意义的字符，比如\w等 在正则中某些字符有特殊含义(比如下面说到的)，转义字符可以让其显示自身的含义 下面是常用转义字符列表： 转义字符 含义 \n 匹配换行符 \r 匹配回车符 \t 匹配制表符，也就是tab键 \v 匹配垂直制表符 \x20 20是2位16进制数字，代表对应的字符 \u002B 002B是4位16进制数字，代表对应的字符 \u002B 002B是4位16进制数字，代表对应的字符 \w 匹配任何一个字母或者数字或者下划线 \W 匹配任何一个字母或者数字或者下划线以外的字符 \s 匹配空白字符，如空格，tab等 \S 匹配非空白字符 \d 匹配数字字符，0~9 \D 匹配非数字字符 \b 匹配单词的边界 \B 匹配非单词边界 \ 匹配\本身 []有时我们需要匹配一类字符，字符集可以实现这个功能，字符集的语法用[]分隔，下面的代码能够匹配a或b或c：1[abc] 如果要表示字符很多，可以使用-表示一个范围内的字符，下面两个功能相同：12[0123456789][0-9] 在前面添加^，可表示非的意思，下面的代码能够匹配abc之外的任意字符：1[^abc] 其实正则还内置了一些字符集，在上面的转义字符有提到，下面给出内置字符集对应的自定义字符集： 字符 说明 . 匹配除了换行符（\n）以外的任意一个字符 = [^\n] \w [0-9a-zA-Z_] \W [^0-9a-zA-Z_] \s [ \t\n\v] \S [^ \t\n\v] \d [0-9] \D [^0-9] 量词如果我们有三个苹果，我们可以说自己有个3个苹果，也可以说有一个苹果，一个苹果，一个苹果，每种语言都有量词的概念。如果需要匹配多次某个字符，正则也提供了量词的功能，正则中的量词有多个，如?、+、*、{n}、{m,n}、{m,} 量词 释义 {n} 匹配n次，比如a{2}，匹配aa {m, n} 匹配m-n次，优先匹配n次，比如a{1,3}，可以匹配aaa、aa、a {m,} 匹配m-∞次，优先匹配∞次，比如a{1,}，可以匹配aaaa… ? 匹配0次或1次，优先匹配1次，相当于{0,1} + 匹配1-n次，优先匹配n次，相当于{1,} * 匹配0-n次，优先匹配n次，相当于{0,} 正则默认和人心一样是贪婪的，也就是常说的贪婪模式，凡是表示范围的量词，都优先匹配上限而不是下限:1a&#123;1, 3&#125; // 匹配字符串&apos;aaa&apos;的话，会匹配aaa而不是a 有时候这不是我们想要的结果，可以在量词后面加上?，就可以开启非贪婪模式1a&#123;1, 3&#125;? // 匹配字符串&apos;aaa&apos;的话，会匹配a而不是aaa 字符边界有时我们会有边界的匹配要求，比如以xxx开头，以xxx结尾。^在[]外表示匹配开头的意思：1^abc // 可以匹配abc，但是不能匹配aabc $表示匹配结尾的意思:1abc$ // 可以匹配abc，但是不能匹配abcc 上面提到的\b表示单词的边界：1abc\b // 可以匹配 abc ，但是不能匹配 abcc 选择表达式有时我们想匹配x或者y，如果x和y是单个字符，可以使用字符集，[abc]可以匹配a或b或c，如果x和y是多个字符，字符集就无能为力了，此时就要用到分组。正则中用|来表示分组，a|b表示匹配a或者b的意思：1123|456|789 // 匹配 123 或 456 或 789 分组分组是正则中非常强大的一个功能，可以让上面提到的量词作用于一组字符，而非单个字符，分组的语法是圆括号包裹(xxx)：1(abc)&#123;2&#125; // 匹配abcabc 分组不能放在[]中，分组中还可以使用选择表达式：1(123|456)&#123;2&#125; // 匹配 123123、456456、123456、456123 和分组相关的概念还有一个捕获分组和非捕获分组，分组默认都是捕获的，在分组的(后面添加?:可以让分组变为非捕获分组，非捕获分组可以提高性能和简化逻辑：12&apos;123&apos;.match(/(?:123)/) // 返回 [&apos;123&apos;]&apos;123&apos;.match(/(123)/) // 返回 [&apos;123&apos;, &apos;123&apos;] 引用和分组相关的另一个概念是引用，比如在匹配html标签时，通常希望&lt;xxx&gt;&lt;/xxx&gt;后面的xxx能够和前面保持一致。引用的语法是\数字，数字代表引用前面第几个捕获分组，注意非捕获分组不能被引用：1&lt;([a-z]+)&gt;&lt;\/\1&gt; // 可以匹配 `&lt;span&gt;&lt;/span&gt;` 或 `&lt;div&gt;&lt;/div&gt;`等 预搜索如果你想匹配xxx前不能是yyy，或者xxx后不能是yyy，那就要用到预搜索，js只支持正向预搜索，也就是xxx后面必须是yyy，或者xxx后面不能是yyy：121(?=2) // 可以匹配12，不能匹配221(?!2) // 可有匹配22，不能匹配12 (?:pattern) 匹配 pattern 但不获取匹配结果，这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 (|) 来组合一个模式的各个部分是很有用。例如， &#39;industr(?:y|ies) 就是一个比 &#39;industry|industries&#39; 更简略的表达式。 (?=pattern) 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如， &#39;Windows (?=95|98|NT|2000)&#39; 能匹配 &quot;Windows 2000&quot; 中的 &quot;Windows&quot; ，但不能匹配 &quot;Windows 3.1&quot; 中的 “Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern) 负向预查，在任 何不匹配的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如&#39;Windows (?!95|98|NT|2000)&#39; 能匹配 &quot;Windows 3.1&quot; 中的 &quot;Windows&quot;，但不能匹配 &quot;Windows 2000&quot; 中的 &quot;Windows&quot;。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 修饰符默认正则是区分大小写，这可能并不是我们想要的，正则提供了修饰符的功能，修复的语法如下：1/xxx/gi // 最后面的g和i就是两个修饰符 g 正则遇到第一个匹配的字符就会结束，加上全局修复符，可以让其匹配到结束i 正则默认是区分大小写的，i可以忽略大小写m 正则默认情况下，^和$只能匹配字符串的开始和结尾，m修饰符可以让^和$匹配行首和行尾 12345/jing$/ // 能够匹配 &apos;yanhaijing，不能匹配 &apos;yanhaijing\n&apos;/jing$/m // 能够匹配 &apos;yanhaijing， 能够匹配 &apos;yanhaijing\n&apos;/^jing/ // 能够匹配 &apos;jing&apos;，不能匹配 &apos;\njing&apos;/^jing/m // 能够匹配 &apos;jing&apos;，能够匹配 &apos;\njing&apos;]]></content>
      <tags>
        <tag>软件开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[善用佳软]]></title>
    <url>%2F2018%2F01%2F05%2Fuse-good-software%2F</url>
    <content type="text"><![CDATA[屏幕录像 软件名称 开源 支持平台 其他说明 FSCapture 否 windows 自带视频录制功能 Bandicam 否 windows Open Broadcaster Software (OBS) 开源 windows、mac、linux ScreenToGif 开源 windows GIF录制]]></content>
      <categories>
        <category>日常工作</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JDBC超时时间]]></title>
    <url>%2F2018%2F01%2F02%2Fjava-jdbc-timeout%2F</url>
    <content type="text"><![CDATA[“超时”在系统设计中是很重要的一块，有很多种超时，如服务超时、数据库连接超时、写入超时、读取超时，涉及到的设计点包括重试策略、显示策略、错误处理策略等，本文主要讨论数据库超时的方方面面、 数据库超时数据库超时涉及到的超时面有：JDBC超时、连接池超时、MyBatis查询超时（Statement Timeout）、事务超时、Socket超时。 JDBC原理JDBC(Java Database Connectivity：Java访问数据库的解决方案)是Java应用程序访问数据库的里程碑式解决方案。Java研发者希望用相同的方式访问不同的数据库，以实现与具体数据库无关的Java操作界面。JDBC定义了一套标准接口，即访问数据库的通用API，不同的数据库厂商根据各自数据库的特点去实现这些接口。 JDBC接口及数据库厂商实现JDBC中定义了一些接口： 驱动管理：DriverManager 连接接口：Connection、DatabasemetaData 语句对象接口：Statement、PreparedStatement、CallableStatement 结果集接口：ResultSet、ResultSetMetaData JDBC工作原理JDBC只定义接口，具体实现由各个数据库厂商负责。程序员使用时只需要调用接口，实际调用的是底层数据库厂商的实现部分。 JDBC访问数据库的工作过程： 加载驱动，建立连接 创建语句对象 执行SQL语句 处理结果集 关闭连接 Driver接口及驱动类加载要使用JDBC接口，需要先将对应数据库的实现部分（驱动）加载进来。驱动类加载方式（Oracle）：1Class.forName("oracle.jdbc.driver.OracleDriver"); 这条语句的含义是：装载驱动类，驱动类通过static块实现在DriverManager中的“自动注册”。 Connection接口Connection接口负责应用程序对数据库的连接，在加载驱动之后，使用url、username、password三个参数，创建到具体数据库的连接。12345Class.forName("oracle.jdbc.OracleDriver")//根据url连接参数，找到与之匹配的Driver对象，调用其方法获取连接Connection conn = DriverManager.getConnection("jdbc:oracle:thin:@192.168.0.26:1521:tarena","openlab","open123"); 需要注意的是:Connection只是接口，真正的实现是由数据库厂商提供的驱动包完成的。 Statement接口Statement接口用来处理发送到数据库的SQL语句对象，通过Connection对象创建。主要有三个常用方法：1234567Statement stmt=conn.createStatement();//1.execute方法，如果执行的sql是查询语句且有结果集则返回true，如果是非查询语句或者没有结果集，返回falseboolean flag = stmt.execute(sql);//2.执行查询语句，返回结果集ResultSetrs = stmt.executeQuery(sql);//3.执行DML语句，返回影响的记录数int flag = stmt.executeUpdate(sql); ResultSet接口执行查询SQL语句后返回的结果集，由ResultSet接口接收。常用处理方式：遍历 / 判断是否有结果（登录）。123456String sql = "select * from emp";ResultSetrs = stmt.executeQuery(sql);while (rs.next()) &#123; System.out.println(rs.getInt("empno")+",“ +rs.getString("ename") );&#125; 查询的结果存放在ResultSet对象的一系列行中，指针的最初位置在行首，使用next()方法用来在行间移动，getXXX()方法用来取得字段的内容。 连接池技术数据库连接的建立及关闭资源消耗巨大。传统数据库访问方式：一次数据库访问对应一个物理连接,每次操作数据库都要打开、关闭该物理连接, 系统性能严重受损。 解决方案：数据库连接池（Connection Pool） 系统初始运行时，主动建立足够的连接，组成一个池.每次应用程序请求数据库连接时，无需重新打开连接，而是从池中取出已有的连接，使用完后，不再关闭，而是归还。 连接池中连接的释放与使用原则： 应用启动时，创建初始化数目的连接 当申请时无连接可用或者达到指定的最小连接数，按增量参数值创建新的连接 为确保连接池中最小的连接数的策略： 动态检查：定时检查连接池，一旦发现数量小于最小连接数，则补充相应的新连接，保证连接池正常运转 静态检查：空闲连接不足时，系统才检测是否达到最小连接数 按需分配，用过归还，超时归还 连接池也只是JDBC中定义的接口，具体实现由厂商实完成。 JDBC超时恰当的JDBC超时设置能够有效地减少服务失效的时间。本文将对数据库的各种超时设置及其设置方法做介绍。 真实案例：应用服务器在遭到DDos攻击后无法响应 在遭到DDos攻击后，整个服务都垮掉了。由于第四层交换机不堪重负，网络变得无法连接，从而导致业务系统也无法正常运转。安全组很快屏蔽了所有的DDos攻击，并恢复了网络，但业务系统却还是无法工作。 通过分析系统的thread dump发现，业务系统停在了JDBC API的调用上。20分钟后，系统仍处于WAITING状态，无法响应。30分钟后，系统抛出异常，服务恢复正常。 为什么我们明明将query timeout设置成了3秒，系统却持续了30分钟的WAITING状态？为什么30分钟后系统又恢复正常了？ 当你对理解了JDBC的超时设置后，就能找到问题的答案。 为什么我们要了解JDBC？ 当遇到性能问题或系统出错时，业务系统和数据库通常是我们最关心的两个部分。在公司里，这两个部分是交由两个不同的部门来负责的，因此各个部门都会集中精力地在自身领域内寻找问题，这样的话，在业务系统和数据库之间的部分就会成为一个盲区。对于Java应用而言，这个盲区就是DBCP数据库连接池和JDBC，本文将集中介绍JDBC。 什么是JDBC？ JDBC是Java应用中用来连接关系型数据库的标准API。Sun公司一共定义了4种类型的JDBC，我们主要使用的是第4种，该类型的Driver完全由Java代码实现，通过使用socket与数据库进行通信。 第4种类型的JDBC通过socket对字节流进行处理，因此也会有一些基本网络操作，类似于HttpClient这种用于网络操作的代码库。当在网络操作中遇到问题的时候，将会消耗大量的cpu资源，并且失去响应超时。如果你之前用过HttpClient，那么你一定遇到过未设置timeout造成的错误。同样，第4种类型的JDBC，若没有合理地设置socket timeout，也会有相同的错误——连接被阻塞。 接下来，就让我们来学习一下如何正确地设置socket timeout，以及需要考虑的问题。 应用与数据库间的timeout层级: 上图展示了简化后应用与数据库间的timeout层级。（译者注：WAS/BLOC是作者公司的具体应用名称，无需深究） 高级别的timeout依赖于低级别的timeout，只有当低级别的timeout无误时，高级别的timeout才能确保正常。例如，当socket timeout出现问题时，高级别的statement timeout和transaction timeout都将失效。 我们收到的很多评论中提到： 即使设置了statement timeout，当网络出错时，应用也无法从错误中恢复。statement timeout无法处理网络连接失败时的超时，它能做的仅仅是限制statement的操作时间。网络连接失败时的timeout必须交由JDBC来处理。 JDBC的socket timeout会受到操作系统socket timeout设置的影响，这就解释了为什么在之前的案例中，JDBC连接会在网络出错后阻塞30分钟，然后又奇迹般恢复，即使我们并没有对JDBC的socket timeout进行设置。 DBCP连接池位于图2的左侧，你会发现timeout层级与DBCP是相互独立的。DBCP负责的是数据库连接的创建和管理，并不干涉timeout的处理。当连接在DBCP中创建，或是DBCP发送校验query检查连接有效性的时候，socket timeout将会影响这些过程，但并不直接对应用造成影响。 当在应用中调用DBCP的getConnection()方法时，你可以设置获取数据库连接的超时时间，但是这和JDBC的timeout毫不相关。 什么是Transaction Timeout？transaction timeout一般存在于框架（Spring, EJB）或应用级。transaction timeout或许是个相对陌生的概念，简单地说，transaction timeout就是“statement Timeout * N（需要执行的statement数量） + @（垃圾回收等其他时间）”。transaction timeout用来限制执行statement的总时长。 例如，假设执行一个statement需要0.1秒，那么执行少量statement不会有什么问题，但若是要执行100,000个statement则需要10,000秒（约7个小时）。这时，transaction timeout就派上用场了。EJB CMT (Container Managed Transaction)就是一种典型的实现，它提供了多种方法供开发者选择。但我们并不使用EJB，Spring的transaction timeout设置会更常用一些。在Spring中，你可以使用下面展示的XML或是在源码中使用@Transactional注解来进行设置。 123&lt;tx:attributes&gt; &lt;tx:method name="…" timeout="3"/&gt; &lt;/tx:attributes&gt; Spring提供的transaction timeout配置非常简单，它会记录每个事务的开始时间和消耗时间，当特定的事件发生时就会对消耗时间做校验，当超出timeout值时将抛出异常。 Spring中，数据库连接被保存在ThreadLocal里，这被称为事务同步（Transaction Synchronization），与此同时，事务的开始时间和消耗时间也被保存下来。当使用这种代理连接创建statement时，就会校验事务的消耗时间。EJB CMT的实现方式与之类似，其结构本身也十分简单。 当你选用的容器或框架并不支持transaction timeout这一特性，你可以考虑自己来实现。transaction timeout并没有标准的API。Lucy框架的1.5和1.6版本都不支持transaction timeout，但是你可以通过使用Spring的Transaction Manager来达到与之同样的效果。 假设某个事务中包含5个statement，每个statement的执行时间是200ms，其他业务逻辑的执行时间是100ms，那么transaction timeout至少应该设置为1,100ms（200 * 5 + 100）。 什么是Statement Timeout？statement timeout用来限制statement的执行时长，timeout的值通过调用JDBC的java.sql.Statement.setQueryTimeout(int timeout) API进行设置。不过现在开发者已经很少直接在代码中设置，而多是通过框架来进行设置。 以iBatis为例，statement timeout的默认值可以通过sql-map-config.xml中的defaultStatementTimeout 属性进行设置。同时，你还可以设置sqlmap中select，insert，update标签的timeout属性，从而对不同sql语句的超时时间进行独立的配置。 如果你使用的是Lucy1.5或1.6版本，通过设置queryTimeout属性可以在datasource层面对statement timeout进行设置。 statement timeout的具体值需要依据应用本身的特性而定，并没有可供推荐的配置。 JDBC的statement timeout处理过程 不同的关系型数据库，以及不同的JDBC驱动，其statement timeout处理过程会有所不同。其中，Oracle和MS SQLServer的处理相类似，MySQL和CUBRID类似。 Oracle JDBC Statement的QueryTimeout处理过程 通过调用Connection的createStatement()方法创建statement 调用Statement的executeQuery()方法； statement通过自身connection将query发送给Oracle数据库； statement在OracleTimeoutPollingThread（每个classloader一个）上进行注册； 达到超时时间； OracleTimeoutPollingThread调用OracleStatement的cancel()方法； 通过connection向正在执行的query发送cancel消息； JTDS (MS SQLServer) Statement的QueryTimeout处理过程 通过调用Connection的createStatement()方法创建statement； 调用Statement的executeQuery()方法； statement通过自身connection将query发送给MS SqlServer数据库； statement在TimerThread上进行注册； 达到超时时间； TimerThread调用JtdsStatement实例中的TsdCore.cancel()方法； 通过ConnectionJDBC向正在执行的query发送cancel消息； MySQL JDBC Statement的QueryTimeout处理过程 1. 通过调用Connection的createStatement()方法创建statement 2. 调用Statement的executeQuery()方法 3. statement通过自身connection将query发送给MySQL数据库 4. statement创建一个新的timeout-execution线程用于超时处理 5. 5.1版本后改为每个connection分配一个timeout-execution线程 6. 向timeout-execution线程进行注册 7. 达到超时时间 6. TimerThread调用JtdsStatement实例中的TsdCore.cancel()方法 7. timeout-execution线程创建一个和statement配置相同的connection 8. 使用新创建的connection向超时query发送cancel query（KILL QUERY “connectionId”） CUBRID JDBC Statement的QueryTimeout处理过程 1. 通过调用Connection的createStatement()方法创建statement 2. 调用Statement的executeQuery()方法 3. statement通过自身connection将query发送给CUBRID数据库 4. statement创建一个新的timeout-execution线程用于超时处理 5. 5.1版本后改为每个connection分配一个timeout-execution线程 6. 向timeout-execution线程进行注册 7. 达到超时时间 6. TimerThread调用JtdsStatement实例中的TsdCore.cancel()方法 7. timeout-execution线程创建一个和statement配置相同的connection 8. 使用新创建的connection向超时query发送cancel消息 什么是JDBC的socket timeout？ 第4种类型的JDBC使用socket与数据库连接，数据库并不对应用与数据库间的连接超时进行处理。 JDBC的socket timeout在数据库被突然停掉或是发生网络错误（由于设备故障等原因）时十分重要。由于TCP/IP的结构原因，socket没有办法探测到网络错误，因此应用也无法主动发现数据库连接断开。如果没有设置socket timeout的话，应用在数据库返回结果前会无期限地等下去，这种连接被称为dead connection。 为了避免dead connections，socket必须要有超时配置。socket timeout可以通过JDBC设置，socket timeout能够避免应用在发生网络错误时产生无休止等待的情况，缩短服务失效的时间。 不推荐使用socket timeout来限制statement的执行时长，因此socket timeout的值必须要高于statement timeout，否则，socket timeout将会先生效，这样statement timeout就变得毫无意义，也无法生效。 下面展示了socket timeout的两个设置项，不同的JDBC驱动其配置方式会有所不同。 socket连接时的timeout：通过Socket.connect(SocketAddress endpoint, int timeout)设置 socket读写时的timeout：通过Socket.setSoTimeout(int timeout)设置 通过查看CUBRID，MySQL，MS SQL Server (JTDS)和Oracle的JDBC驱动源码，我们发现所有的驱动内部都是使用上面的2个API来设置socket timeout的。 下面是不同驱动的socket timeout配置方式： JDBC Driver connectTimeout配置项 socketTimeout配置项 url格式 示例 MySQL Driver connectTimeout（默认值：0，单位：ms） socketTimeout（默认值：0，单位：ms） jdbc:mysql://[host:port],[host:port]…/[database][?propertyName1][=propertyValue1][&amp;propertyName2][=propertyValue2]… jdbc:mysql://x.x.x.x:3306/db?connectTimeout=60000&amp;socketTimeout=60000 MS-SQL DriverjTDS Driver loginTimeout（默认值：0，单位：s） socketTimeout（默认值：0，单位：s） jdbc:jtds:&lt;server_type&gt;://&lt;server&gt;[:&lt;port&gt;][/&lt;database&gt;][;&lt;property&gt;=&lt;value&gt;[;...]] jdbc:jtds:sqlserver://server:port/database;loginTimeout=60;socketTimeout=60 Oracle Thin Driver oracle.net.CONNECT_TIMEOUT（默认值：0，单位：ms） oracle.jdbc.ReadTimeout（默认值：0，单位：ms） 不支持通过url配置，只能通过OracleDatasource.setConnectionProperties() API设置，使用DBCP时可以调用BasicDatasource.setConnectionProperties()或BasicDatasource.addConnectionProperties()进行设置 CUBRID Thin Driver 无独立配置项（默认值：5,000，单位：ms） 无独立配置项（默认值：5,000，单位：ms） connectTimeout和socketTimeout的默认值为0时，timeout不生效。 除了调用DBCP的API以外，还可以通过properties属性进行配置。 通过properties属性进行配置时，需要传入key为“connectionProperties”的键值对，value的格式为“[propertyName=property;]*”。下面是iBatis中的properties配置。 123456&lt;transactionManager type="JDBC"&gt; &lt;dataSource type="com.nhncorp.lucy.db.DbcpDSFactory"&gt; … &lt;property name="connectionProperties" value="oracle.net.CONNECT_TIMEOUT=6000;oracle.jdbc.ReadTimeout=6000"/&gt; &lt;/dataSource&gt; &lt;/transactionManager&gt; 操作系统的socket timeout配置 如果不设置socket timeout或connect timeout，应用多数情况下是无法发现网络错误的。因此，当网络错误发生后，在连接重新连接成功或成功接收到数据之前，应用会无限制地等下去。但是，通过本文开篇处的实际案例我们发现，30分钟后应用的连接问题奇迹般的解决了，这是因为操作系统同样能够对socket timeout进行配置。公司的Linux服务器将socket timeout设置为了30分钟，从而会在操作系统的层面对网络连接做校验，因此即使JDBC的socket timeout设置为0，由网络错误造成的数据库连接问题的持续时间也不会超过30分钟。 通常，应用会在调用Socket.read()时由于网络问题被阻塞住，而很少在调用Socket.write()时进入waiting状态，这取决于网络构成和错误类型。当Socket.write()被调用时，数据被写入到操作系统内核的缓冲区，控制权立即回到应用手上。因此，一旦数据被写入内核缓冲区，Socket.write()调用就必然会成功。但是，如果系统内核缓冲区由于某种网络错误而满了的话，Socket.write()也会进入waiting状态。这种情况下，操作系统会尝试重新发包，当达到重试的时间限制时，将产生系统错误。在我们公司，重新发包的超时时间被设置为15分钟。 至此，我已经对JDBC的内部操作做了讲解，希望能够让大家学会如何正确的配置超时时间，从而减少错误的发生。 最后，我将列出一些常见的问题。 FAQ Q1. 我已经使用Statement.setQueryTimeout()方法设置了查询超时，但在网络出错时并没有产生作用。 查询超时仅在socket timeout生效的前提下才有效，它并不能用来解决外部的网络错误，要解决这种问题，必须设置JDBC的socket timeout。 Q2. transaction timeout，statement timeout和socket timeout和DBCP的配置有什么关系？ 当通过DBCP获取数据库连接时，除了DBCP获取连接时的waitTimeout配置以外，其他配置对JDBC没有什么影响。 Q3. 如果设置了JDBC的socket timeout，那DBCP连接池中处于IDLE状态的连接是否也会在达到超时时间后被关闭？ 不会。socket的设置只会在产生数据读写时生效，而不会对DBCP中的IDLE连接产生影响。当DBCP中发生新连接创建，老的IDLE连接被移除，或是连接有效性校验的时候，socket设置会对其产生一定的影响，但除非发生网络问题，否则影响很小。 Q4. socket timeout应该设置为多少？ 就像我在正文中提的那样，socket timeout必须高于statement timeout，但并没有什么推荐值。在发生网络错误的时候，socket timeout将会生效，但是再小心的配置也无法避免网络错误的发生，只是在网络错误发生后缩短服务失效的时间（如果网络恢复正常的话） Spring超时时间Spring事务测试spring-config.xml 12345678910&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/test?autoReconnect=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value=""/&gt; &lt;/bean&gt; &lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; 测试用例: 12345678910111213141516@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = "classpath:spring-config.xml") @TransactionConfiguration(transactionManager = "txManager", defaultRollback = false) @Transactional(timeout = 2) public class Timeout1Test &#123; @Autowired private DataSource ds; @Test public void testTimeout() throws InterruptedException &#123; System.out.println(System.currentTimeMillis()); JdbcTemplate jdbcTemplate = new JdbcTemplate(ds); jdbcTemplate.execute(" update test set name = name || '1'"); System.out.println(System.currentTimeMillis()); Thread.sleep(3000L); &#125; &#125; 我设置事务超时时间是2秒；但我事务肯定执行3秒以上；为什么没有起作用呢？ 这其实是对Spring实现的事务超时的错误认识。那首先分析下Spring事务超时实现吧。 分析在此我们分析下DataSourceTransactionManager；首先开启事物会调用其doBegin方法： 1234int timeout = determineTimeout(definition); if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) &#123; txObject.getConnectionHolder().setTimeoutInSeconds(timeout); &#125; 其中determineTimeout用来获取我们设置的事务超时时间；然后设置到ConnectionHolder对象上（其是ResourceHolder子类），接着看ResourceHolderSupport的setTimeoutInSeconds实现： 1234567public void setTimeoutInSeconds(int seconds) &#123; setTimeoutInMillis(seconds * 1000); &#125; public void setTimeoutInMillis(long millis) &#123; this.deadline = new Date(System.currentTimeMillis() + millis); &#125; 大家可以看到，其会设置一个deadline时间；用来判断事务超时时间的；那什么时候调用呢？首先检查该类中的代码，会发现： 123456789101112131415161718192021public int getTimeToLiveInSeconds() &#123; double diff = ((double) getTimeToLiveInMillis()) / 1000; int secs = (int) Math.ceil(diff); checkTransactionTimeout(secs &lt;= 0); return secs; &#125; public long getTimeToLiveInMillis() throws TransactionTimedOutException&#123; if (this.deadline == null) &#123; throw new IllegalStateException("No timeout specified for this resource holder"); &#125; long timeToLive = this.deadline.getTime() - System.currentTimeMillis(); checkTransactionTimeout(timeToLive &lt;= 0); return timeToLive; &#125; private void checkTransactionTimeout(boolean deadlineReached) throws TransactionTimedOutException &#123; if (deadlineReached) &#123; setRollbackOnly(); throw new TransactionTimedOutException("Transaction timed out: deadline was " + this.deadline); &#125; &#125; 会发现在调用getTimeToLiveInSeconds和getTimeToLiveInMillis，会检查是否超时，如果超时设置事务回滚，并抛出TransactionTimedOutException异常。到此我们只要找到调用它们的位置就好了，那什么地方调用的它们呢？ 最简单的办法使用如“IntelliJ IDEA”中的“Find Usages”找到get*的使用地方；会发现： DataSourceUtils.applyTransactionTimeout会调用DataSourceUtils.applyTimeout，DataSourceUtils.applyTimeout代码如下： 12345678910111213public static void applyTimeout(Statement stmt, DataSource dataSource, int timeout) throws SQLException &#123; Assert.notNull(stmt, "No Statement specified"); Assert.notNull(dataSource, "No DataSource specified"); ConnectionHolder holder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); if (holder != null &amp;&amp; holder.hasTimeout()) &#123; // Remaining transaction timeout overrides specified value. stmt.setQueryTimeout(holder.getTimeToLiveInSeconds()); &#125; else if (timeout &gt; 0) &#123; // No current transaction timeout -&gt; apply specified value. stmt.setQueryTimeout(timeout); &#125; &#125; 其中其在stmt.setQueryTimeout(holder.getTimeToLiveInSeconds());中会调用getTimeToLiveInSeconds，此时就会检查事务是否超时； 然后在JdbcTemplate中，执行sql之前，会调用其applyStatementSettings：其会调用DataSourceUtils.applyTimeout(stmt, getDataSource(), getQueryTimeout());设置超时时间；具体可以看其源码； 到此我们知道了在JdbcTemplate拿到Statement之后，执行之前会设置其queryTimeout，具体意思参考Javadoc。 结论 Spring事务超时 = 事务开始时到最后一个Statement创建时时间 + 最后一个Statement的执行时超时时间（即其queryTimeout）。 因此假设事务超时时间设置为2秒；假设sql执行时间为1秒；如下调用是事务不超时的： 1234567public void testTimeout() throws InterruptedException &#123; System.out.println(System.currentTimeMillis()); JdbcTemplate jdbcTemplate = new JdbcTemplate(ds); jdbcTemplate.execute(" update test set hobby = hobby || '1'"); System.out.println(System.currentTimeMillis()); Thread.sleep(3000L); &#125; 而如下事务超时是起作用的： 1234567public void testTimeout() throws InterruptedException &#123; Thread.sleep(3000L); System.out.println(System.currentTimeMillis()); JdbcTemplate jdbcTemplate = new JdbcTemplate(ds); jdbcTemplate.execute(" update test set hobby = hobby || '1'"); System.out.println(System.currentTimeMillis()); &#125; 因此，不要忽略应用中如远程调用产生的事务时间和这个事务时间是否对您的事务产生影响。 提供AOP工具类监测Spring常见问题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196package com.sishuok.es.common.spring.utils;import org.aopalliance.aop.Advice;import org.springframework.aop.Advisor;import org.springframework.aop.TargetSource;import org.springframework.aop.framework.ProxyFactory;import org.springframework.aop.interceptor.AsyncExecutionInterceptor;import org.springframework.aop.support.AopUtils;import org.springframework.transaction.interceptor.TransactionInterceptor;import org.springframework.util.ReflectionUtils;import java.lang.reflect.Field;import java.lang.reflect.Proxy;/** * AOP代理工具类 * &lt;p&gt;User: Zhang Kaitao * &lt;p&gt;Date: 13-7-3 下午12:29 * &lt;p&gt;Version: 1.0 */public class AopProxyUtils &#123; /** * 是否代理了多次 * see http://jinnianshilongnian.iteye.com/blog/1894465 * @param proxy * @return */ public static boolean isMultipleProxy(Object proxy) &#123; try &#123; ProxyFactory proxyFactory = null; if(AopUtils.isJdkDynamicProxy(proxy)) &#123; proxyFactory = findJdkDynamicProxyFactory(proxy); &#125; if(AopUtils.isCglibProxy(proxy)) &#123; proxyFactory = findCglibProxyFactory(proxy); &#125; TargetSource targetSource = (TargetSource) ReflectionUtils.getField(ProxyFactory_targetSource_FIELD, proxyFactory); return AopUtils.isAopProxy(targetSource.getTarget()); &#125; catch (Exception e) &#123; throw new IllegalArgumentException("proxy args maybe not proxy with cglib or jdk dynamic proxy. this method not support", e); &#125; &#125; /** * 查看指定的代理对象是否 添加事务切面 * see http://jinnianshilongnian.iteye.com/blog/1850432 * @param proxy * @return */ public static boolean isTransactional(Object proxy) &#123; return hasAdvice(proxy, TransactionInterceptor.class); &#125; /** * 移除代理对象的异步调用支持 * @return */ public static void removeTransactional(Object proxy) &#123; removeAdvisor(proxy, TransactionInterceptor.class); &#125; /** * 是否是异步的代理 * @param proxy * @return */ public static boolean isAsync(Object proxy) &#123; return hasAdvice(proxy, AsyncExecutionInterceptor.class); &#125; /** * 移除代理对象的异步调用支持 * @return */ public static void removeAsync(Object proxy) &#123; removeAdvisor(proxy, AsyncExecutionInterceptor.class); &#125; private static void removeAdvisor(Object proxy, Class&lt;? extends Advice&gt; adviceClass) &#123; if(!AopUtils.isAopProxy(proxy)) &#123; return; &#125; ProxyFactory proxyFactory = null; if(AopUtils.isJdkDynamicProxy(proxy)) &#123; proxyFactory = findJdkDynamicProxyFactory(proxy); &#125; if(AopUtils.isCglibProxy(proxy)) &#123; proxyFactory = findCglibProxyFactory(proxy); &#125; Advisor[] advisors = proxyFactory.getAdvisors(); if(advisors == null || advisors.length == 0) &#123; return; &#125; for(Advisor advisor : advisors) &#123; if(adviceClass.isAssignableFrom(advisor.getAdvice().getClass())) &#123; proxyFactory.removeAdvisor(advisor); break; &#125; &#125; &#125; private static boolean hasAdvice(Object proxy, Class&lt;? extends Advice&gt; adviceClass) &#123; if(!AopUtils.isAopProxy(proxy)) &#123; return false; &#125; ProxyFactory proxyFactory = null; if(AopUtils.isJdkDynamicProxy(proxy)) &#123; proxyFactory = findJdkDynamicProxyFactory(proxy); &#125; if(AopUtils.isCglibProxy(proxy)) &#123; proxyFactory = findCglibProxyFactory(proxy); &#125; Advisor[] advisors = proxyFactory.getAdvisors(); if(advisors == null || advisors.length == 0) &#123; return false; &#125; for(Advisor advisor : advisors) &#123; if(adviceClass.isAssignableFrom(advisor.getAdvice().getClass())) &#123; return true; &#125; &#125; return false; &#125; private static ProxyFactory findJdkDynamicProxyFactory(final Object proxy) &#123; Object jdkDynamicAopProxy = ReflectionUtils.getField(JdkDynamicProxy_h_FIELD, proxy); return (ProxyFactory) ReflectionUtils.getField(JdkDynamicAopProxy_advised_FIELD, jdkDynamicAopProxy); &#125; private static ProxyFactory findCglibProxyFactory(final Object proxy) &#123; Field field = ReflectionUtils.findField(proxy.getClass(), "CGLIB$CALLBACK_0"); ReflectionUtils.makeAccessible(field); Object CGLIB$CALLBACK_0 = ReflectionUtils.getField(field, proxy); return (ProxyFactory) ReflectionUtils.getField(CglibAopProxy$DynamicAdvisedInterceptor_advised_FIELD, CGLIB$CALLBACK_0); &#125; ///////////////////////////////////内部使用的反射 静态字段/////////////////////////////////// //JDK动态代理 字段相关 private static Field JdkDynamicProxy_h_FIELD; private static Class JdkDynamicAopProxy_CLASS; private static Field JdkDynamicAopProxy_advised_FIELD; //CGLIB代理 相关字段 private static Class CglibAopProxy_CLASS; private static Class CglibAopProxy$DynamicAdvisedInterceptor_CLASS; private static Field CglibAopProxy$DynamicAdvisedInterceptor_advised_FIELD; //ProxyFactory 相关字段 private static Class ProxyFactory_CLASS; private static Field ProxyFactory_targetSource_FIELD; static &#123; JdkDynamicProxy_h_FIELD = ReflectionUtils.findField(Proxy.class, "h"); ReflectionUtils.makeAccessible(JdkDynamicProxy_h_FIELD); try &#123; JdkDynamicAopProxy_CLASS = Class.forName("org.springframework.aop.framework.JdkDynamicAopProxy"); JdkDynamicAopProxy_advised_FIELD = ReflectionUtils.findField(JdkDynamicAopProxy_CLASS, "advised"); ReflectionUtils.makeAccessible(JdkDynamicAopProxy_advised_FIELD); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); /*ignore*/ &#125; try &#123; CglibAopProxy_CLASS = Class.forName("org.springframework.aop.framework.CglibAopProxy"); CglibAopProxy$DynamicAdvisedInterceptor_CLASS = Class.forName("org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor"); CglibAopProxy$DynamicAdvisedInterceptor_advised_FIELD = ReflectionUtils.findField(CglibAopProxy$DynamicAdvisedInterceptor_CLASS, "advised"); ReflectionUtils.makeAccessible(CglibAopProxy$DynamicAdvisedInterceptor_advised_FIELD); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); /*ignore*/ &#125; ProxyFactory_CLASS = ProxyFactory.class; ProxyFactory_targetSource_FIELD = ReflectionUtils.findField(ProxyFactory_CLASS, "targetSource"); ReflectionUtils.makeAccessible(ProxyFactory_targetSource_FIELD); &#125;&#125;]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
      <tags>
        <tag>基础原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Percona XtraBackup]]></title>
    <url>%2F2017%2F12%2F25%2Fpercona-xtrabackup%2F</url>
    <content type="text"><![CDATA[Percona XtraBackup是一个相对完美的免费开源数据备份工具，支持在线无锁表同步复制和可并行高效率的安全备份恢复。 备份原理Percona XtraBackup 基于InnoDB引擎的故障恢复功能。它拷贝InnoDB的数据文件，但是数据文件内存的数据并不是一致的；但是通过 XtraBackup 执行故障恢复确保了数据的一致性。Percona XtraBackup 保证数据一致性 是通过InnoDB的redo log（也叫事务日志 transaction log）。redo log记录了InnoDB 数据的每次改变。当InnoDB（MySQL）启动，它检查数据文件和事务日志（redo / transaction log），然后执行如下两步: 应用已经提交的事务 回滚已经修改但是没有提交的事务 Percona XtraBackup 备份过程如下： 备份InnoDB引擎：当 Percona XtraBackup 开始工作，它记录所有 LSN （ log sequence number ），然后拷贝所有数据文件。拷贝数据文件的同时， Percona XtraBackup 的一个后台进程监测 事务日志（redo / transaction log），然后从事务日志中拷贝改变的部分。由于事务日志（log/transaction log）写日志采取round-robin方式，短时间事务日志就能够被重用，所以Percona XtraBackup 必须一致保持监测事务日志并拷贝改变部分。Percona XtraBackup 从执行开始，就必须记录每一条事务日志，不然无法保证一致性和完整性。 备份其他存储引擎（如MyISAM）：Percona XtraBackup 备份 InnoDB/XtraDB 数据文件和事务日志完毕后。使用 FLUSH TABLES WITH READ LOCK 锁，阻止对MyISAM的DML操作,（从MySQL 5.6开始），然后备份拷贝MyISAM等non-InnoDB的相关文件，如.frm, .MRG, .MYD, .MYI,.TRG, .TRN, .ARM, .ARZ, .CSM, .CSV, .par, 和 .opt 文件。 注意，备份MyISAM时，执行FLUSH TABLES WITH READ LOCK ，并不会影响InnoDB。. 安装与使用官方网站：https://www.percona.com/downloads/XtraBackup/LATEST/，下载适合你的平台软件，然后安装，需要注意的是如果下载的是RPM包或者源码，需要手动解决依赖的相关问题(报错:Transaction Check Error:)，推荐使用Percona仓库安装：12345yum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpmyum list | grep perconayum install percona-xtrabackup-24# 用于解压备份文件yum install qpress 全量备份：123456# 备份并压缩xtrabackup --backup --compress --target-dir=/backup_store/db_back/# 解压，必须解压才能--preparextrabackup --backup --decompress --target-dir=/backup_store/db_back/# prepare之前，数据文件是不一致的，因为它们在不同时间点被备份因此，--prepare会使所有数据文件的步调达成一致xtrabackup --prepare --target-dir=/backup_store/db_back/ 增量备份：12 基于XtraBackup搭建主从12345678910111213141516171819202122232425262728293031323334353637383940414243#原有主数据库版本mysql -Vmysql Ver 14.14 Distrib 5.5.31, for Linux (x86_64) using readline 5.1#迁移从数据库版本mysql -Vmysql Ver 14.14 Distrib 5.6.25, for linux-glibc2.5 (x86_64) using EditLine wrapper#检查数据库引擎show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+#主从数据库同步注意点[mysqld]#主从之间的id不能相同server-id#启用二进制日志log-bin#一般在从库开启（可选）read_only#推荐使用InnoDB并做好相关配置#检查主从数据库状态mysql -S /tmp/mysql.sock -e "show global variables like 'server_id';"+---------------+-------+| Variable_name | Value |+---------------+-------+| server_id | 1 |+---------------+-------+mysql -S /tmp/mysql.sock -e "show global variables like 'log_bin';"+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+ 备份和恢复通常一般都直接使用innobackupex，因为它能同时备份InnoDB和MyISAM引擎的表。重点关注Slave_IO_Running和Slave_SQL_Runningd的状态是否为YES。12345678910111213141516171819202122232425262728293031323334353637383940414243#备份innobackupex --socket=/usr/local/var/mysql2/mysql2.sock --user=root --password --defaults-file=/etc/mysqld_multi.cnf --parallel=4 --database=passport /tmp/backup#保持事务一致性innobackupex --socket=/usr/local/var/mysql2/mysql2.sock --user=root --password --defaults-file=/etc/mysqld_multi.cnf --database=passport --apply-log /tmp/backup/2015-08-05_16-08-14#传输scp -r /tmp/backup/2015-08-05_16-08-14 10.10.16.24:/tmp/backup/ #恢复innobackupex --socket=/tmp/mysql.sock --user=root --password --defaults-file=/app/local/mysql/my.cnf --copy-back /tmp/backup/2015-08-05_16-08-14/#还原权限chown -R mysql:mysql /app/data/mysql/dataservice mysqld start/app/local/mysql/scripts/mysql_install_db --basedir=/app/local/mysql --datadir=/app/data/mysql/data --no-defaults --skip-name-resolve --user=mysql#主库授权同步帐号SELECT DISTINCT CONCAT('User: ''',user,'''@''',host,''';') AS query FROM mysql.user;GRANT REPLICATION SLAVE ON *.* TO 'slave_passport'@'10.10.16.24' IDENTIFIED BY 'slave_passport';FLUSH PRIVILEGES;#从库开启同步cat /tmp/backup/2015-08-05_16-08-14/xtrabackup_binlog_info mysql-bin.002599 804497686CHANGE MASTER TOMASTER_HOST='10.10.16.51',MASTER_USER='slave_passport',MASTER_PASSWORD='slave_passport',MASTER_PORT=3307,MASTER_LOG_FILE='mysql-bin.002599',MASTER_LOG_POS=804497686;#开启主从同步start slave;#查看从库状态show slave status\ G#从库的检查参数Slave_IO_Running=YesSlave_SQL_Running=Yes#主库的检查参数show master status \G+------------------+-----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+-----------+--------------+------------------+| mysql-bin.002600 | 454769337 | | |+------------------+-----------+--------------+------------------+1 row in set (0.00 sec)show processlist;Master has sent all binlog to slave; waiting for binlog to be updated MySQL主从切换切换前断开主库访问连接观察进程状态，无写操作后再停止从库IO_THREAD进行切换。1234567891011121314151617181920212223242526272829303132333435#查看主库状态show processlist;Master has sent all binlog to slave; waiting for binlog to be updatedshow master status \G#从库停止 IO_THREAD 线程stop slave IO_THREAD;show processlist;Slave has read all relay log; waiting for the slave I/O thread to update itshow slave status \G#从库切换为主库stop slave;reset master;reset slave all;show master status \G#激活帐户SELECT DISTINCT CONCAT('User: ''',user,'''@''',host,''';') AS query FROM mysql.user;GRANT REPLICATION SLAVE ON *.* TO 'slave_passport'@'10.10.16.51' IDENTIFIED BY 'slave_passport';FLUSH PRIVILEGES;#切换原有主库为从库reset master;reset slave all;CHANGE MASTER TOMASTER_HOST='10.10.16.24',MASTER_USER='slave_passport',MASTER_PASSWORD='slave_passport',MASTER_PORT=3306,MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=804497686;#检查主库SHOW PROCESSLIST;show master status \G#启动从库SHOW PROCESSLIST;start slave;show slave status \G 常见问题Slave_SQL_Running:No1234#一般是事务回滚造成的stop slave;set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;start slave;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Finding a needle in Haystack-Facebook’s photo storage]]></title>
    <url>%2F2017%2F12%2F19%2Ffacebook-haystack%2F</url>
    <content type="text"><![CDATA[面对海量小文件的存储和检索，Google发表了GFS，淘宝开源了TFS，而Facebook又是如何应对千亿级别的图片存储、每秒百万级别的图片查询？Facebook与同样提供了海量图片服务的淘宝，解决方案有何异同？本篇文章，为您揭晓。 本篇论文的原文可谓通俗易懂、行云流水、结构清晰、图文并茂……正如作者所说的——“替换Facebook的图片存储系统就像高速公路上给汽车换轮子，我们无法去追求完美的设计……我们花费了很多的注意力来保持它的简单”，本篇论文也是一样，没有牵扯空洞的庞大架构、也没有晦涩零散的陈述，有的是对痛点的反思，对目标的分解，条理清晰，按部就班。既描述了宏观的整体流程，又推导了细节难点的技术突破过程。以至于译者都不需要在文中插入过多备注和解读了^_^。不过在文章末尾，译者以淘宝的解决方案作为对比，阐述了文章中的一些精髓的突破点，以供读者参考。 摘要本篇论文描述了Haystack，一个为Facebook的照片应用而专门优化定制的对象存储系统。Facebook当前存储了超过260 billion的图片，相当于20PB的数据。用户每个星期还会上传1 billion的新照片（60TB），Facebook在峰值时需提供每秒查询超过1 million图片的能力。相比我们以前的方案(基于NAS和NFS)，Haystack提供了一个成本更低的、性能更高的解决方案。我们观察到一个非常关键的问题：传统的设计因为元数据查询而导致了过多的磁盘操作。我们竭尽全力的减少每个图片的元数据，让Haystack能在内存中执行所有的元数据查询。这个突破让系统腾出了更多的性能来读取真实的数据，增加了整体的吞吐量。 介绍分享照片是Facebook最受欢迎的功能之一。迄今为止，用户已经上传了超过65 billion的图片，使得Facebook成为世界上最大的图片分享网站。对每个上传的照片，Facebook生成和存储4种不同大小的图片（比如在某些场景下只需展示缩略图），这就产生了超过260 billion张图片、超过20PB的数据。用户每个星期还在上传1 billion的新照片（60TB），Facebook峰值时需要提供每秒查询1 million张图片的能力。这些数字未来还会不断增长，图片存储对Facebook的基础设施提出了一个巨大的挑战。 这篇论文介绍了Haystack的设计和实现，它已作为Facebook的图片存储系统投入生产环境24个月了。Haystack是一个为Facebook上分享照片而设计的对象存储技术，在这个应用场景中，每个数据只会写入一次、读操作频繁、从不修改、很少删除。在Facebook遭遇的负荷下，传统的文件系统性能很差，优化定制出Haystack是大势所趋。 根据我们的经验，传统基于POSIX的文件系统的缺点主要是目录和每个文件的元数据。对于图片应用，很多元数据（比如文件权限），是无用的而且浪费了很多存储容量。而且更大的性能消耗在于文件的元数据必须从磁盘读到内存来定位文件。文件规模较小时这些花费无关紧要，然而面对几百billion的图片和PB级别的数据，访问元数据就是吞吐量瓶颈所在。这是我们从之前（NAS+NFS）方案中总结的血的教训。通常情况下，我们读取单个照片就需要好几个磁盘操作：一个（有时候更多）转换文件名为inode number，另一个从磁盘上读取inode，最后一个读取文件本身。简单来说，为了查询元数据使用磁盘I/O是限制吞吐量的重要因素。在实际生产环境中，我们必须依赖内容分发网络（CDN，比如Akamai）来支撑主要的读取流量，即使如此，文件元数据的大小和I/O同样对整体系统有很大影响。 了解传统途径的缺点后，我们设计了Haystack来达到4个主要目标： 高吞吐量和低延迟。我们的图片存储系统必须跟得上海量用户查询请求。超过处理容量上限的请求，要么被忽略（对用户体验是不可接受的），要么被CDN处理（成本昂贵而且可能遭遇一个性价比转折点）。想要用户体验好，图片查询必须快速。Haystack希望每个读操作至多需要一个磁盘操作，基于此才能达到高吞吐量和低延迟。为了实现这个目标，我们竭尽全力的减少每个图片的必需元数据，然后将所有的元数据保存在内存中。 容错。在大规模系统中，故障每天都会发生。尽管服务器崩溃和硬盘故障是不可避免的，也绝不可以给用户返回一个error，哪怕整个数据中心都停电，哪怕一个跨国网络断开。所以，Haystack复制每张图片到地理隔离的多个地点，一台机器倒下了，多台机器会替补上来。 高性价比。Haystack比我们之前（NAS+NFS）方案性能更好，而且更省钱。我们按两个维度来衡量：每TB可用存储的花费、每TB可用存储的读取速度。相对NAS设备，Haystack每个可用TB省了28%的成本，每秒支撑了超过4倍的读请求。 简单。替换Facebook的图片存储系统就像高速公路上给汽车换轮子，我们无法去追求完美的设计，这会导致实现和维护都非常耗时耗力。Haystack是一个新系统，缺乏多年的生产环境级别的测试。我们花费了很多的注意力来保持它的简单，所以构建和部署一个可工作的Haystack只花了几个月而不是好几年。 本篇文章3个主要的贡献是： Haystack，一个为高效存储和检索billion级别图片而优化定制的对象存储系统。 构建和扩展一个低成本、高可靠、高可用图片存储系统中的经验教训。 访问Facebook照片分享应用的请求的特征描述 背景 &amp; 我的前任在本章节，我们将描述Haystack之前的架构，突出其主要的经验教训。由于文章大小限制，一些细节就不细述了。 背景 我们先来看一个概览图，它描述了通常的设计方案，web服务器、CDN和存储系统如何交互协作，来实现一个热门站点的图片服务。图1描述了从用户访问包含某个图片的页面开始，直到她最终从磁盘的特定位置下载此图片结束的全过程。访问一个页面时，用户的浏览器首先发送HTTP请求到一个web服务器，它负责生成markup以供浏览器渲染。对每张图片，web服务器为其构造一个URL，引导浏览器在此位置下载图片数据。对于热门站点，这个URL通常指向一个CDN。如果CDN缓存了此图片，那么它会立刻将数据回复给浏览器。否则，CDN检查URL，URL中需要嵌入足够的信息以供CDN从本站点的存储系统中检索图片。拿到图片后，CDN更新它的缓存数据、将图片发送回用户的浏览器。 基于NFS的设计在我们最初的设计中，我们使用了一个基于NFS的方案。我们吸取的主要教训是，对于一个热门的社交网络站点，只有CDN不足以为图片服务提供一个实用的解决方案。对于热门图片，CDN确实很高效——比如个人信息图片和最近上传的照片——但是一个像Facebook的社交网络站点，会产生大量的对不热门（较老）内容的请求，我们称之为long tail（长尾理论中的名词）。long tail的请求也占据了很大流量，它们都需要访问更下游的图片存储主机，因为这些请求在CDN缓存里基本上都会命中失败。缓存所有的图片是可以解决此问题，但这么做代价太大，需要极大容量的缓存。 基于NFS的设计中，图片文件存储在一组商用NAS设备上，NAS设备的卷被mount到Photo Store Server的NFS上。图2展示了这个架构。Photo Store Server解析URL得出卷和完整的文件路径，在NFS上读取数据，然后返回结果到CDN。 我们最初在NFS卷的每个目录下存储几千个文件，导致读取文件时产生了过多的磁盘操作，哪怕只是读单个图片。由于NAS设备管理目录元数据的机制，放置几千个文件在一个目录是极其低效的，因为目录的blockmap太大不能被设备有效的缓存。因此检索单个图片都可能需要超过10个磁盘操作。在减少到每个目录下几百个图片后，系统仍然大概需要3个磁盘操作来获取一个图片：一个读取目录元数据到内存、第二个装载inode到内存、最后读取文件内容。 为了继续减少磁盘操作，我们让图片存储服务器明确的缓存NAS设备返回的文件“句柄”。第一次读取一个文件时，图片存储服务器正常打开一个文件，将文件名与文件“句柄”的映射缓存到memcache中。同时，我们在os内核中添加了一个通过句柄打开文件的接口，当查询被缓存的文件时，图片存储服务器直接用此接口和“句柄”参数打开文件。遗憾的是，文件“句柄”缓存改进不大，因为越冷门的图片越难被缓存到（没有解决long tail问题）。值得讨论的是可以将所有文件“句柄”缓存到memcache，不过这也需要NAS设备能缓存所有的inode信息，这么做是非常昂贵的。总结一下，我们从NAS方案吸取的主要教训是，仅针对缓存——不管是NAS设备缓存还是额外的像memcache缓存——对减少磁盘操作的改进是有限的。存储系统终究是要处理long tail请求（不热门图片）。 讨论我们很难提出一个指导方针关于何时应该构建一个自定义的存储系统。下面是我们在最终决定搭建Haystack之前的一些思考，希望能给大家提供参考。 面对基于NFS设计的瓶颈，我们探讨了是否可以构建一个类似GFS的系统。而我们大部分用户数据都存储在Mysql数据库，文件存储主要用于开发工作、日志数据以及图片。NAS设备其实为这些场景提供了性价比很好的方案。此外，我们补充了hadoop以供海量日志数据处理。面对图片服务的long tail问题，Mysql、NAS、Hadoop都不太合适。 我们面临的困境可简称为“已存在存储系统缺乏合适的RAM-to-disk比率”。然而，没有什么比率是绝对正确的。系统需要足够的内存才能缓存所有的文件系统元数据。在我们基于NAS的方案中，一个图片对应到一个文件，每个文件需要至少一个inode，这已经占了几百byte。提供足够的内存太昂贵。所以我们决定构建一个定制存储系统，减少每个图片的元数据总量，以便能有足够的内存。相对购买更多的NAS设备，这是更加可行的、性价比更好的方案。 设计和实现Facebook使用CDN来支撑热门图片查询，结合Haystack则解决了它的long tail问题。如果web站点在查询静态内容时遇到I/O瓶颈，传统方案就是使用CDN，它为下游的存储系统挡住了绝大部分的查询请求。在Facebook，为了传统的、廉价的的底层存储不受I/O摆布，CDN往往需要缓存难以置信的海量静态内容。 上面已经论述过，在不久的将来，CDN也不能完全的解决我们的问题，所以我们设计了Haystack来解决这个严重瓶颈：磁盘操作。我们接受long tail请求必然导致磁盘操作的现实，但是会尽量减少除了访问真实图片数据之外的其他操作。Haystack有效的减少了文件系统元数据的空间，并在内存中保存所有元数据。 每个图片存储为一个文件将会导致元数据太多，难以被全部缓存。Haystack的对策是：将多个图片存储在单个文件中，控制文件个数，维护大型文件，我们将论述此方案是非常有效的。另外，我们强调了它设计的简洁性，以促进快速的实现和部署。我们将以此核心技术展开，结合它周边的所有架构组件，描述Haystack是如何实现了一个高可靠、高可用的存储系统。在下面对Haystack的介绍中，需要区分两种元数据，不要混淆。一种是应用元数据，它是用来为浏览器构造检索图片所需的URL；另一种是文件系统元数据，用于在磁盘上检索文件。 概览Haystack架构包含3个核心组件：Haytack Store、Haystack Directory和Haystack Cache（简单起见我们下面就不带Haystack前缀了）。Store是持久化存储系统，并负责管理图片的文件系统元数据。Store将数据存储在物理的卷上。比如，在一台机器上提供100个物理卷，每个提供100GB的存储容量，整台机器则可以支撑10TB的存储。更进一步，不同机器上的多个物理卷将对应一个逻辑卷。Haystack将一个图片存储到一个逻辑卷时，图片被写入到所有对应的物理卷。这个冗余可避免由于硬盘故障，磁盘控制器bug等导致的数据丢失。Directory维护了逻辑到物理卷的映射以及其他应用元数据，比如某个图片寄存在哪个逻辑卷、某个逻辑卷的空闲空间等。Cache的功能类似我们系统内部的CDN，它帮Store挡住热门图片的请求（可以缓存的就绝不交给下游的持久化存储）。在独立设计Haystack时，我们要设想它处于一个没有CDN的大环境中，即使有CDN也要预防其节点故障导致大量请求直接进入存储系统，所以Cache是十分必要的。 图3说明了Store、Directory、Cache是如何协作的，以及如何与外部的浏览器、web服务器、CDN和存储系统交互。在Haystack架构中，浏览器会被引导至CDN或者Cache上。需要注意的是Cache本质上也是一个CDN，为了避免困惑，我们使用“CDN”表示外部的系统、使用“Cache”表示我们内部的系统。有一个内部的缓存设施能减少对外部CDN的依赖。 当用户访问一个页面，web服务器使用Directory为每个图片来构建一个URL（Directory中有足够的应用元数据来构造URL）。URL包含几块信息，每一块内容可以对应到从浏览器访问CDN(或者Cache)直至最终在一台Store机器上检索到图片的各个步骤。一个典型的URL如下：1http://&lt;CDN&gt;/&lt;Cache&gt;/&lt;Machine id&gt;/&lt;Logical volume, Photo&gt; 第一个部分指明了从哪个CDN查询此图片。到CDN后它使用最后部分的URL（逻辑卷和图片ID）即可查找缓存的图片。如果CDN未命中缓存，它从URL中删除相关信息，然后访问Cache。Cache的查找过程与之类似，如果还没命中，则去掉相关信息，请求被发至指定的Store机器()。如果请求不经过CDN直接发至Cache，其过程与上述类似，只是少了CDN这个环节。 上图说明了在Haystack中的上传流程。用户上传一个图片时，她首先发送数据到web服务器。web服务器随后从Directory中请求一个可写逻辑卷。最后，web服务器为图片分配一个唯一的ID，然后将其上传至逻辑卷对应的每个物理卷。 ### Haystack Directory Directory提供4个主要功能。首先，它提供一个从逻辑卷到物理卷的映射。web服务器上传图片和构建图片URL时都需要使用这个映射。第二，Directory在分配写请求到逻辑卷、分配读请求到物理卷时需保证负载均衡。第三，Directory决定一个图片请求应该被发至CDN还是Cache，这个功能可以让我们动态调整是否依赖CDN。第四，Directory指明那些逻辑卷是只读的（只读限制可能是源自运维原因、或者达到存储容量上限；为了运维方便，我们以机器粒度来标记卷的只读）。 当我们增加新机器以增大Store的容量时，那些新机器是可写的；仅仅可写的机器会收到upload请求。随时间流逝这些机器的可用容量会不断减少。当一个机器达到容量上限，我们标记它为只读，在下一个子章节我们将讨论如何这个特性如何影响Cache和Store。 Directory将应用元数据存储在一个冗余复制的数据库，通过一个PHP接口访问，也可以换成memcache以减少延迟。当一个Store机器故障、数据丢失时，Directory在应用元数据中删除对应的项，新Store机器上线后则接替此项。 3.2章节是整篇文章中唯一一处译者认为没有解释清楚的环节。结合3.1章节中的URL结构解析部分，读者可以发现Directory需要拿到图片的“原始URL”（页面html中link的URL），再结合应用元数据，就可以构造出“引导URL”以供下游使用。从3.2中我们知道Directory必然保存了逻辑卷到物理卷的映射，仅用此映射+原始URL足够发掘其他应用元数据吗？原始URL中到底包含了什么信息（论文中没看到介绍）？我们可以做个假设，假如原始URL中仅仅包含图片ID，那Directory如何得知它对应哪个逻辑卷（必须先完成这一步映射，才能继续挖掘更多应用元数据）？Directory是否在upload阶段将图片ID与逻辑卷的映射也保存了？如果是，那这个映射的数据量不能忽略不计，论文也不该一笔带过。 从原文一些细枝末节的描述中，译者认为Directory确实保存了很多与图片ID相关的元数据（存储在哪个逻辑卷、cookie等）。但整篇论文译者也没找到对策，总感觉这样性价比太低，不符合Haystack的作风。对于这个疑惑，文章末尾扩展阅读部分将尝试解答。读者先认为其具备此能力吧。 Haystack CacheCache会从CDN或者直接从用户浏览器接收到图片查询请求。Cache的实现可理解为一个分布式Hash Table，使用图片ID作为key来定位缓存的数据。如果Cache未命中，Cache则根据URL从指定Store机器上获取图片，视情况回复给CDN或者用户浏览器。 我们现在强调一下Cache的一个重要行为概念。只有当符合两种条件之一时它才会缓存图片：(a)请求直接来自用户浏览器而不是CDN；(b)图片获取自一个可写的Store机器。第一个条件的理由是一个请求如果在CDN中没命中（非热门图片），那在我们内部缓存也不太需要命中（即使此图片开始逐渐活跃，那也能在CDN中命中缓存，这里无需多此一举；直接的浏览器请求说明是不经过CDN的，那就需要Cache代为CDN，为其缓存）。第二个条件的理由是间接的，有点经验论，主要是为了保护可写Store机器；原因挺有意思，大部分图片在上传之后很快会被频繁访问（比如某个美女新上传了一张自拍），而且文件系统在只有读或者只有写的情况下执行的更好，不太喜欢同时并发读写。如果没有Cache，可写Store机器往往会遭遇频繁的读请求。因此，我们甚至会主动的推送最近上传的图片到Cache。 Haystack StoreStore机器的接口设计的很简约。读操作只需提供一些很明确的元数据信息，包括图片ID、哪个逻辑卷、哪台物理Store机器等。机器如果找到图片则返回其真实数据，否则返回错误信息。 每个Store机器管理多个物理卷。每个物理卷存有百万张图片。读者可以将一个物理卷想象为一个非常大的文件（100GB），保存为’/hay/haystack&lt;logical volume id&gt;’。Store机器仅需要逻辑卷ID和文件offset就能非常快的访问一个图片。这是Haystack设计的主旨：不需要磁盘操作就可以检索文件名、偏移量、文件大小等元数据。Store机器会将其下所有物理卷的文件描述符（open的文件“句柄”，卷的数量不多，数据量不大）缓存在内存中。同时，图片ID到文件系统元数据（文件、偏移量、大小等）的映射（后文简称为“内存中映射”）是检索图片的重要条件，也会全部缓存在内存中。 现在我们描述一下物理卷和内存中映射的结构。一个物理卷可以理解为一个大型文件，其中包含一系列的needle。每个needle就是一张图片。图5说明了卷文件和每个needle的格式。Table1描述了needle中的字段。 为了快速的检索needle，Store机器需要为每个卷维护一个内存中的key-value映射。映射的Key就是（needle.key+needle.alternate_key）的组合，映射的Value就是needle的flag、size、卷offset（都以byte为单位）。如果Store机器崩溃、重启，它可以直接分析卷文件来重新构建这个映射（构建完成之前不处理请求）。下面我们介绍Store机器如何响应读写和删除请求（Store仅支持这些操作）。 译者注: 从Table1我们看到needle.key就是图片ID，为何仅用图片ID做内存中映射的Key还不够，还需要一个alternate_key？这是因为一张照片会有4份副本，它们的图片ID相同，只是类型不同（比如大图、小图、缩略图等），于是将图片ID作为needle.key，将类型作为needle.alternate_key。根据译者的理解，内存中映射不是一个简单的HashMap结构，而是类似一个两层的嵌套HashMap，Map&lt;long/*needle.key*/,Map&lt;int/*alternate_key*/,Object&gt;&gt;。这样做可以让4个副本共用同一个needle.key，避免为重复的内容浪费内存空间。 读取图片Cache机器向Store机器请求一个图片时，它需要提供逻辑卷id、key、alternate key，和cookie。cookie是个数字，嵌在URL中。当一张新图片被上传，Directory为其随机分配一个cookie值，并作为应用元数据之一存储在Directory。它就相当于一张图片的“私人密码”，此密码可以保证所有发往Cache或CDN的请求都是经过Directory“批准”的（Cache和Store都持有图片的cookie，若用户自己在浏览器中伪造、猜测URL或发起攻击，则会因为cookie不匹配而失败，从而保证Cache、Store能放心处理合法的图片请求）。 当Store机器接收到Cache机器发来的图片查询请求，它会利用内存中映射快速的查找相关的元数据。如果图片没有被删除，Store则在卷文件中seek到相应的offset，从磁盘上读取整个needle（needle的size可以提前计算出来），然后检查cookie和数据完整性，若全部合法则将图片数据返回到Cache机器。 写入图片上传一个图片到Haystack时，web服务器向Directory咨询得到一个可写逻辑卷及其对应的多台Store机器，随后直接访问这些Store机器，向其提供逻辑卷id、key、alternate key、cookie和真实数据。每个Store机器为图片创建一个新needle，append到相应的物理卷文件，更新内存中映射。过程很简单，但是append-only策略不能很好的支持修改性的操作，比如旋转（图片顺时针旋转90度之类的）。Haystack并不允许覆盖needle，所以图片的修改只能通过添加一个新needle，其拥有相同的key和alternate key。如果新needle被写入到与老needle不同的逻辑卷，则只需要Directory更新它的应用元数据，未来的请求都路由到新逻辑卷，不会获取老版本的数据。如果新needle写入到相同的逻辑卷，Store机器也只是将其append到相同的物理卷中。Haystack利用一个十分简单的手段来区分重复的needle，那就是判断它们的offset（新版本的needle肯定是offset最高的那个），在构造或更新内存中映射时如果遇到相同的needle，则用offset高的覆盖低的。 图片删除在删除图片时，Store机器将内存中映射和卷文件中相应的flag同步的设置为已删除（软删除机制，此刻不会删除needle的磁盘数据）。当接收到已删除图片的查询请求，Store会检查内存中flag并返回错误信息。值得注意的是，已删除needle依然占用的空间是个问题，我们稍后将讨论如何通过压缩技术来回收已删除needle的空间。 索引文件Store机器使用一个重要的优化——索引文件——来帮助重启初始化。尽管理论上一个机器能通过读取所有的物理卷来重新构建它的内存中映射，但大量数据（TB级别）需要从磁盘读取，非常耗时。索引文件允许Store机器快速的构建内存中映射，减少重启时间。 Store机器为每个卷维护一个索引文件。索引文件可以想象为内存中映射的一个“存档”。索引文件的布局和卷文件类似，一个超级块包含了一系列索引记录，每个记录对应到各个needle。索引文件中的记录与卷文件中对应的needle必须保证相同的存储顺序。图6描述了索引文件的布局，Table2解释了记录中的不同的字段。 使用索引帮助重启稍微增加了系统复杂度，因为索引文件都是异步更新的，这意味着当前索引文件中的“存档”可能不是最新的。当我们写入一个新图片时，Store机器同步append一个needle到卷文件末尾，并异步append一个记录到索引文件。当我们删除图片时，Store机器在对应needle上同步设置flag，而不会更新索引文件。这些设计决策是为了让写和删除操作更快返回，避免附加的同步磁盘写。但是也导致了两方面的影响：一个needle可能没有对应的索引记录、索引记录中无法得知图片已删除。 我们将对应不到任何索引记录的needle称为“孤儿”。在重启时，Store机器顺序的检查每个孤儿，重新创建匹配的索引记录，append到索引文件。我们能快速的识别孤儿是因为索引文件中最后的记录能对应到卷文件中最后的非孤儿needle。处理完孤儿问题，Store机器则开始使用索引文件初始化它的内存中映射。 由于索引记录中无法得知图片已删除，Store机器可能去检索一个实际上已经被删除的图片。为了解决这个问题，可以在Store机器读取整个needle后检查其flag，若标记为已删除，则更新内存中映射的flag，并回复Cache此对象未找到。 文件系统Haystack可以理解为基于通用的类Unix文件系统搭建的对象存储，但是某些特殊文件系统能更好的适应Haystack。比如，Store机器的文件系统应该不需要太多内存就能够在一个大型文件上快速的执行随机seek。当前我们所有的Store机器都在使用的文件系统是XFS，一个基于“范围(extent)”的文件系统。XFS有两个优势：首先，XFS中邻近的大型文件的”blockmap”很小，可放心使用内存存储；第二，XFS提供高效文件预分配，减轻磁盘碎片等问题。 使用XFS，Haystack可以在读取一张图片时完全避免检索文件系统元数据导致的磁盘操作。但是这并不意味着Haystack能保证读取单张图片绝对只需要一个磁盘操作。在一些极端情况下会发生额外的磁盘操作，比如当图片数据跨越XFS的“范围(extent)”或者RAID边界时。不过Haystack会预分配1GB的“范围(extent)”、设置RAID stripe大小为256KB，所以实际上我们很少遭遇这些极端场景。 故障恢复对于运行在普通硬件上的大规模系统，容忍各种类型的故障是必须的，包括硬盘驱动故障、RAID控制器错误、主板错误等，Haystack也不例外。我们的对策由两个部分组成——一个为侦测、一个为修复。 为了主动找到有问题的Store机器，我们维护了一个后台任务，称之为pitchfork，它周期性的检查每个Store机器的健康度。pitchfork远程的测试到每台Store机器的连接，检查其每个卷文件的可用性，并尝试读取数据。如果pitchfork确定某台Store机器没通过这些健康检查，它会自动标记此台机器涉及的所有逻辑卷为只读。我们的工程师将在线下人工的检查根本故障原因。 一旦确诊，我们就能快速的解决问题。不过在少数情况下，需要执行一个更加严厉的bulk同步操作，此操作需要使用复制品中的卷文件重置某个Store机器的所有数据。Bulk同步发生的几率很小（每个月几次），而且过程比较简单，只是执行很慢。主要的瓶颈在于bulk同步的数据量经常会远远超过单台Store机器NIC速度，导致好几个小时才能恢复。我们正积极解决这个问题。 优化Haystack的成功还归功于几个非常重要的细节优化。 压缩压缩操作是直接在线执行的，它能回收已删除的、重复的needle所占据的空间。Store机器压缩卷文件的方式是，逐个复制needle到一个新的卷文件，并跳过任何重复项、已删除项。在压缩时如果接收到删除操作，两个卷文件都需处理。一旦复制过程执行到卷文件末尾，所有对此卷的修改操作将被阻塞，新卷文件和新内存中映射将对前任执行原子替换，随后恢复正常工作。 节省更多内存上面描述过，Store机器会在内存中映射中维护一个flag，但是目前它只会用来标记一个needle是否已删除，有点浪费。所以我们通过设置偏移量为0来表示图片已删除，物理上消除了这个flag。另外，映射Value中不包含cookie，当needle从磁盘读出之后Store才会进行cookie检查。通过这两个技术减少了20%的内存占用。 当前，Haystack平均为每个图片使用10byte的内存。每个上传的图片对应4张副本，它们共用同一个key（占64bits），alternate keys不同（占32bits），size不同（占16bits），目前占用(64+(32+16)*4)/8=32个bytes。另外，对于每个副本，Haystack在用hash table等结构时需要消耗额外的2个bytes，最终总量为一张图片的4份副本共占用40bytes。作为对比，一个xfs_inode_t结构在Linux中需占用536bytes。 批量上传磁盘在执行大型的、连续的写时性能要优于大量小型的随机写，所以我们尽量将相关写操作捆绑批量执行。幸运的是，很多用户都会上传整个相册到Facebook，而不是频繁上传单个图片。因此只需做一些巧妙的安排就可以捆绑批量upload，实现大型、连续的写操作。 章节4、5、6是实验和总结等内容，这里不再赘述了。 扩展阅读提到CDN和分布式文件存储就不得不提到淘宝，它的商品图片不会少于Facebook的个人照片。其著名的CDN+TFS的解决方案由于为公司节省了巨额的预算开支而获得创新大奖，团队成员也得到不菲的奖金（羡慕嫉妒恨）。淘宝的CDN技术做了非常多的技术创新和突破，不过并非本文范畴，接下来的讨论主要是针对Haystack与TFS在存储、检索环节的对比，并尝试提取出此类场景常见的技术难点。（译者对TFS的理解仅限于介绍文档，若有错误望读者矫正） 淘宝CDN、TFS的介绍请移步 http://www.infoq.com/cn/presentations/zws-taobao-image-store-cdnhttp://tfs.taobao.org/index.html 注意：下文中很多术语（比如应用元数据、Store、文件系统元数据等，都是基于本篇论文的上下文，请勿混淆） 上图是整个CDN+TFS解决方案的全貌，对应本文就是图3。CDN在前三层上实现了各种创新和技术突破，不过并非本文焦点，这里主要针对第四层Storage（淘宝的分布式文件系统TFS），对比Haystack，看其是否也解决了long tail问题。下面是TFS的架构概览： 从粗粒度的宏观视角来看，TFS与Haystack的最大区别就是： TFS只care存储层面，它没有Haystack Cache组件；Haystack期望提供的是从浏览器、到CDN、到最终存储的一整套解决方案，架构定位稍有不同，Haystack也是专门为这种场景下的图片服务所定制的，做了很多精细的优化；TFS的目标是通用分布式文件存储，除了CDN还会支持其他各种场景。 到底是定制一整套优化的解决方案，还是使用通用分布式文件存储平台强强联手？Facebook的工程师也曾纠结过（章节2.3），这个没有标准答案，各有所长，视情况去选择最合适的方案吧。 下面我们以本文中关注的一些难点来对比一下双方的实现： 存储机器上的文件结构、文件系统元数据对策Haystack的机器上维护了少量的大型物理卷文件，其中包含一系列needle来存储小文件，同时needle的文件系统元数据被全量缓存、持久化“存档”。 在TFS中（后文为清晰起见，引用TFS文献的内容都用淘宝最爱的橙色展示）： “……在TFS中，将大量的小文件(实际用户文件)合并成为一个大文件，这个大文件称为块(Block)。TFS以Block的方式组织文件的存储……” “……!DataServer进程会给Block中的每个文件分配一个ID(File ID，该ID在每个Block中唯一)，并将每个文件在Block中的信息存放在和Block对应的Index文件中。这个Index文件一般都会全部load在内存……” 看来面对可怜的操作系统，大家都不忍心把海量的小文件直接放到它的文件系统上，合并成super block，维护super block中各entry的元数据和索引信息（并全量缓存），才是王道。这里TFS的Block应该对应到Haystack中的一个物理卷。 分布式协调调度、应用元数据策略Haystack在接收到读写请求时，依靠Directory分析应用元数据，再结合一定策略（如负载均衡、容量、运维、只读、可写等），决定请求被发送到哪台Store机器，并向Store提供足够的存储或检索信息。Directory负责了整体分布式环境的协调调度、应用元数据管理职能，并基于此帮助实现了系统的可扩展性、容错性。 在TFS中： “……!NameServer主要功能是: 管理维护Block和!DataServer相关信息,包括!DataServer加入，退出, 心跳信息, block和!DataServer的对应关系建立，解除。正常情况下，一个块会在!DataServer上存在， 主!NameServer负责Block的创建，删除，复制，均衡，整理……” “……每一个Block在整个集群内拥有唯一的编号，这个编号是由NameServer进行分配的，而DataServer上实际存储了该Block。在!NameServer节点中存储了所有的Block的信息……” TFS中与Directory对应的就是NameServer了，职责大同小异，就是分布式协调调度和应用元数据分配管理，并基于此实现系统的平滑扩容、故障容忍。下面专门讨论一下这两个重要特性。 扩展性Haystack和TFS都基于（分布式协调调度+元数据分配管理）实现了非常优雅的可扩展方案。我们先回顾一下传统扩展性方案中的那些简单粗暴的方法。 最简单最粗暴的场景： 现在有海量的数据，比如data [key : value]，有100台机器，通过一种策略让这些数据能负载均衡的发给各台机器。策略可以是这样，int index=Math.abs(key.hashCode)%100，这就得到了一个唯一的、确定的、[0,99]的序号，按此序号发给对应的某台机器，最终能达到负载均衡的效果。此方案的粗暴显而易见，当我们新增机器后（比如100变成130），大部分老数据的key执行此策略后得到的index会发生变化，这也就意味着对它们的检索都会发往错误的机器，找不到数据。 稍微改进的场景是： 现在有海量的数据，比如data [key : value]，我假想自己是高富帅，有一万台机器，同样按照上述的策略进行路由。但是我只有100台机器，这一万台是假想的，怎么办？先给它们一个称号，叫虚拟节点（简称vnode，vnode的序号简称为vnodeId），然后想办法将vnode与真实机器建立多对一映射关系（每个真实机器上100个vnode），这个办法可以是某种策略，比如故技重施对vnodeId%100得到[0,99]的机器序号，或者在数据库中建几张表维护一下这个多对一的映射关系。在路由时，先按老办法得到vnodeId，再执行一次映射，找到真实机器。这个方案还需要一个架构假设：我的系统规模在5年内都不需要上涨到一万台机器（5年差不多了，像我等码农估计一辈子也玩不了一万台机器的集群吧），因此10000这个数字“永远”不会变，这就保证了一个key永远对应某个vnodeId，不会发生改变。然后在扩容时，我们改变的是vnode与真实机器的映射关系，但是此映射关系一改，也会不可避免的导致数据命中失败，因为必然会产生这样的现象：某个vnodeId（v1）原先是对应机器A的，现在变成了机器B。但是相比之前的方案，现在已经好很多了，我们可以通过运维手段先阻塞住对v1的读写请求，然后执行数据迁移（以已知的vnode为粒度，而不是千千万万个未知的data，这种迁移操作还是可以接受的），迁移完毕后新机器开始接收请求。做的更好一点，可以不阻塞请求，想办法做点容错处理和写同步之类的，可以在线无痛的完成迁移。 上面两个老方案还可以加上一致性Hash等策略来尽量避免数据命中失败和数据迁移。但是始终逃避不了这样一个公式：1int machine_id=function(data.key , x) machine_id指最终路由到哪台机器，function代表我们的路由策略函数，data.key就是数据的key（数据ID之类的），x在第一个方案里就是机器数量100，在第二个方案里就是vnode数量+(vnode与机器的映射关系)。在这个公式里，永远存在了x这个未知数，一旦它风吹草动，function的执行结果就可能改变，所以它逃避不了命中失败。 只有当公式变成下面这个，才能绝对避免： 12Map&lt;data.key,final machine_id&gt; map = xxx; int machine_id=map.get(data.key); 注意map只是个理论上的结构，这里只是简单的伪代码，并不强制它是个简单的&lt;key-value&gt;结构，它的结构可能会更复杂，但是无论怎么复杂，此map都真实的、明确的存在，其效果都是——用data.key就能映射到machine_id，找到目标机器，不管是直接，还是间接，反正不是用一个function去动态计算得到。map里的final不符合语法，加在这里是想强调，此map一旦为某个data.key设置了machine_id，就永不改变（起码不会因为日常扩容而改变）。当增加机器时，此map的已有值也不会受到影响。这样一个没有未知数x的公式，才能保证新老数据来了都能根据key拿到一个永远不变的machine_id，永远命中成功。 因此我们得出这样一个结论，只要拥有这样一个map，系统就能拥有非常优雅平滑的可扩展潜力。当系统扩容时，老的数据不会命中失败，在分布式协调调度的保证下，新的增量数据会更倾向于写入新机器，整个集群的负载会逐渐均衡。 很显然Haystack和TFS都做到了，下面忽略其他细节问题，着重讨论一下它们是如何装备上这个map的。 读者回顾一下3.2章节留下的那个疑惑——原始URL中到底包含什么信息，是不是只有图片ID？Directory到底需不需要维护图片ID到逻辑卷的映射？ 这个“图片ID到逻辑卷的映射”，就是我们需要的map，用图片ID（data.key）能get到逻辑卷ID（此值是upload时就明确分配的，不会改变），再间接从“逻辑卷到物理卷映射”中就能get到目标Store机器；无论是新增逻辑卷还是新增物理卷，“图片ID到逻辑卷的映射”中的已有值都可以不受影响。这些都符合map的行为定义。 Haystack也因此，具备了十分优雅平滑的可扩展能力。但是译者提到的疑惑并没有解答——“这个映射（图片ID到逻辑卷的映射）的数据量不能忽略不计，论文也不该一笔带过” 作者提到过memcache，也许这就是相关的解决方案，此数据虽然不小，但是也没大到望而生畏的地步。不过我们依然可以发散一下，假如Haystack没保存这个映射呢？ 这就意味着原始URL不只包含图片ID，还包含逻辑卷ID等必要信息。这样也是遵循map的行为定义的，即使map的信息没有集中存储在系统内，但是却分散在各个原始URL中，依然存在。不可避免的，这些信息就要在upload阶段返回给业务系统（比如Facebook的照片分享应用系统），业务系统需要理解、存储和处理它们（随后再利用它们组装为原始URL去查询图片）。这样相当于把map的维护工作分担给了各个用户系统，这也是让人十分痛苦的，导致了不可接受的耦合。 我们可以看看TFS的解决方案： “……TFS的文件名由块号和文件号通过某种对应关系组成，最大长度为18字节。文件名固定以T开始，第二字节为该集群的编号(可以在配置项中指定，取值范围 1~9)。余下的字节由Block ID和File ID通过一定的编码方式得到。文件名由客户端程序进行编码和解码，它映射方式如下图……” “……根据TFS文件名解析出Block ID和block中的File ID.……dataserver会根据本地记录的信息来得到File ID所在block的偏移量，从而读取到正确的文件内容……” 一切，迎刃而解了…… 这个方案可以称之为“结构化ID”、“聚合ID”，或者是“命名规则大于配置”。当我们纠结于仅仅有图片ID不够时，可以给ID简单的动动手脚，比如ID是long类型，8个byte，左边给点byte用于存储逻辑卷ID，剩下的用于存储真实的图片ID（某些场景下还可以多截几段给更多的元数据），于是既避免了保存大量的映射数据，又避免了增加系统间的耦合，鱼和熊掌兼得。不过这个方案对图片ID有所约束，也不支持自定义的图片名称，针对这个问题，TFS在新版本中： “……metaserver是我们在2.0版本引进的一个服务. 用来存储一些元数据信息, 这样原本不支持自定义文件名的 TFS 就可以在 metaserver 的帮助下, 支持自定义文件名了.……” 此metaserver的作用无疑就和Directory中部分应用元数据相关的职责类似了。个人认为可以两者结合双管齐下，毕竟自定义文件名这种需求应该不是主流。 值得商榷的是，全量保存这部分应用元数据其实还是有很多好处的，最典型的就是顺带保存的cookie，有效的帮助Haystack不受伪造URL攻击的困扰，这个问题不知道TFS是如何解决的（大量的文件检索异常势必会影响系统性能）。如果Haystack的作者能和TFS的同学们做个交流，说不定大家都能少走点弯路吧（这都是后话了~） 小结一下，针对第三个可扩展性痛点，译者描述了传统方案的缺陷，以及Haystack和TFS是如何弥补了这些缺陷，实现了平滑优雅的可扩展能力。此小节的最后再补充一个TFS的特性： “……同时，在集群负载比较轻的时候，!NameServer会对!DataServer上的Block进行均衡，使所有!DataServer的容量尽早达到均衡。进行均衡计划时，首先计算每台机器应拥有的blocks平均数量，然后将机器划分为两堆，一堆是超过平均数量的，作为移动源；一类是低于平均数量的，作为移动目的……” 均衡计划的职责是在负载较低的时候（深夜），按计划执行Block数据的迁移，促进整体负载更加均衡。根据译者的理解，此计划会改变公式中的map，因为根据文件名拿到的BlockId对应的机器可能发生变化，这也是它为何要在深夜负载较低时按计划缜密执行的原因。其效果是避免了因为运维操作等原因导致的数据分布不均。 容错性Haystack的容错是依靠：一个逻辑卷对应多个物理卷（不同机器上）；“客户端”向一个逻辑卷的写操作会翻译为对多个物理卷的写，达到冗余备份；机器故障时Directory优雅的修改应用元数据（在牵涉到的逻辑卷映射中删除此机器的物理卷项）、或者标记只读，继而指导路由过程（分布式协调调度）将请求发送到后备的节点，避免请求错误；通过bulk复制重置来安全的恢复数据。等等。 在TFS中： “……TFS可以配置主辅集群，一般主辅集群会存放在两个不同的机房。主集群提供所有功能，辅集群只提供读。主集群会把所有操作重放到辅集群。这样既提供了负载均衡，又可以在主集群机房出现异常的情况不会中断服务或者丢失数据。……” “……每一个Block会在TFS中存在多份，一般为3份，并且分布在不同网段的不同!DataServer上……” “……客户端向master dataserver开始数据写入操作。master server将数据传输为其他的dataserver节点，只有当所有dataserver节点写入均成功时，master server才会向nameserver和客户端返回操作成功的信息。……” 可以看出冗余备份+协调调度是解决这类问题的惯用范式，在大概思路上两者差不多，但是有几个技术方案却差别很大： 第一，冗余写机制。Haystack Store是将冗余写的责任交给“客户端”（发起写操作的客户端，就是图3中的web server），“客户端”需要发起多次写操作到不同的Store机器上；而TFS是依靠自身的master-slave机制，由master向slave复制。 第二，机房容错机制。TFS依然是遵循master-slave机制，集群也分主辅，主辅集群分布在不同机房，主集群负责重放数据操作到辅集群。而Haystack在这方面没有详细介绍，只是略微提到“……Haystack复制每张图片到地理隔离的多个地点……” 针对上面两点，按译者的理解，Haystack可能更偏向于对等结构的设计，也就是说没有master、slave之分，各个Store是对等的节点，没有谁负责给谁复制数据，“客户端”向各个Store写入数据，一视同仁。 不考虑webserver、Directory等角色，只考虑Store，来分析一下它的容错机制：如果单台Store挂了，Directory在应用元数据的相关逻辑卷映射中删除此台机器的物理卷（此过程简称为“调整逻辑物理映射”），其他“对等”的物理卷能继续服务，没有问题；一整个机房挂了，Directory处理过程和单台故障相同，只是会对此机房中每台机器都执行一遍“调整逻辑物理映射”，由于逻辑卷到物理卷的映射是在Directory中明确维护的，所以只要在维护和管理过程中确保一个逻辑卷下不同的物理卷分布在不同的机房，哪怕在映射中删除一整个机房所有机器对应的物理卷，各个逻辑卷下依然持有到其他机房可用物理卷的映射，依然有对等Store的物理卷做后备，没有问题。 主从结构和对等结构各有所长，视情况选择。对等结构看似简洁美好，也有很多细节上的妥协；主从结构增加了复杂度，比如严格角色分配、约定角色行为等等（TFS的辅集群为何只读？在主集群挂掉时是否依然只读？这些比较棘手也是因为此复杂度吧） 第三，修复机制。Haystack的修复机制依靠周期性后台任务pitchfork和离线bulk重置等。在TFS中： “……Dataserver后台线程介绍……” “……心跳线程……这里的心跳是指Ds向Ns发的周期性统计信息……负责keepalive……汇报block的工作……” “……检查线程……修复check_filequeue中的逻辑块……每次对文件进行读写删操作失败的时候，会try_add_repair_task(blockid, ret)来将ret错误的block加入check_filequeue中……若出错则会请求Ns进行update_block_info……” 除了类似的远程心跳机制，TFS还多了在DataServer上对自身的错误统计和自行恢复，必要时还会请求上级（NameServer）帮助恢复。 文件系统 Haystack提到了预分配、磁盘碎片、XFS等方案，TFS中也有所涉及： “……在!DataServer节点上，在挂载目录上会有很多物理块，物理块以文件的形式存在磁盘上，并在!DataServer部署前预先分配，以保证后续的访问速度和减少碎片产生。为了满足这个特性，!DataServer现一般在EXT4文件系统上运行。物理块分为主块和扩展块，一般主块的大小会远大于扩展块，使用扩展块是为了满足文件更新操作时文件大小的变化。每个Block在文件系统上以“主块+扩展块”的方式存储。每一个Block可能对应于多个物理块，其中包括一个主块，多个扩展块。在DataServer端，每个Block可能会有多个实际的物理文件组成：一个主Physical Block文件，N个扩展Physical Block文件和一个与该Block对应的索引文件……” 各有各的考究吧，比较了解底层的读者可以深入研究下。 删除和压缩Haystack使用软删除（设置flag）、压缩回收来支持delete操作，在TFS中： “……压缩线程（compact_block.cpp）……真正的压缩线程也从压缩队列中取出并进行执行（按文件进行，小文件合成一起发送）。压缩的过程其实和复制有点像，只是说不需要将删除的文件数据以及index数据复制到新创建的压缩块中。要判断某个文件是否被删除，还需要拿index文件的offset去fileinfo里面取删除标记，如果标记不是删除的，那么就可以进行write_raw_data的操作，否则则滤过……” 可见两者大同小异，这也是此类场景中常用的解决机制。 总结本篇论文以long tail无法避免出发，探究了文件元数据导致的I/O瓶颈，推导了海量小文件的存储和检索方案，以及如何与CDN等外部系统配合搭建出整套海量图片服务。其在各个痛点的解决方案以及简约而不简单的设计值得我们学习。文章末尾将这些痛点列出并与淘宝的解决方案逐一对比，以供读者发散。]]></content>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[POI两种读取Excel的方式]]></title>
    <url>%2F2017%2F12%2F18%2Fpoi-read-excel%2F</url>
    <content type="text"><![CDATA[前言在实际项目上遇到了上传 Excel 并解析到数据库中的需求，经分析后选择 Apache POI 来实现，故事也就开始了…… 常规模式123456789101112131415161718192021222324252627282930313233343536373839File file = new File(yourFilepath);FileInputStream is = new FileInputStream(file);Workbook workbook = WorkbookFactory.create(is);FormulaEvaluator formulaEvaluator = workbook.getCreationHelper().createFormulaEvaluator();for (Sheet sheet : workbook) &#123; for (Row row : sheet) &#123; for (Cell cell : row) &#123; // Alternatively, get the value and format it yourself switch (formulaEvaluator.evaluateInCell(cell).getCellTypeEnum()) &#123; case STRING: System.out.println(cell.getRichStringCellValue().getString()); break; case NUMERIC: if (DateUtil.isCellDateFormatted(cell)) &#123; System.out.println(cell.getDateCellValue()); &#125; else &#123; System.out.println(cell.getNumericCellValue()); &#125; break; case BOOLEAN: System.out.println(cell.getBooleanCellValue()); break; case FORMULA: System.out.println(cell.getCellFormula()); break; case BLANK: System.out.println(); break; default: System.out.println(); &#125; &#125; &#125;&#125; 优点：取值方便，可供调用方法多； 缺点：一次性读完值，在读取大量数据时可能会出现堆溢出。 事件驱动模式优点：逐个单元格读取，理论上多大数据都能处理； 缺点：调用方法较少，需要自己动手堆数据进行处理。 查看 Excel XML 映射关系——新增 Excel 后缀名 .zip，打开 xl &gt; worksheets &gt; sheet1.xml ，查看对应的标签节点信息，通过 POI 提供的方法来读取。 Excel XML 片段截取： 1234567891011121314151617181920212223242526&lt;row r="1" spans="1:8" s="4" customFormat="1" ht="18"&gt; &lt;c r="A1" s="3" t="s"&gt; &lt;v&gt;6&lt;/v&gt; &lt;/c&gt; &lt;c r="B1" s="3" t="s"&gt; &lt;v&gt;7&lt;/v&gt; &lt;/c&gt; &lt;c r="C1" s="3" t="s"&gt; &lt;v&gt;8&lt;/v&gt; &lt;/c&gt; &lt;c r="D1" s="3" t="s"&gt; &lt;v&gt;9&lt;/v&gt; &lt;/c&gt; &lt;c r="E1" s="3" t="s"&gt; &lt;v&gt;10&lt;/v&gt; &lt;/c&gt; &lt;c r="F1" s="3" t="s"&gt; &lt;v&gt;11&lt;/v&gt; &lt;/c&gt; &lt;c r="G1" s="3" t="s"&gt; &lt;v&gt;12&lt;/v&gt; &lt;/c&gt; &lt;c r="H1" s="3" t="s"&gt; &lt;v&gt;13&lt;/v&gt; &lt;/c&gt;&lt;/row&gt; 读取 row c r t 等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224public class TestEventModel &#123; // EXCEL 读取文件 public void processOneSheet(String filename) throws Exception &#123; OPCPackage pkg = OPCPackage.open(filename); XSSFReader r = new XSSFReader(pkg); SharedStringsTable sst = r.getSharedStringsTable(); XMLReader parser = fetchSheetParser(sst); InputStream sheet = r.getSheet("rId1"); InputSource sheetSource = new InputSource(sheet); parser.parse(sheetSource); sheet.close(); &#125; public XMLReader fetchSheetParser(SharedStringsTable sst) throws SAXException &#123; XMLReader parser = XMLReaderFactory.createXMLReader("org.apache.xerces.parsers.SAXParser"); ContentHandler handler = new SheetHandler(sst); parser.setContentHandler(handler); return parser; &#125; private static class SheetHandler extends DefaultHandler &#123; private SharedStringsTable sst; private String lastContents; private boolean nextIsString; private int curRowNum = 0; private char nextCell = 'A'; private Map&lt;String, String&gt; rowData = new HashMap&lt;String, String&gt;(); private SheetHandler(SharedStringsTable sst) &#123; this.sst = sst; &#125; // 开始读取 excel xml文件中的标签 public void startElement(String uri, String localName, String name, Attributes attributes) throws SAXException &#123; // 读到了一行 &lt;row&gt;&lt;/row&gt; if (name.equals("row")) &#123; // 取得当前的行数 curRowNum = Integer.parseInt(attributes.getValue("r")); // 将下一列数置为第一列，也就是 excel 中的 A nextCell = 'A'; &#125; // 开始读列数 if (name.equals("c")) &#123; // 取得要读取的列数，值为 EXCEL 的单元格位置 A1 B1 C1 D1... String readCell = attributes.getValue("r"); // 取得当前行的第一列 A1 String curCell = nextCell + String.valueOf(curRowNum); // 循环判断，解决单元格空值被跳过的问题（A4为空的话，A4就不会被 attributes.getValue("r") 取到） // 当被跳过，单元格会错位，这里就进行判断，不相等，那么单元格列数向后 + 1 为实际单元格 while (!curCell.equals(readCell)) &#123; // rowData——把一行单元格里的数据整合到一个 Map 中，key 为列数，值为对应的值 rowData.put(curCell, ""); // 单元格列数加一 nextCell = (char) ((int) nextCell + 1); // 取得当前正确的单元格 curCell = nextCell + String.valueOf(curRowNum); &#125; // 由于当前单元格加一，下一个单元格也要做出对应的改变 nextCell = (char) ((int) nextCell + 1); // 处理单元格数据类型，全当做 string 读出来，之后对应处理 String cellType = attributes.getValue("t"); if (cellType != null &amp;&amp; cellType.equals("s")) &#123; nextIsString = true; &#125; else &#123; nextIsString = false; &#125; &#125; lastContents = ""; &#125; public void endElement(String uri, String localName, String name) throws SAXException &#123; // 结束读取 if (nextIsString) &#123; // 取得单元格里的值作为字符串 int idx = Integer.parseInt(lastContents); lastContents = new XSSFRichTextString(sst.getEntryAt(idx)).toString(); nextIsString = false; &#125; if (name.equals("v")) &#123; // 取当前单元格的位置，并作为 key set 到 rowData 中，完成数据封装 String curCell = (char) ((int) nextCell - 1) + String.valueOf(curRowNum); rowData.put(curCell, lastContents); &#125; // 如果读到行结束 if (name.equals("row")) &#123; // 第一行为表头，不处理 if (curRowNum == 1) &#123; return; &#125; // 循环取 A-H 位置的值，这里要取到的值要写死在长度那，超出的不会写入到数据库 for (int i = (int) 'A'; i &lt;= (int) 'H'; i++) &#123; // 取当前列 String curCell = (char) i + String.valueOf(curRowNum); // 从 rowData 里取出值 String data = rowData.get(curCell); // 如果是单元格内是空格，会出现被置为 null 的情况，这里统一置成空字符串 data = data == null ? "" : data.trim(); switch ((char) i) &#123; case 'A': // 如果 A 列是日期，能处理 yyyy/MM/DD 和 yyyy-MM-dd 两种类型 if (data.equals("")) &#123; // do something setDate(null); &#125; else &#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); Date date; try &#123; date = sdf.parse(data); &#125; catch (ParseException e) &#123; try &#123; date = calculateDate(data); &#125; catch (Exception e1) &#123; // do something for error message continue; &#125; &#125; // do something setDate(date); &#125; break; case 'B': System.out.printf(d); break; case 'C': System.out.printf(d); break; case 'D': System.out.printf(d); break; case 'E': System.out.printf(d); break; case 'F': System.out.printf(d); break; case 'G': System.out.printf(d); break; case 'H': System.out.printf(d); break; &#125; &#125; rowData.clear(); &#125; // 读完 excel 标志 if (name.equals("worksheet")) &#123; System.out.println("读取结束"); &#125; &#125; public void characters(char[] ch, int start, int length) throws SAXException &#123; lastContents += new String(ch, start, length); &#125; private Date calculateDate(String data) throws Exception &#123; if (null == data) &#123; return null; &#125; // 从 1900年到1970年的天数是25569天，减去之后再进行操作 long millisecond = (Long.parseLong(data) - 25569) * 24 * 60 * 60 * 1000; if (millisecond &lt; 0) &#123; return new Date(0); &#125; return new Date(millisecond); &#125; &#125; public static void main(String[] args) throws Exception &#123; TestEventModel testEventModel = new TestEventModel(); testEventModel.processOneSheet(yourFilePath); &#125;&#125;]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL通识-基础应用]]></title>
    <url>%2F2017%2F12%2F14%2Fmysql-tutorial-1%2F</url>
    <content type="text"><![CDATA[基础运维命令连接MySQL1234--本地连接mysql -h localhost -u root -p123--远程连接mysql -h localhost -u root -p123 基本命令一览 命令 说明 show processlist 显示正在执行的SQL，显示完整SQL使用show full processlist show databases 显示所有数据库 用户管理查询MySQL所有用户：12SELECT User, Host, Password FROM mysql.user;SELECT DISTINCT User FROM mysql.user; 添加MySQL用户：1234create user keaimo identified by 'keaimopw';grant all privileges on *.* to keaimo@'%' identified by 'keaimopw';show grants for 'keaimo'; 忘记root密码：方法一 更改配置文件/etc/my.cnf,在[mysqld]的段上加上一句skip-grant-tables保存并退出； 重启MySQL； 登录并修改密码： 1234mysql&gt; USE mysql ; mysql&gt; UPDATE user SET Password=password( 'new-password' ) WHERE User='root'; mysql&gt; flush privileges ; mysql&gt; quit 将MySQL配置改回来； 重启MySQL； 方法二 KILL掉系统里的MySQL进程； 1killall -TERM mysqld 用以下命令启动MySQL，以不检查权限的方式启动(safe_mysqld是mysqld_safe的符号链接)； 1safe_mysqld --skip-grant-tables &amp; 然后用空密码方式使用root用户登录 MySQL； 1mysql -u root 修改root用户的密码； 123mysql&gt; update mysql.user set password=PASSWORD('新密码') where User='root';mysql&gt; flush privileges;mysql&gt; quit 方法三如果系统中没有safe_mysqld，可以使用如下方式恢复： 停止mysqld(您可能有其它的方法,总之停止mysqld的运行就可以了)； 1/etc/init.d/mysql stop 用以下命令启动MySQL，以不检查权限的方式启动； 1mysqld --skip-grant-tables &amp; 然后用空密码方式使用root用户登录 MySQL； 1mysql -u root 修改root用户的密码； 123mysql&gt; update mysql.user set password=PASSWORD('newpassword') where User='root'; mysql&gt; flush privileges; mysql&gt; quit 重新启动MySQL 1/etc/init.d/mysql restart 环境信息MySQL版本信息 Shell命令： 1mysql -V MySQL中： 1mysql&gt; status; help中查找: 1mysql --help | grep Distrib 使用mysql函数： 1mysql&gt; select version(); 实时SQL监控进入Mysql，启用Log功能(general_log=ON)12SHOW VARIABLES LIKE "general_log%"; SET GLOBAL general_log = 'ON'; 设置Log文件地址(所有Sql语句都会在general_log_file里)1SET GLOBAL general_log_file = 'c:\mysql.log'; 查询结果导出到文件1select count(1) from table into outfile '/data/test.xls'; 123456mysql&gt; pager cat &gt; /tmp/test.txt ;PAGER set to 'cat &gt; /tmp/test.txt'# 之后的所有查询结果都自动写入/tmp/test.txt'，并前后覆盖mysql&gt; select * from table ;30 rows in set (0.59 sec)# 在框口不再显示查询结果 直接执行SQL文件第一种方式在未连接数据库的情况下，输入 mysql -h localhost -u root -p 123456 &lt; d:\book.sql 回车即可； 第二种方式在已连接数据库的情况下，此时命令提示符为mysql&gt;，输入 source d:\book.sql 或者 \. d:\book.sql 回车即可。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL通识-SQL]]></title>
    <url>%2F2017%2F12%2F14%2Fmysql-tutorial-3%2F</url>
    <content type="text"><![CDATA[JOININNER JOIN INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。默认为INNER JOIN。 LEFT JOIN LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。 RIGHT JOIN RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。 GROUP BY分组依据为多条件组合成一个条件，当组合条件相同时为一组。 MySql避免重复插入记录提供三种在mysql中避免重复插入记录方法，主要是讲到了ignore,Replace,ON DUPLICATE KEY UPDATE三种方法。 使用ignore关键字如果是用主键primary或者唯一索引unique区分了记录的唯一性,避免重复插入记录可以使用：12INSERT IGNORE INTO `table_name` (`email`, `phone`, `user_id`) VALUES ('test9@163.com', '99999', '9999'); 这样当有重复记录就会忽略,执行后返回数字0。还有个应用就是复制表,避免重复记录：1INSERT IGNORE INTO `table_1` (`name`) SELECT `name` FROM `table_2`; 使用Replace语法格式：123REPLACE INTO `table_name`(`col_name`, ...) VALUES (...);REPLACE INTO `table_name` (`col_name`, ...) SELECT ...;REPLACE INTO `table_name` SET `col_name`='value', REPLACE的运行与INSERT很相像,但是如果旧记录与新记录有相同的值，则在新记录被插入之前，旧记录被删除，即： 尝试把新行插入到表中 当因为对于主键或唯一关键字出现重复关键字错误而造成插入失败时：从表中删除含有重复关键字值的冲突行,再次尝试把新行插入到表中。旧记录与新记录有相同的值的判断标准就是：表有一个PRIMARY KEY或UNIQUE索引，否则，使用一个REPLACE语句没有意义。该语句会与INSERT相同，因为没有索引被用于确定是否新行复制了其它的行。 返回值：REPLACE语句会返回一个数，来指示受影响的行的数目。该数是被删除和被插入的行数的和。受影响的行数可以容易地确定是否REPLACE只添加了一行，或者是否REPLACE也替换了其它行：检查该数是否为1（添加）或更大（替换）。 示例:(phone字段为唯一索引)12REPLACE INTO `table_name` (`email`, `phone`, `user_id`) VALUES ('test569', '99999', '123'); 另外,在 SQL Server 中可以这样处理：1234if not exists (select phone from t where phone= '1') insert into t(phone, update_time) values('1', getdate()) else update t set update_time = getdate() where phone= '1' ON DUPLICATE KEY UPDATE如‍上所写，你也可以在INSERT INTO…..后面加上 ON DUPLICATE KEY UPDATE方法来实现。如果您指定了ON DUPLICATE KEY UPDATE，并且插入行后会导致在一个UNIQUE索引或PRIMARY KEY中出现重复值，则执行旧行UPDATE。例如，如果列a被定义为UNIQUE，并且包含值1，则以下两个语句具有相同的效果：123INSERT INTO `table` (`a`, `b`, `c`) VALUES (1, 2, 3) ON DUPLICATE KEY UPDATE `c`=`c`+1; UPDATE `table` SET `c`=`c`+1 WHERE `a`=1; 如果行作为新记录被插入，则受影响行的值为1；如果原有的记录被更新，则受影响行的值为2。如果列b也是唯一列，则INSERT与此UPDATE语句相当：1UPDATE `table` SET `c`=`c`+1 WHERE `a`=1 OR `b`=2 LIMIT 1; 如果a=1 OR b=2与多个行向匹配，则只有一个行被更新。通常，您应该尽量避免对带有多个唯一关键字的表使用ON DUPLICATE KEY子句。 您可以在UPDATE子句中使用VALUES(col_name)函数从INSERT…UPDATE语句的INSERT部分引用列值。换句话说，如果没有发生重复关键字冲突，则UPDATE子句中的VALUES(col_name)可以引用被插入的col_name的值。本函数特别适用于多行插入。VALUES()函数只在INSERT…UPDATE语句中有意义，其它时候会返回NULL。12INSERT INTO `table` (`a`, `b`, `c`) VALUES (1, 2, 3), (4, 5, 6) ON DUPLICATE KEY UPDATE `c`=VALUES(`a`)+VALUES(`b`); 本语句与以下两个语句作用相同：12INSERT INTO `table` (`a`, `b`, `c`) VALUES (1, 2, 3) ON DUPLICATE KEY UPDATE `c`=3; INSERT INTO `table` (`a`, `b`, `c`) VALUES (4, 5, 6) ON DUPLICATE KEY UPDATE c=9; 注释：当您使用ON DUPLICATE KEY UPDATE时，DELAYED选项被忽略。 示例：这个例子是我在实际项目中用到的：是将一个表的数据导入到另外一个表中，数据的重复性就得考虑(如下)，唯一索引为：email：123456INSERT INTO `table_name1` (`title`, `first_name`, `last_name`, `email`, `phone`, `user_id`, `role_id`, `status`, `campaign_id`) SELECT '', '', '', `table_name2`.`email`, `table_name2`.`phone`, NULL, NULL, 'pending', 29 FROM `table_name2` WHERE `table_name2`.`status` = 1 ON DUPLICATE KEY UPDATE `table_name1`.`status`='pending' 再贴一个例子：12INSERT INTO `class` SELECT * FROM `class1` ON DUPLICATE KEY UPDATE `class`.`course`=`class1`.`course` 其它关键：DELAYED 做为快速插入，并不是很关心失效性，提高插入性能。IGNORE 只关注主键对应记录是不存在，无则添加，有则忽略。 更多信息请看: http://dev.mysql.com/doc/refman/5.1/zh/sql-syntax.html#insert 特别说明：在MYSQL中UNIQUE索引将会对null字段失效，也就是说(a字段上建立唯一索引)：1INSERT INTO `test` (`a`) VALUES (NULL); 是可以重复插入的（联合唯一索引也一样）。 MySQL关联更新假定我们有两张表，一张表为Product表存放产品信息，其中有产品价格列Price；另外一张表是ProductPrice表，我们要将ProductPrice表中的价格字段Price更新为Price表中价格字段的80%。在Mysql中我们有几种手段可以做到这一点。 update table1 t1, table2 ts …1234UPDATE product p, productPrice ppSET pp.price = pp.price * 0.8WHERE p.productId = pp.productIdAND p.dateCreated &lt; '2004-01-01' inner join更新12345UPDATE product pINNER JOIN productPrice ppON p.productId = pp.productIdSET pp.price = pp.price * 0.8WHERE p.dateCreated &lt; '2004-01-01' left outer join我们也可以使用left outer join来做多表update，比方说如果ProductPrice表中没有产品价格记录的话，将Product表的isDeleted字段置为1，如下sql语句：12345UPDATE product pLEFT JOIN productPrice ppON p.productId = pp.productIdSET p.deleted = 1WHERE pp.productId IS null 同时更新2张表面的几个例子都是两张表之间做关联，但是只更新一张表中的记录，其实是可以同时更新两张表的，如下sql：123456UPDATE product pINNER JOIN productPrice ppON p.productId = pp.productIdSET pp.price = pp.price * 0.8,p.dateUpdate = CURDATE()WHERE p.dateCreated &lt; '2004-01-01' 等价示例对单表执行更新没有什么好说的，无非就是update table_name set col1 = xx,col2 = yy where col = zz，主要就是where条件的设置。有时候更新某个表可能会涉及到多张数据表，例如：1update table_1 set score = score + 5 where uid in (select uid from table_2 where sid = 10); 其实update也可以用到left join、inner join来进行关联，可能执行效率更高，把上面的sql替换成join的方式如下：1update table_1 t1 inner join table_2 t2 on t1.uid = t2.uid set score = score + 5 where t2.sid = 10;]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL通识-高可用]]></title>
    <url>%2F2017%2F12%2F14%2Fmysql-tutorial-2%2F</url>
    <content type="text"><![CDATA[二进制日志准备两台MySQL服务器，版本越接近越好 ### 查看二进制日志状态 123show variables like 'log_bin';show variables like '%log_bin%';show variables like 'binlog_format'; ### 开启二进制日志修改my.cnf，在[mysqld]下面增加log_bin=mysql_bin_log，重启MySQL后，你就会发现log_bin变为了ON。如果在my.cnf里面只设置log_bin，但是不指定file_name，然后重启数据库。你会发现二进制日志文件名称为${hostname}-bin 这样的格式。12[mysqld]log_bin=/mysql/bin_log/mysql_binlog ### 查看二进制日志文件 123show binary logs;show master logs;show master status; 切换二进制日志1flush logs; 每次MySQL重启也会生成新的二进制日志文件。 删除二进制日志purge binary logs to xxx;表示删除某个日志之前的所有二进制日志文件。这个命令会修改index中相关数据：1purge binary logs to 'DB-Server-bin.000002'; 清除某个时间点以前的二进制日志文件：1purge binary logs before '2017-03-10 10:10:00'; 清除7天前的二进制日志文件：1purge master logs before date_sub( now( ), interval 7 day); 清除所有的二进制日志文件（当前不存在主从复制关系）:1reset master; 也可以设置expire_logs_days参数，设置自动清理，其默认值为0,表示不启用过期自动删除功能，如果启用了自动清理功能，表示超出此天数的二进制日志文件将被自动删除，自动删除工作通常发生在MySQL启动时或FLUSH日志时。1show variables like 'expire_logs_days'; 查看二进制日志内容show binlog events使用show binlog events方式可以获取当前以及指定binlog的日志，不适宜提取大量日志。SHOW BINLOG EVENTS[IN &#39;log_name&#39;] [FROM pos] [LIMIT [offset,] row_count]。生产环境不要执行这个命令，可能会导致卡死，应该使用limit限制查询大小：123show binlog events;show binlog events in 'DB-Server-bin.000012';show binlog events in 'DB-Server-bin.000012' from 336; mysqlbinlog当bin-log的模式设置为row时不仅日志长得快 并且查看执行的sql时 也稍微麻烦一点：1.干扰语句多；2生成sql的编码需要解码。直接mysqlbinlog出来的文件执行sql部分的sql显示为base64编码格式，故生成sql记录的时候不能用常规的办法去生成，需要加上相应的参数才能显示出sql语句--base64-output=decode-rows -v。使用时可能会报错mysqlbinlog: unknown variable &#39;default-character-set=utf8mb4&#39;，原因是mysqlbinlog这个工具无法识别binlog中的配置中的default-character-set=utf8这个指令，解决的办法有两个: 将/etc/my.cnf中配置的default-character-set = utf8mb4修改为character-set-server = utf8mb4 但是这种修改方法需要重启数据库, 在线上业务库中使用这种方法查看 binlog 日志并不划算 mysqlbinlog –no-defaults mysql-bin.000256 完美解决; 123456789101112131415161718192021222324252627# 提取指定的binlog日志 mysqlbinlog /opt/data/APP01bin.000001 mysqlbinlog /opt/data/APP01bin.000001|grep insert # 提取指定position位置的binlog日志 mysqlbinlog --start-position="120" --stop-position="332" /opt/data/APP01bin.000001 # 提取指定position位置的binlog日志并输出到压缩文件 mysqlbinlog --start-position="120" --stop-position="332" /opt/data/APP01bin.000001 |gzip &gt;extra_01.sql.gz # 提取指定position位置的binlog日志导入数据库 mysqlbinlog --start-position="120" --stop-position="332" /opt/data/APP01bin.000001 | mysql -uroot -p # 提取指定开始时间的binlog并输出到日志文件 mysqlbinlog --start-datetime="2014-12-15 20:15:23" /opt/data/APP01bin.000002 --result-file=extra02.sql # 提取指定位置的多个binlog日志文件 mysqlbinlog --start-position="120" --stop-position="332" /opt/data/APP01bin.000001 /opt/data/APP01bin.000002|more # 提取指定数据库binlog并转换字符集到UTF8 mysqlbinlog --database=test --set-charset=utf8 /opt/data/APP01bin.000001 /opt/data/APP01bin.000002 &gt;test.sql # 远程提取日志，指定结束时间 mysqlbinlog -urobin -p -h192.168.1.116 -P3306 --stop-datetime="2014-12-15 20:30:23" --read-from-remote-server mysql-bin.000033 |more # 远程提取使用row格式的binlog日志并输出到本地文件 mysqlbinlog -urobin -p -P3606 -h192.168.1.177 --read-from-remote-server -vv inst3606bin.000005 &gt;row.sql]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存中的Cache]]></title>
    <url>%2F2017%2F12%2F12%2Flinux-cache%2F</url>
    <content type="text"><![CDATA[在Linux系统中，我们经常用free命令来查看系统内存的使用状态。在一个RHEL6的系统上，free命令的显示内容大概是这样一个状态：12345[root@tencent64 ~]# free total used free shared buffers cachedMem: 132256952 72571772 59685180 0 1762632 53034704-/+ buffers/cache: 17774436 114482516Swap: 2101192 508 2100684 这里的默认显示单位是kb，我的服务器是128G内存，所以数字显得比较大。这个命令几乎是每一个使用过Linux的人必会的命令，但越是这样的命令，似乎真正明白的人越少（我是说比例越少）。一般情况下，对此命令输出的理解可以分这几个层次： 不了解。这样的人的第一反应是：天啊，内存用了好多，70个多G，可是我几乎没有运行什么大程序啊？为什么会这样？Linux好占内存！ 自以为很了解。这样的人一般评估过会说：嗯，根据我专业的眼光看的出来，内存才用了17G左右，还有很多剩余内存可用。buffers/cache占用的较多，说明系统中有进程曾经读写过文件，但是不要紧，这部分内存是当空闲来用的。 真的很了解。这种人的反应反而让人感觉最不懂Linux，他们的反应是：free显示的是这样，好吧我知道了。神马？你问我这些内存够不够，我当然不知道啦！我特么怎么知道你程序怎么写的？ 根据目前网络上技术文档的内容，我相信绝大多数了解一点Linux的人应该处在第二种层次。大家普遍认为，buffers和cached所占用的内存空间是可以在内存压力较大的时候被释放当做空闲空间用的。但真的是这样么？在论证这个题目之前，我们先简要介绍一下buffers和cached是什么意思： 什么是buffer/cachebuffer和cache是两个在计算机技术中被用滥的名词，放在不通语境下会有不同的意义。在Linux的内存管理中，这里的buffer指Linux内存的：Buffer cache。这里的cache指Linux内存中的：Page cache。翻译成中文可以叫做缓冲区缓存和页面缓存。在历史上，它们一个（buffer）被用来当成对io设备写的缓存，而另一个（cache）被用来当作对io设备的读缓存，这里的io设备，主要指的是块设备文件和文件系统上的普通文件。但是现在，它们的意义已经不一样了。在当前的内核中，page cache顾名思义就是针对内存页的缓存，说白了就是，如果有内存是以page进行分配管理的，都可以使用page cache作为其缓存来管理使用。当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到cache功能，则都集中到buffer cache中来使用。（从这个角度出发，是不是buffer cache改名叫做block cache更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在X86上无论是32位还是64位都是4k。 明白了这两套缓存系统的区别，就可以理解它们究竟都可以用来做什么了。 什么是page cachePage cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read／write操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用：mmap是不是很自然的也应该用到page cache？在当前的系统实现里，page cache也被作为其它文件类型的缓存设备来用，所以事实上page cache也负责了大部分的块设备文件的缓存工作。 什么是buffer cacheBuffer cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用buffer cache进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache的内容会被改变，而buffer cache则可以用来将page标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个page写回，而只需要写回修改的部分即可。 如何回收cacheLinux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 但是这种清缓存的工作也并不是没有成本。理解cache是干什么的就可以明白清缓存必须保证cache中的数据跟对应文件中的数据一致，才能对cache进行释放。所以伴随着cache清除的行为的，一般都是系统IO飙高。因为内核要对比cache中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。 在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以使用下面这个文件来人工触发缓存清除的操作：12[root@tencent64 ~]# cat /proc/sys/vm/drop_caches 1 方法是：1echo 1 &gt; /proc/sys/vm/drop_caches 当然，这个文件可以设置的值分别为1、2、3。它们所表示的含义为：echo 1 &gt; /proc/sys/vm/drop_caches:表示清除pagecache。 echo 2 &gt; /proc/sys/vm/drop_caches:表示清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。 echo 3 &gt; /proc/sys/vm/drop_caches:表示清除pagecache和slab分配器中的缓存对象。 cache都能被回收么我们分析了cache能被回收的情况，那么有没有不能被回收的cache呢？当然有。我们先来看第一种情况： tmpfs大家知道Linux提供一种“临时”文件系统叫做tmpfs，它可以将内存的一部分空间拿来当做文件系统使用，使内存空间可以当做目录文件来用。现在绝大多数Linux系统都有一个叫做/dev/shm的tmpfs目录，就是这样一种存在。当然，我们也可以手工创建一个自己的tmpfs，方法如下： 12345678910[root@tencent64 ~]# mkdir /tmp/tmpfs[root@tencent64 ~]# mount -t tmpfs -o size=20G none /tmp/tmpfs/[root@tencent64 ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda1 10325000 3529604 6270916 37% //dev/sda3 20646064 9595940 10001360 49% /usr/local/dev/mapper/vg-data 103212320 26244284 71725156 27% /datatmpfs 66128476 14709004 51419472 23% /dev/shmnone 20971520 0 20971520 0% /tmp/tmpfs 于是我们就创建了一个新的tmpfs，空间是20G，我们可以在/tmp/tmpfs中创建一个20G以内的文件。如果我们创建的文件实际占用的空间是内存的话，那么这些数据应该占用内存空间的什么部分呢？根据pagecache的实现功能可以理解，既然是某种文件系统，那么自然该使用pagecache的空间来管理。我们试试是不是这样？123456789101112131415[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 36 89 0 1 19-/+ buffers/cache: 15 111Swap: 2 0 2[root@tencent64 ~]# dd if=/dev/zero of=/tmp/tmpfs/testfile bs=1G count=1313+0 records in13+0 records out13958643712 bytes (14 GB) copied, 9.49858 s, 1.5 GB/s[root@tencent64 ~]# [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 49 76 0 1 32-/+ buffers/cache: 15 110Swap: 2 0 2 我们在tmpfs目录下创建了一个13G的文件，并通过前后free命令的对比发现，cached增长了13G，说明这个文件确实放在了内存里并且内核使用的是cache作为存储。再看看我们关心的指标： -/+ buffers/cache那一行。我们发现，在这种情况下free命令仍然提示我们有110G内存可用，但是真的有这么多么？我们可以人工触发内存回收看看现在到底能回收多少内存：123456[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 43 82 0 0 29-/+ buffers/cache: 14 111Swap: 2 0 2 可以看到，cached占用的空间并没有像我们想象的那样完全被释放，其中13G的空间仍然被/tmp/tmpfs中的文件占用的。当然，我的系统中还有其他不可释放的cache占用着其余16G内存空间。那么tmpfs占用的cache空间什么时候会被释放呢？是在其文件被删除的时候.如果不删除文件，无论内存耗尽到什么程度，内核都不会自动帮你把tmpfs中的文件删除来释放cache空间。 123456[root@tencent64 ~]# rm /tmp/tmpfs/testfile [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 这是我们分析的第一种cache不能被回收的情况。还有其他情况，比如： 共享内存共享内存是系统提供给我们的一种常用的进程间通信（IPC）方式，但是这种通信方式不能在shell中申请和使用，所以我们需要一个简单的测试程序，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778[root@tencent64 ~]# cat shm.c #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;string.h&gt;#define MEMSIZE 2048*1024*1023intmain()&#123; int shmid; char *ptr; pid_t pid; struct shmid_ds buf; int ret; shmid = shmget(IPC_PRIVATE, MEMSIZE, 0600); if (shmid&lt;0) &#123; perror("shmget()"); exit(1); &#125; ret = shmctl(shmid, IPC_STAT, &amp;buf); if (ret &lt; 0) &#123; perror("shmctl()"); exit(1); &#125; printf("shmid: %d\n", shmid); printf("shmsize: %d\n", buf.shm_segsz); buf.shm_segsz *= 2; ret = shmctl(shmid, IPC_SET, &amp;buf); if (ret &lt; 0) &#123; perror("shmctl()"); exit(1); &#125; ret = shmctl(shmid, IPC_SET, &amp;buf); if (ret &lt; 0) &#123; perror("shmctl()"); exit(1); &#125; printf("shmid: %d\n", shmid); printf("shmsize: %d\n", buf.shm_segsz); pid = fork(); if (pid&lt;0) &#123; perror("fork()"); exit(1); &#125; if (pid==0) &#123; ptr = shmat(shmid, NULL, 0); if (ptr==(void*)-1) &#123; perror("shmat()"); exit(1); &#125; bzero(ptr, MEMSIZE); strcpy(ptr, "Hello!"); exit(0); &#125; else &#123; wait(NULL); ptr = shmat(shmid, NULL, 0); if (ptr==(void*)-1) &#123; perror("shmat()"); exit(1); &#125; puts(ptr); exit(0); &#125;&#125; 程序功能很简单，就是申请一段不到2G共享内存，然后打开一个子进程对这段共享内存做一个初始化操作，父进程等子进程初始化完之后输出一下共享内存的内容，然后退出。但是退出之前并没有删除这段共享内存。我们来看看这个程序执行前后的内存使用： 12345678910111213141516[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2[root@tencent64 ~]# ./shm shmid: 294918shmsize: 2145386496shmid: 294918shmsize: -4194304Hello![root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2 cached空间由16G涨到了18G。那么这段cache能被回收么？继续测试： 123456[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2 结果是仍然不可回收。大家可以观察到，这段共享内存即使没人使用，仍然会长期存放在cache中，直到其被删除。删除方法有两种，一种是程序中使用shmctl()去IPC_RMID，另一种是使用ipcrm命令。我们来删除试试： 1234567891011121314151617181920212223242526272829[root@tencent64 ~]# ipcs -m------ Shared Memory Segments --------key shmid owner perms bytes nattch status 0x00005feb 0 root 666 12000 4 0x00005fe7 32769 root 666 524288 2 0x00005fe8 65538 root 666 2097152 2 0x00038c0e 131075 root 777 2072 1 0x00038c14 163844 root 777 5603392 0 0x00038c09 196613 root 777 221248 0 0x00000000 294918 root 600 2145386496 0 [root@tencent64 ~]# ipcrm -m 294918[root@tencent64 ~]# ipcs -m------ Shared Memory Segments --------key shmid owner perms bytes nattch status 0x00005feb 0 root 666 12000 4 0x00005fe7 32769 root 666 524288 2 0x00005fe8 65538 root 666 2097152 2 0x00038c0e 131075 root 777 2072 1 0x00038c14 163844 root 777 5603392 0 0x00038c09 196613 root 777 221248 0 [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 删除共享内存后，cache被正常释放了。这个行为与tmpfs的逻辑类似。内核底层在实现共享内存（shm）、消息队列（msg）和信号量数组（sem）这些POSIX:XSI的IPC机制的内存存储时，使用的都是tmpfs。这也是为什么共享内存的操作逻辑与tmpfs类似的原因。当然，一般情况下是shm占用的内存更多，所以我们在此重点强调共享内存的使用。说到共享内存，Linux还给我们提供了另外一种共享内存的方法，就是： mmapmmap()是一个非常重要的系统调用，这仅从mmap本身的功能描述上是看不出来的。从字面上看，mmap就是将一个文件映射进进程的虚拟内存地址，之后就可以通过操作内存的方式对文件的内容进行操作。但是实际上这个调用的用途是很广泛的。当malloc申请内存时，小段内存内核使用sbrk处理，而大段内存就会使用mmap。当系统调用exec族函数执行时，因为其本质上是将一个可执行文件加载到内存执行，所以内核很自然的就可以使用mmap方式进行处理。我们在此仅仅考虑一种情况，就是使用mmap进行共享内存的申请时，会不会跟shmget()一样也使用cache？ 同样，我们也需要一个简单的测试程序：12345678910111213141516171819202122232425262728293031323334353637383940[root@tencent64 ~]# cat mmap.c #include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;strings.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#define MEMSIZE 1024*1024*1023*2#define MPFILE "./mmapfile"int main()&#123; void *ptr; int fd; fd = open(MPFILE, O_RDWR); if (fd &lt; 0) &#123; perror("open()"); exit(1); &#125; ptr = mmap(NULL, MEMSIZE, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANON, fd, 0); if (ptr == NULL) &#123; perror("malloc()"); exit(1); &#125; printf("%p\n", ptr); bzero(ptr, MEMSIZE); sleep(100); munmap(ptr, MEMSIZE); close(fd); exit(1);&#125; 这次我们干脆不用什么父子进程的方式了，就一个进程，申请一段2G的mmap共享内存，然后初始化这段空间之后等待100秒，再解除影射所以我们需要在它sleep这100秒内检查我们的系统内存使用，看看它用的是什么空间？当然在这之前要先创建一个2G的文件./mmapfile。结果如下：1234567[root@tencent64 ~]# dd if=/dev/zero of=mmapfile bs=1G count=2[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 然后执行测试程序： 123456789101112131415[root@tencent64 ~]# ./mmap &amp;[1] 191570x7f1ae3635000[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2 我们可以看到，在程序执行期间，cached一直为18G，比之前涨了2G，并且此时这段cache仍然无法被回收。然后我们等待100秒之后程序结束。 12345678[root@tencent64 ~]# [1]+ Exit 1 ./mmap[root@tencent64 ~]# [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 程序退出之后，cached占用的空间被释放。这样我们可以看到，使用mmap申请标志状态为MAP_SHARED的内存，内核也是使用的cache进行存储的。在进程对相关内存没有释放之前，这段cache也是不能被正常释放的。实际上，mmap的MAP_SHARED方式申请的内存，在内核中也是由tmpfs实现的。由此我们也可以推测，由于共享库的只读部分在内存中都是以mmap的MAP_SHARED方式进行管理，实际上它们也都是要占用cache且无法被释放的。 最后我们通过三个测试例子，发现Linux系统内存中的cache并不是在所有情况下都能被释放当做空闲空间用的。并且也也明确了，即使可以释放cache，也并不是对系统来说没有成本的。总结一下要点，我们应该记得这样几点： 当cache作为文件缓存被释放的时候会引发IO变高，这是cache加快文件访问速度所要付出的成本。 tmpfs中存储的文件会占用cache空间，除非文件删除否则这个cache不会被自动释放。 使用shmget方式申请的共享内存会占用cache空间，除非共享内存被ipcrm或者使用shmctl去IPC_RMID，否则相关的cache空间都不会被自动释放。 使用mmap方法申请的MAP_SHARED标志的内存会占用cache空间，除非进程将这段内存munmap，否则相关的cache空间都不会被自动释放。 实际上shmget、mmap的共享内存，在内核层都是通过tmpfs实现的，tmpfs实现的存储用的都是cache。 当理解了这些的时候，希望大家对free命令的理解可以达到我们说的第三个层次。我们应该明白，内存的使用并不是简单的概念，cache也并不是真的可以当成空闲空间用的。如果我们要真正深刻理解你的系统上的内存到底使用的是否合理，是需要理解清楚很多更细节知识，并且对相关业务的实现做更细节判断的。我们当前实验场景是Centos 6的环境，不同版本的Linux的free现实的状态可能不一样，大家可以自己去找出不同的原因。 当然，本文所述的也不是所有的cache不能被释放的情形。那么，在你的应用场景下，还有那些cache不能被释放的场景呢？]]></content>
      <categories>
        <category>Linux运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java关键字通识]]></title>
    <url>%2F2017%2F12%2F11%2Fjava-keywords%2F</url>
    <content type="text"><![CDATA[strictfpstrictfp的意思是FP-strict，也就是说精确浮点的意思。在Java虚拟机进行浮点运算时，如果没有指定strictfp关键字时，Java的编译器以及运行环境在对浮点运算的表达式是采取一种近似于我行我素的行为来完成这些操作，以致于得到的结果往往无法令你满意。而一旦使用了strictfp来声明一个类、接口或者方法时，那么所声明的范围内Java的编译器以及运行环境会完全依照浮点规范IEEE-754来执行。因此如果你想让你的浮点运算更加精确，而且不会因为不同的硬件平台所执行的结果不一致的话，那就请用关键字strictfp。 strictfp不能解决所谓”精确“问题，是用来保证可移植性的。如果没有加strictfp关键字，在不同的平台下面，可能会得到不同的结果。使用strictfp关键字的目的，是保证平台移植之后，浮点运算结果是一致的。如果要进行精确的金额计算，还是需要使用BigDecimal。 transient变量修饰符(只能修饰字段)。标记为transient的变量，在对象存储时，这些变量状态不会被持久化。当对象序列化的保存在存储器上时，不希望有些字段数据被保存，为了保证安全性，可以把这些字段声明为transient。 volatilevolatile修饰变量。在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 Java内存模型规定了所有变量都存储在主内存中，每条线程都有自己的工作内存，线程的工作内存保存了被该线程使用到变量的主内存副本拷贝，线程对变量的所有操作(读取,赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程也不能直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 当一个变量定义成volatile之后, 保证了此变量对所有线程的可见性,也就是说当一条线程修改了这个变量的值,新的值对于其它线程来说是可以立即得知的.此时,该变量的读写操作直接在主内存中完成。Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取－修改－写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。 在多线程并发的环境下, 各个线程的读/写操作可能有重叠现象, 在这个时候, volatile并不能保证数据同步。 volatile适用于简单的标志量的场景中。如：12345678910public class CheesyCounter &#123; private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; synchronized通过 synchronized 关键字来实现，所有加上synchronized 和 块语句，在多线程访问的时候，同一时刻只能有一个线程能够用。synchronized用来修饰方法或者代码块。]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java多线程常识]]></title>
    <url>%2F2017%2F12%2F09%2Fjava-multithreading-common-sense%2F</url>
    <content type="text"><![CDATA[线程安全给线程安全下定义比较困难。存在很多种定义，如：“一个类在可以被多个线程安全调用时就是线程安全的”。 静态变量使用static关键字定义的变量。static可以修饰变量和方法，也有static静态代码块。被static修饰的成员变量和成员方法独立于该类的任何对象。也就是说，它不依赖类特定的实例，被类的所有实例共享。只要这个类被加载，Java虚拟机就能根据类名在运行时数据区的方法区内定找到他们。因此，static对象可以在它的任何对象创建之前访问，无需引用任何对象。静态变量通常用于对象间共享值、方便访问变量等场景。静态变量即类变量，位于方法区，为所有对象共享，共享一份内存，一旦静态变量被修改，其他对象均对修改可见，静态变量是非线程安全的。 实例变量单例模式（只有一个对象实例存在）线程非安全，非单例线程安全。 实例变量为对象实例私有，在虚拟机的堆中分配，若在系统中只存在一个此对象的实例，在多线程环境下，“犹如”静态变量那样，被某个线程修改后，其他线程对修改均可见，故线程非安全；如果每个线程执行都是在不同的对象中，那对象与对象之间的实例变量的修改将互不影响，故线程安全。 局部变量线程安全。每个线程执行时将会把局部变量放在各自栈帧的工作内存中，线程间不共享，故不存在线程安全问题。 线程安全的单例模式单例模式是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例类的特殊类。通过单例模式可以保证系统中一个类只有一个实例而且该实例易于外界访问，从而方便对实例个数的控制并节约系统资源。如果希望在系统中某个类的对象只能存在一个，单例模式是最好的解决方案。 Double Check在 Effecitve Java 一书的第 48 条中提到了双重检查模式，并指出这种模式在 Java 中通常并不适用。该模式的结构如下所示：12345678910public Resource getResource() &#123; if (resource == null) &#123; synchronized(this)&#123; if (resource==null) &#123; resource = new Resource(); &#125; &#125; &#125; return resource;&#125; 该模式是对下面的代码改进：123456public synchronized Resource getResource()&#123; if (resource == null)&#123; resource = new Resource(); &#125; return resource;&#125; 这段代码的目的是对 resource 延迟初始化。但是每次访问的时候都需要同步。为了减少同步的开销，于是有了双重检查模式。在 Java 中双重检查模式无效的原因是在不同步的情况下引用类型不是线程安全的。对于除了 long 和 double 的基本类型，双重检查模式是适用 的。比如下面这段代码就是正确的：1234567891011private int count;public int getCount()&#123; if (count == 0)&#123; synchronized(this)&#123; if (count == 0)&#123; count = computeCount(); //一个耗时的计算 &#125; &#125; &#125; return count;&#125; 上面就是关于java中双重检查模式（double-check idiom）的一般结论。但是事情还没有结束，因为java的内存模式也在改进中。Doug Lea 在他的文章中写道：“根据最新的 JSR133 的 Java 内存模型，如果将引用类型声明为 volatile，双重检查模式就可以工作了”，参见 http://gee.cs.oswego.edu/dl/cpj/updates.html 。所以以后要在 Java 中使用双重检查模式，可以使用下面的代码：1234567891011private volatile Resource resource;public Resource getResource()&#123; if (resource == null)&#123; synchronized(this)&#123; if (resource==null)&#123; resource = new Resource(); &#125; &#125; &#125; return resource;&#125; 当然了，得是在遵循 JSR133 规范的 Java 中。所以，double-check 在 J2SE 1.4 或早期版本在多线程或者 JVM 调优时由于 out-of-order writes，是不可用的。 这个问题在 J2SE 5.0 中已经被修复，可以使用 volatile 关键字来保证多线程下的单例。12345678910111213public class Singleton &#123; private volatile Singleton instance = null; public Singleton getInstance() &#123; if (instance == null) &#123; synchronized(this) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; IODH推荐方法 是Initialization on Demand Holder（IODH），详见 http://en.wikipedia.org/wiki/Initialization_on_demand_holder_idiom12345678910public class Singleton &#123; static class SingletonHolder &#123; static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHolder.instance; &#125;&#125; 编译并运行上述代码，运行结果为：true，即创建的单例对象s1和s2为同一对象。由于静态单例对象没有作为Singleton的成员变量直接实例化，因此类加载时不会实例化Singleton，第一次调用getInstance()时将加载内部类SingletonHolder，在该内部类中定义了一个static类型的变量instance，此时会首先初始化这个成员变量，由Java虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于getInstance()方法没有任何线程锁定，因此其性能不会造成任何影响。通过使用IoDH，我们既可以实现延迟加载，又可以保证线程安全，不影响系统性能，不失为一种最好的Java语言单例模式实现方式（其缺点是与编程语言本身的特性相关，很多面向对象语言不支持IoDH）。 线程池Java通过Executors提供四种线程池，分别为：newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 ExecutorServiceExecutorServcie中执行一个Runnable有两个方法，两个分别是：12public void execute(Runnable command);public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); 其实submit最后是调用的execute的，而且在调用execute前，对task进行了一次封装，变成了RunnableFuture。 executesubmit创建线程池newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。示例代码如下：123456789101112131415161718192021package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; System.out.println(index); &#125; &#125;); &#125; &#125; &#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下：123456789101112131415161718192021package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 因为线程池大小为3，每个任务输出index后sleep 2秒，所以每两秒打印3个数字。定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors() newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下：1234567891011121314package test; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.schedule(new Runnable() &#123; public void run() &#123; System.out.println("delay 3 seconds"); &#125; &#125;, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟3秒执行。定期执行示例代码如下：1234567891011121314package test; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; public void run() &#123; System.out.println("delay 1 seconds, and excute every 3 seconds"); &#125; &#125;, 1, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟1秒后每3秒执行一次。 newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下：123456789101112131415161718192021package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 结果依次输出，相当于顺序执行各个任务。你可以使用JDK自带的监控工具来监控我们创建的线程数量，运行一个不终止的线程，创建指定量的线程，来观察：工具目录：C:\Program Files\Java\jdk1.6.0_06\bin\jconsole.exe运行程序做稍微修改：12345678910111213141516171819202122232425262728package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService singleThreadExecutor = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; while(true) &#123; System.out.println(index); Thread.sleep(10 * 1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java内存分析]]></title>
    <url>%2F2017%2F12%2F08%2Fjava-memory-analysis%2F</url>
    <content type="text"><![CDATA[内存分析通过top命令定位占用大内存的应用，通过jps命令找到应用进程号。打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。 jmapjmap命令(Java Memory Map) jmap -heap [pid] 查看整个JVM内存状态; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Attaching to process ID 22999, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.80-b11using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2065694720 (1970.0MB) NewSize = 1310720 (1.25MB) MaxNewSize = 17592186044415 MB OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 21757952 (20.75MB) MaxPermSize = 85983232 (82.0MB) G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 24117248 (23.0MB) used = 8397088 (8.008087158203125MB) free = 15720160 (14.991912841796875MB) 34.81777025305706% usedFrom Space: capacity = 524288 (0.5MB) used = 98304 (0.09375MB) free = 425984 (0.40625MB) 18.75% usedTo Space: capacity = 524288 (0.5MB) used = 0 (0.0MB) free = 524288 (0.5MB) 0.0% usedPS Old Generation capacity = 85983232 (82.0MB) used = 44148184 (42.102989196777344MB) free = 41835048 (39.897010803222656MB) 51.34510877655774% usedPS Perm Generation capacity = 39321600 (37.5MB) used = 39033120 (37.224884033203125MB) free = 288480 (0.275115966796875MB) 99.266357421875% used19166 interned Strings occupying 1688912 bytes. jmap -histo [pid] 查看JVM堆中对象详细占用情况 1234567891011121314151617num #instances #bytes class name---------------------------------------------- 1: 10823 3072312 [B 2: 16605 2318720 &lt;constMethodKlass&gt; 3: 18687 1388088 [C 4: 16605 1328608 &lt;methodKlass&gt; 5: 27595 1296832 &lt;symbolKlass&gt; 6: 1699 940392 &lt;constantPoolKlass&gt; 7: 2520 883408 [I 8: 1699 724944 &lt;instanceKlassKlass&gt; 9: 1472 565136 &lt;constantPoolCacheKlass&gt;10: 256 561152 [Lnet.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry;11: 12148 291552 java.lang.String12: 4505 288320 net.sf.ehcache.Element13: 7290 233280 java.lang.ThreadLocal$ThreadLocalMap$Entry14: 1946 186816 java.lang.Class15: 4509 180360 net.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry 其中[开头表示数组，[C [I [B 分别是char[] int[] byte[]。constMethodKlass、都实现自sun.jvm.hotspot.oops.Klass，用于在永久代里保存类的信息。 jmap -dump:format=b,file=文件名 [pid] 导出整个JVM 中内存信息,通过jhat启动一个Web Server（端口7000）查看分析结果：12jmap -dump:file=a.txt 22999jhat -J-Xmx512m a.txt kill -3 [pid]在Linux 上找到Java所在的进程号，然后执行以上命令，线程的相关信息就输出到console。inux的kill -3指令可以帮我们输出当前进程中所有线程的状态，如哪些线程在运行，哪些在等待，因为什么等待，代码哪一行等待。kill -3会将信息输出至控制台，所以使用时，被kill -3的进程最好是nohup启动的。kill -3并不会影响程序运行，不用担心他把程序杀死了。PS: 需要-Xrs JVM选择被使用。 jstackjstack 是sun JDK 自带的工具，通过该工具可以看到JVM 中线程的运行状况，包括锁等待，线程是否在运行。]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux运维基础]]></title>
    <url>%2F2017%2F12%2F08%2Flinux-ops-base%2F</url>
    <content type="text"><![CDATA[常用命令 命令 用法 ls ls -lha (以mb为单位显示) 磁盘管理查看文件(夹)所在分区(挂载点)1234df /pathcat /etc/mtabmountfdisk -l 查找大文件/文件夹：1234find . -type f -size +800Mfind . -type f -size +800M -print0 | xargs -0 ls -lfind . -type f -size +800M -print0 | xargs -0 du -hfind . -type f -size +800M -print0 | xargs -0 du -h | sort -nr 运行状态TOP查看系统运行情况： 输入大写P，结果按CPU占用降序排序； 输入大写M，结果按内存占用降序排序； NFS12 网络安全当VPS暴露在外网中，就会有人不断暴力破解你的SSH登录。于是就有必要使用SSH密钥来登录。并关闭密码登录。用以下命令可以查看别人暴力破解你SSH密码登录的大概情况：1grep "Failed password for invalid user" /var/log/secure | awk '&#123;print $13&#125;' | sort | uniq -c | sort -nr | more 这时可以使用SSH秘钥登录来防止暴力破解。]]></content>
      <categories>
        <category>Linux运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[iframe无刷新跨域上传文件并获取返回值]]></title>
    <url>%2F2017%2F12%2F08%2Fweb-upfile-iframe%2F</url>
    <content type="text"><![CDATA[通常我们会有一个统一的上传接口，这个接口会被其他的服务调用。如果出现不同域，还需要无刷新上传文件，并且获取返回值，这就有点麻烦了。比如，新浪微博启用了新域名www.weibo.com，但接口还是使用原来的域：picupload.t.sina.com.cn。 研究了一下新浪微博的处理方法，这里大概演示一下。 首先是一个正常的上传页面 upload.html 123456789101112131415&lt;script&gt; // 这个函数将来会被iframe用到 function getIframeVal(val) &#123; alert(val); &#125;&lt;/script&gt;&lt;!-- 我把upload.com指向了127.0.0.1 --&gt;&lt;form method="post" target="if" enctype="multipart/form-data" action="http://upload.com/playground/js/deal.php?cb=http://localhost/playground/js/deal_cd.html"&gt; &lt;input type="file" name="file" /&gt; &lt;input type="SUBMIT" value="upload" /&gt;&lt;/form&gt;&lt;IFRAME id="if" name="if" src="about:blank" frameborder='0'&gt;&lt;/IFRAME&gt; 这里有一个关键点是form的target要指向iframe，同时把iframe隐藏起来，这样上传的处理结果就会显示在该iframe里。action里的cb(callback)参数表示处理完成后要跳转的url，因为我们的目标是iframe，所以只会把跳转的页面输出到iframe，而不会让当前页面跳转。 还有一点，callback url要和当前页面同域。跨域的iframe无法调用父页面的内容。 再来看看deal.php，也就是form的action 1234&lt;?php// deal upload file// and get file id, you can pass other params eitherheader('location:'.$_GET['cb'].'?file_id=123'); 这里可以处理文件，然后入库。操作完成后，把文件的id及其他信息都放在url里，最后跳转到这个url。 最后来看看deal_cd.html，也就是刚刚deal.php跳转到的url，这个文件的内容会填充到页面的iframe里。 1234&lt;script type="text/javascript"&gt; var rs = window.location.search.split('?').slice(1); window.parent.getIframeVal(rs.toString().split('=').slice(1));&lt;/script&gt; 这里调用了父窗口的getIframeVal方法，这样父页面就获得了文件的id。]]></content>
      <tags>
        <tag>软件开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find命令-print0和xargs中-0的奥妙]]></title>
    <url>%2F2017%2F12%2F08%2Flinux-find-xargs%2F</url>
    <content type="text"><![CDATA[-print0默认情况下, find 每输出一个文件名, 后面都会接着输出一个换行符 (‘\n’), 因此我们看到的 find 的输出都是一行一行的: 12345678[bash-4.1.5] ; ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:09 file1.log-rw-r--r-- 1 root root 0 2010-08-02 18:09 file2.log[bash-4.1.5] ; find -name '*.log'./file2.log./file1.log 比如我想把所有的 .log 文件删掉, 可以这样配合 xargs 一起用:12345[bash-4.1.5] ; find -name '*.log'./file2.log./file1.log[bash-4.1.5] ; find -name '*.log' | xargs rm[bash-4.1.5] ; find -name '*.log' find+xargs 真的很强大. 然而: 123456789101112[bash-4.1.5] ; ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 1.log-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 2.log[bash-4.1.5] ; find -name '*.log'./file 1.log./file 2.log[bash-4.1.5] ; find -name '*.log' | xargs rmrm: cannot remove `./file': No such file or directoryrm: cannot remove `1.log': No such file or directoryrm: cannot remove `./file': No such file or directoryrm: cannot remove `2.log': No such file or directory 原因其实很简单, xargs 默认是以空白字符 (空格, TAB, 换行符) 来分割记录的, 因此文件名 ./file 1.log 被解释成了两个记录 ./file 和 1.log, 不幸的是 rm 找不到这两个文件. 为了解决此类问题, 聪明的人想出了一个办法, 让 find 在打印出一个文件名之后接着输出一个 NULL 字符 (‘\0’) 而不是换行符, 然后再告诉 xargs 也用 NULL 字符来作为记录的分隔符. 这就是 find 的 -print0 和 xargs 的 -0 的来历吧. 1234567891011[bash-4.1.5] ; ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 1.log-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 2.log[bash-4.1.5] ; find -name '*.log' -print0 | hd 0 1 2 3 4 5 6 7 8 9 A B C D E F |0123456789ABCDEF|--------+--+--+--+--+---+--+--+--+---+--+--+--+---+--+--+--+--+----------------|00000000: 2e 2f 66 69 6c 65 20 31 2e 6c 6f 67 00 2e 2f 66 |./file 1.log../f|00000010: 69 6c 65 20 32 2e 6c 6f 67 00 |ile 2.log. |[bash-4.1.5] ; find -name '*.log' -print0 | xargs -0 rm[bash-4.1.5] ; find -name '*.log' 你可能要问了, 为什么要选 ‘\0’ 而不是其他字符做分隔符呢? 这个也容易理解: 一般的编程语言中都用 ‘\0’ 来作为字符串的结束标志, 文件的路径名中不可能包含 ‘\0’ 字符. find|xargs实例查找当前目录大文件并按大小排序：1234find . -type f -size +800Mfind . -type f -size +800M -print0 | xargs -0 ls -lfind . -type f -size +800M -print0 | xargs -0 du -hfind . -type f -size +800M -print0 | xargs -0 du -h | sort -nr 查找Linux下大目录：1234du -h --max-depth=1du -h --max-depth=2 | sort -ndu -hm --max-depth=2 | sort -ndu -hm --max-depth=2 | sort -nr | head -12 删除以html结尾的10天前的文件，包括带空格的文件：12find /usr/local/backups -name &quot;*.html&quot; -mtime +10 -print0 |xargs -0 rm -rfvfind /usr/local/backups -mtime +10 -name &quot;*.html&quot; -exec rm -rf &#123;&#125; \; 当前目录下文件从大到小排序（包括隐藏文件），文件名不为”.”：12find . -maxdepth 1 ! -name &quot;.&quot; -print0 | xargs -0 du -b | sort -nr | head -10 | nlnl：可以为输出列加上编号,与cat -n相似，但空行不编号 以下功能同上，但不包括隐藏文件：1for file in *; do du -b "$file"; done|sort -nr|head -10|nl xargs结合sed替换：1find . -name "*.txt" -print0 | xargs -0 sed -i 's/aaa/bbb/g' xargs结合grep：1find . -name '*.txt' -type f -print0 |xargs -0 grep -n 'aaa' #“-n”输出行号 用rm删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用xargs去避免这个问题(xargs -0将\0作为定界符)：1find . -type f -name "*.log" -print0 | xargs -0 rm -f]]></content>
      <categories>
        <category>Linux命令</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[单点登录解决方案]]></title>
    <url>%2F2017%2F12%2F05%2Fsso-arch%2F</url>
    <content type="text"><![CDATA[什么是SSOWeb应用系统的演化总是从简单到复杂，从单功能到多功能模块再到多子系统方向发展。当前的大中型Web互联网应用基本都是多系统组成的应用群，由多个web系统协同为用户提供服务。多系统应用群，必然意味着各系统间既相对独立，又保持着某种联系。独立，意味着给用户提供一个相对完整的功能服务，比如C2C商城，比如B2C商城。联系，意味着从用户角度看，不管企业提供的服务如何多样化、系列化，在用户看来，仍旧是一个整体，用户体验不能受到影响。譬如用户的账号管理，用户应该有一个统一账号，不应该让用户在每个子系统分别注册、分别登录、再分别登出。系统的复杂性不应该让用户承担。登录用户使用系统服务，可以看做是一次用户会话过程。在单Web应用中，用户登录、登录状态判断、用户登出等操作，已有很常规的解决方案实现。在多系统应用群中，这个问题就变得有些复杂，以前本不是问题的问题，现在可能就变成了一个重大技术问题。我们要用技术手段，屏蔽系统底层本身的技术复杂性，给用户提供自然超爽的用户体验。这就是的单点登录问题，即SSO(Single Sign On)。我们这里主要讨论Web系统，应该叫Web SSO。 实际案例例如阿里系统种类繁多，典型系统应用www.taobao.com 淘宝应用、www.tmall.com 天猫应用、www.alitrip.com 阿里旅游。这些应用，当用户访问时，都需要登录。当我在一个应用如淘宝上登录后，再访问阿里旅游、天猫等其它系统，我们发现，系统都显示已登录状态。当在任意一系统退出登录后，再刷新访问其它系统，均已显示登出状态。可以看出，阿里实现了SSO。实际上，几乎所有提供复杂服务的互联网公司，都实现了SSO，如阿里、百度、新浪、网易、腾讯、58…SSO问题，是大中型Web应用经常碰到的问题，是Java架构师需要掌握的必备技能之一，中高级以上Web工程师都应对它有个了解。 SSO技术难点SSO有啥技术难点？为什么我们不能像解决单Web应用系统登录那样自然解决？为说清楚这一问题，我们得先了解下单应用系统下，用户登录的解决方案。 单应用系统登录我们讨论的应用是Web应用，大家知道，对于Web应用，系统是Browser/Server架构，Browser和Server之间的通信协议是HTTP协议。HTTP是一个无状态协议。即对服务器来说，每次收到的浏览器HTTP请求都是单一独立的，服务器并不考虑两次HTTP请求是否来自同一会话，即HTTP协议是非连接会话状态协议。对于Web应用登录，意味着登录成功后的后续访问，可以看做是登录用户和服务端的一次会话交互过程，直到用户登出结束会话。如何在非连接会话协议之上，实现这种会话的管理？ 我们需要额外的手段。通常有两种做法，一种是通过使用HTTP请求参数传递，这种方式对应用侵入性较大，一般不使用。另一种方式就是通过cookie。cookie是HTTP提供的一种机制，cookie代表一小撮数据。服务端通过HTTP响应创建好cookie后，浏览器会接收下来，下次请求会自动携带上返回给服务端。利用这个机制，我们可以实现应用层的登录会话状态管理。例如我们可以把登录状态信息保存在cookie中，这是客户端保存方式。由于会话信息在客户端，需要维护其安全性、需要加密保存、携带量会变大，这样会影响http的处理效率，同时cookie的数据携带量也有一定的限制。比较好的方式是服务端保存，cookie只保存会话信息的句柄。即在登录成功后，服务端可以创建一个唯一登录会话，并把会话标识ID通过cookie返回给浏览器，浏览器下次访问时会自动带上这个ID，服务端根据ID即可判断是此会话中的请求，从而判断出是该用户，这种操作直到登出销毁会话为止。令人高兴的是，我们使用的Web应用服务器一般都会提供这种会话基础服务，如Tomcat的Session机制。也就是说，应用开发人员不必利用Cookie亲自代码实现会话的创建、维护和销毁等整个生命周期管理，这些内容服务器Session已经提供好了，我们只需正确使用即可。当然，为了灵活性和效率，开发人员也可直接使用cookie实现自己的这种会话管理。对于Cookie，处于安全性考虑，它有一个作用域问题，这个作用域由属性Domain和Path共同决定的。也就是说，如果浏览器发送的请求不在此Cookie的作用域范围内，请求是不会带上此Cookie的。Path是访问路径，我们可以定义/根路径让其作用所有路径，Domain就不一样了。我们不能定义顶级域名如.com，让此Cookie对于所有的com网站都起作用，最大范围我们只能定义到二级域名如.taobao.com，而通常，企业的应用群可能包含有多个二级域名，如taobao.com、tmail.com、alitrip.com等等。这时，解决单系统会话问题的Cookie机制不起作用了，多系统不能共享同一会话，这就是问题的所在！ 当然，有的同学会说：我把所有的应用统一用三级域名来表示，如a.taobao.com、b.taobao.com、c.taobao.com或干脆用路径来区分不同的应用如www.taobao.com\a、www.taobao.com\b、www.taobao.com\c，这样cookie不就可以共享了么？事实是成立的，但现实应用中，多域名策略是普遍存在的，也有商业角度的考虑，这些我们必须要面对。退一步讲，即使cookie可以共享了，服务端如何识别处理这个会话？这时，我们是不能直接使用服务器所提供的Session机制的，Session是在单一应用范围内，共享Session需要特殊处理。更复杂的情况是，通常这些子系统可能是异构的，session实现机制并不相同，如有的是Java系统，有的是PHP系统。共享Session对原系统入侵性很大。至此，SSO技术问题这里讲清楚了。那我们有没有更好的通用解决方案？答案肯定是有的，但比较复杂，这也是我们专题讨论的理由。总体来说，我们需要一个中央认证服务器，来统一集中处理各子系统的登录请求。 SSO实现基本思路单Web应用登录，主要涉及到认证（用户名密码）、授权（权限定义）、会话建立（Cookie&amp;Session）、取消会话（删除Session）等几个关键环节。推广到多系统，每个系统也会涉及到认证、授权、会话建立取消等工作。那我们能不能把每个系统的认证工作抽象出来，放到单独的服务应用中取处理，是不是就能解决单点登录问题？ 思考方向是正确的，我们把这个统一处理认证服务的应用叫认证中心。当用户访问子系统需要登录时，我们把它引到认证中心，让用户到认证中心去登录认证，认证通过后返回并告知系统用户已登录。当用户再访问另一系统应用时，我们同样引导到认证中心，发现已经登录过，即返回并告知该用户已登录 三大关键问题登录信息传递问题应用系统将登录请求转给认证中心，这个很好解决，我们一个HTTP重定向即可实现。现在的问题是，用户在认证中心登录后，认证中心如何将消息转回给该系统？这是在单web系统中不存在的问题。我们知道HTTP协议传递消息只能通过请求参数方式或cookie方式，cookie跨域问题不能解决，我们只能通过URL请求参数。我们可以将认证通过消息做成一个令牌(token)再利用HTTP重定向传递给应用系统。但现在的关键是：该系统如何判断这个令牌的真伪？如果判断这个令牌确实是由认证中心发出的，且是有效的？我们还需要应用系统和认证中心之间再来个直接通信，来验证这个令牌确实是认证中心发出的，且是有效的。由于应用系统和认证中心是属于服务端之间的通信，不经过用户浏览器，相对是安全的。 用户首次登录时流程如下： 用户浏览器访问系统A需登录受限资源。 系统A发现该请求需要登录，将请求重定向到认证中心，进行登录。 认证中心呈现登录页面，用户登录，登录成功后，认证中心重定向请求到系统A，并附上认证通过令牌。 系统A与认证中心通信，验证令牌有效,证明用户已登录。 系统A将受限资源返给用户。 已登录用户首次访问应用群中系统B时： 浏览器访问另一应用B需登录受限资源。 系统B发现该请求需要登录，将请求重定向到认证中心，进行登录。 认证中心发现已经登录，即重定向请求响应到系统B，附带上认证令牌。 系统B与认证中心通信，验证令牌有效,证明用户已登录。 系统B将受限资源返回给客户端。 登录状态判断问题用户到认证中心登录后，用户和认证中心之间建立起了会话，我们把这个会话称为全局会话。当用户后续访问系统应用时，我们不可能每次应用请求都到认证中心去判定是否登录，这样效率非常低下，这也是单Web应用不需要考虑的。我们可以在系统应用和用户浏览器之间建立起局部会话，局部会话保持了客户端与该系统应用的登录状态，局部会话依附于全局会话存在，全局会话消失，局部会话必须消失。用户访问应用时，首先判断局部会话是否存在，如存在，即认为是登录状态，无需再到认证中心去判断。如不存在，就重定向到认证中心判断全局会话是否存在，如存在，按1提到的方式通知该应用，该应用与客户端就建立起它们之间局部会话，下次请求该应用，就不去认证中心验证了。 登出问题用户在一个系统登出了，访问其它子系统，也应该是登出状态。要想做到这一点，应用除结束本地局部会话外，还应该通知认证中心该用户登出。认证中心接到登出通知，即可结束全局会话，同时需要通知所有已建立局部会话的子系统，将它们的局部会话销毁。这样，用户访问其它应用时，都显示已登出状态。整个登出流程如下： 客户端向应用A发送登出Logout请求。 应用A取消本地会话，同时通知认证中心，用户已登出。 应用A返回客户端登出请求。 认证中心通知所有用户登录访问的应用，用户已登出。 实现SSO实现分成两大部分，一个是SSO Server，代表认证中心，另一个是SSO Client，代表使用SSO系统应用的登录登出组件。 登录令牌token实现前面我们讨论了，系统把用户重定向导向认证中心并登录后，认证中心要把登录成功信息通过令牌方式告诉给应用系统。认证中心会记录下来自某个应用系统的某个用户本次通过了认证中心的认证所涉及的基本信息，并生成一个登录令牌token，认证中心需要通过URL参数的形式把token传递回应用系统，由于经过客户端浏览器，故令牌token的安全性很重要。因此令牌token的实现要满足三个条件： 首先，token具有唯一性，它代表着来自某应用系统用户的一次成功登录。我们可以利用java util包工具直接生成一个32位唯一字符串来实现。1String token = UUID.randomUUID().toString(); 同时，我们定义一个javabean， TokenInfo 来承载token所表示的具体内容，即某个应用系统来的某个用户本次通过了认证中心123456public class TokenInfo &#123; private int userId; //用户唯一标识ID private String username; //用户登录名 private String ssoClient; //来自登录请求的某应用系统标识 private String globalId; //本次登录成功的全局会话sessionId ... &#125; token和tokenInfo形成了一个&lt;key,value&gt;形式的键值对，后续应用系统向认证中心验证token时还会用到。其次，token存在的有效期间不能过长，这是出于安全的角度，例如token生存最大时长为60秒。我们可以直接利用redis特性来实现这一功能。redis本质就是&lt;key,value&gt;键值对形式的内存数据库，并且这个键值对可以设置有效时长。第三，token只能使用一次，用完即作废，不能重复使用。这也是保证系统安全性。我们可以定义一个TokenUtil工具类，来实现&lt;token,tokenInfo&gt;键值对在redis中的操作，主要接口如下：123456789public class TokenUtil &#123; ... // 存储临时令牌到redis中，存活期60秒 public static void setToken(String tokenId, TokenInfo tokenInfo)&#123; ... &#125; //根据token键取TokenInfo public static TokenInfo getToken(String tokenId)&#123; ... &#125; //删除某个 token键值 public static void delToken(String tokenId)&#123; ... &#125; &#125; 全局会话和本地会话的实现用户登录成功后，在浏览器用户和认证中心之间会建立全局会话，浏览器用户与访问的应用系统之间，会建立本地局部会话。为简便可以使用web应用服务器(如tomcat)提供的session功能来直接实现。这里需要注意的是，我们需要根据会话ID(即sessionId)能访问到这个session。因为根据前面登出流程说明，认证中心的登出请求不是直接来自连接的浏览器用户，可能来自某应用系统。认证中心也会通知注册的系统应用进行登出。这些请求，都是系统之间的交互，不经过用户浏览器。系统要有根据sessionId访问session的能力。同时，在认证中心中，还需要维护全局会话ID和已登录系统本地局部会话ID的关系，以便认证中心能够通知已登录的系统进行登出处理。为了安全，目前的web应用服务器，如tomcat，是不提供根据sessionId访问session的能力的，那是容器级范围内的能力。我们需要在自己的应用中，自己维护一个sessionId和session直接的对应关系，我们把它放到一个Map中，方便需要时根据sessionId找到对应的session。同时，我们借助web容器提供的session事件监听能力，程序来维护这种对应关系。认证中心涉及到两个类，GlobalSessions和GlobalSessionListener，相关代码如下：12345678910111213141516171819202122232425public class GlobalSessions &#123; //存放所有全局会话 private static Map&lt;String, HttpSession&gt; sessions = new HashMap&lt;String,HttpSession&gt;(); public static void addSession(String sessionId, HttpSession session) &#123; sessions.put(sessionId, session); &#125; public static void delSession(String sessionId) &#123; sessions.remove(sessionId); &#125; //根据id得到session public static HttpSession getSession(String sessionId) &#123; return sessions.get(sessionId); &#125;&#125; public class GlobalSessionListener implements HttpSessionListener &#123; public void sessionCreated(HttpSessionEvent httpSessionEvent) &#123; GlobalSessions.addSession( httpSessionEvent.getSession().getId(), httpSessionEvent.getSession()); &#125; public void sessionDestroyed(HttpSessionEvent httpSessionEvent) &#123; GlobalSessions.delSession(httpSessionEvent.getSession().getId()); &#125; &#125; SSO Client对应的是LocalSessions和LocalSessionListener,实现方式同上。 应用系统和认证中心之间的通信根据SSO实现流程，应用系统和认证中心之间需要直接通信。如应用系统需要向认证中心验证令牌token的真伪，应用系统通知认证中心登出，认证中心通知所有已注册应用系统登出等。这是Server之间的通信，如何实现呢？我们可以使用HTTP进行通信，返回的消息应答格式可采用JSON格式。Java的net包，提供了http访问服务器的能力。这里，我们使用apache提供的一个更强大的开源框架，httpclient，来实现应用系统和认证中心之间的直接通信。JSON和JavaBean之间的转换，目前常用的有两个工具包，一个是json-lib，还有一个是Jackson，Jackson效率较高，依赖包少，社区活跃度大，这里我们使用Jackson这个工具包。如应用系统向认证中心发送token验证请求的代码片段如下： 123456789101112131415161718192021222324252627282930//向认证中心发送验证token请求 String verifyURL = "http://" + server + PropertiesConfigUtil.getProperty("sso.server.verify"); HttpClient httpClient = new DefaultHttpClient(); //serverName作为本应用标识 HttpGet httpGet = new HttpGet(verifyURL + "?token=" + token + "&amp;localId=" + request.getSession().getId()); try&#123; HttpResponse httpResponse = httpClient.execute(httpGet); int statusCode = httpResponse.getStatusLine().getStatusCode(); if (statusCode == HttpStatus.SC_OK) &#123; String result = EntityUtils.toString(httpResponse.getEntity(), "utf-8"); //解析json数据 ObjectMapper objectMapper = new ObjectMapper(); VerifyBean verifyResult = objectMapper.readValue(result, VerifyBean.class); //验证通过,应用返回浏览器需要验证的页面 if(verifyResult.getRet().equals("0")) &#123; Auth auth = new Auth(); auth.setUserId(verifyResult.getUserId()); auth.setUsername(verifyResult.getUsername()); auth.setGlobalId(verifyResult.getGlobalId()); request.getSession().setAttribute("auth", auth); //建立本地会话 return "redirect:http://" + returnURL; &#125; &#125; &#125; catch (Exception e) &#123; return "redirect:" + loginURL; &#125; SSO Server接口核心实现细节讨论清楚了，我们就可以根据登录登出操作流程，定义SSO Server和SSO Client所提供的接口。SSO Server认证中心包含4个重要接口，分别如下： 接口一： /page/login。此接口主要接受来自应用系统的认证请求，此时，returnURL参数需加上，用以向认证中心标识是哪个应用系统，以及返回该应用的URL。如用户没有登录，应用中心向浏览器用户显示登录页面。如已登录，则产生临时令牌token，并重定向回该系统。上面登录时序交互图中的2和此接口有关。当然，该接口也同时接受用户直接向认证中心登录，此时没有returnURL参数，认证中心直接返回登录页面。123接口名称：/page/login入参： returnURL (系统URL，可选)返回： 1.显示登录页面；2.产生临时认证token并重定向回系统； 接口二： /auth/login。处理浏览器用户登录认证请求。如带有returnURL参数，认证通过后，将产生临时认证令牌token，并携带此token重定向回系统。如没有带returnURL参数，说明用户是直接从认证中心发起的登录请求，认证通过后，返回认证中心首页提示用户已登录。上面登录时序交互图中的3和此接口有关。123接口名称：/auth/login入参： username[*用户名]、password[*密码]、returnURL返回： 1.产生临时认证token并重定向回系统；2.返回认证中心首页提示登录成功； 接口三： /auth/verify。认证应用系统来的token是否有效，如有效，应用系统向认证中心注册，同时认证中心会返回该应用系统登录用户的相关信息，如ID,username等。上面登录时序交互图中的4和此接口有关。12345678910接口名称：/auth/verify入参： token、localid返回： JSON格式消息 &#123; ret: 返回结果字符串，0表示成功； msg: 返回结果文字说明字符串； userid: 用户ID; username: 用户登录名; globalid: 全局会话ID,登出时使用; &#125; 接口四： /auth/logout。登出接口处理两种情况，一是直接从认证中心登出，一是来自应用重定向的登出请求。这个根据gId来区分，无gId参数说明直接从认证中心注销，有，说明从应用中来。接口首先取消当前全局登录会话，其次根据注册的已登录应用，通知它们进行登出操作。123接口名称：/auth/logout入参： gid[全局会话id,可选]返回： 1.返回OK; 2.返回认证中心首页; SSO Client接口接口一： /auth/check。接收来自认证中心携带临时令牌token的重定向，向认证中心/auth/verify接口去验证此token的有效性，如有效，即建立本地会话，根据returnURL返回浏览器用户的实际请求。如验证失败，再重定向到认证中心登录页面。123接口名称：/auth/check入参： token[*登录token]返回： 成功重定向returnURL，失败重定向到登录页面; 接口二： /auth/logout。处理两种情况，一种是浏览器向本应用接口发出的直接登出请求，应用会消除本地会话，调用认证服务器/auth/logout接口，通知认证中心删除全局会话和其它已登录应用的本地会话。 如果是从认证中心来的登出请求，此时带有localId参数，接口实现会直接删除本地会话，返回字符串”ok”。123接口名称：/auth/logout入参： localid[本地会话id,可选]返回： 1.首页; 2.'ok'字符串; CASCAS是中央认证服务Central Authentication Service的简称。最初由耶鲁大学的Shawn Bayern 开发，后由Jasig社区维护，经过十多年发展，目前已成为影响最大、广泛使用的、基于Java实现的、开源SSO解决方案。2012年，Jasig和另一个有影响的组织Sakai Foundation合并，组成Apereo。Apereo是一个由高等学术教育机构发起组织的联盟，旨在为学术教育机构提供高质量软件，当然很多软件也被大量应用于商业环境，譬如CAS。目前CAS由Apereo社区维护。CAS的官方网址是： https://www.apereo.org/projects/cas工程代码网址：https://github.com/Jasig/cas CAS也提供了一个认证中心，叫CAS Server，参与登录的应用系统都会引导到CAS Server进行登录。各应用系统与CAS Server交互通信的登录组件叫CAS Client。如CAS Client，已经提供了包括Java、.net、php、ruby、perl等多种语言的实现，非常适合异构系统的单点登录使用场景。再比如认证方式，除了常见的基于数据库认证，还提供LDAP使用场景,同时支持各种常见认证协议，如spnego、OpenId、X509等等。对于全局会话，CAS基于Cookie使用了自己的实现方式，而服务端的会话存储，除了缺省基于内存模式，还提供了基于ehcache、memcached等多种实现，同时提供了灵活接口便于自己定制扩展，这非常适合某些高可用性、高性能的应用场景。因此，在一般场景下，我们不需要重新发明轮子，直接在成熟技术框架基础上开发使用即可。这也是CAS在很多互联网和企业应用中广泛使用的原因。当然，对于某些场景，如安全性因素、更特殊更高效的应用场景，在技术实力许可的情况下，通常都自己实现SSO。]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络安全基础知识]]></title>
    <url>%2F2017%2F11%2F29%2Fnetsafe-technology%2F</url>
    <content type="text"><![CDATA[本文主要对软件开发者相关的系统安全问题进行总结。 攻击类型XSSCSRF产生原理 想要攻击成功，这三步缺一不可。 第一，登录受害者网站。如果受害者网站是基于 cookie 的用户验证机制，那么当用户登录成功后，浏览器就会保存一份服务端的 SESSIONID。 第二，这时候在同一个浏览器打开攻击者网站，虽然说它无法获取 SESSIONID 是什么（因为设置了 http only 的 cookie 是无法被 JavaScript 获取的），但是从浏览器向受害者网站发出的任何请求中，都会携带它的 cookie，无论是从哪个网站发出。 第三，利用这个原理，在攻击者网站发出一个请求，命令受害者网站进行一些敏感操作。由于此时发出的请求是处于 session 中的，所以只要该用户有权限，那么任何请求都会被执行。 比如，打开优酷，并登录。再打开攻击者网站，它里面有个 &lt;img&gt; 标签是这样的： 1&lt;img src="http://api.youku.com/follow/123" /&gt; 这个 api 只是个例子，具体的 url 和参数都可以通过浏览器的开发者工具（Network 功能）事先确定。假如它的作用是让该登录的用户关注由 123 确定的一个节目或者用户，那么通过 CSRF 攻击，这个节目的关注量就会不断上升。 解释两点。第一，为什么举这个例子，而不是银行这种和金钱有关的操作？很简单，因为它容易猜。对于攻击者来说，没有什么是一定能成功的，比如 SQL 注入，攻击者他不知道某网站的数据库是怎么设计的，但是他一般会通过个人经验去尝试，比如很多网站把用户的主键设置为 user_id，或 sys_id 等。 银行的操作往往经过多重确认，比如图形验证码、手机验证码等，光靠 CSRF 完成一次攻击基本上是天方夜谭。但其他类型的网站往往不会刻意去防范这些问题。虽然金钱上的利益很难得到，但 CSRF 能办到的事情还是很多，比如利用别人发虚假微博、加好友等，这些都能对攻击者产生利益。 第二，如何确保用户打开优酷之后，又打开攻击者网站？做不到。否则任何人打开优酷之后，都会莫名其妙地去关注某个节目了。但是你要知道，这个攻击成本仅仅是一条 API 调用而已，它在哪里都能出现，你从任何地方下载一张图片，让你请求这个地址，看也不看就点确定，请求不就发出去了吗？ 防范手段对于如何防范 CSRF，一般有三种手段。 判断请求头Referer这个字段记录的是请求的来源。比如 http://www.example.com 上调用了百度的接口 http://api.map.baidu.com/service 那么在百度的服务端，就可以通过 Referer 判断这个请求是来自哪里。在实际应用中，这些跟业务逻辑无关的操作往往会放在拦截器中（或者说过滤器，不同技术使用的名词可能不同）。意思是说，在进入到业务逻辑之前，就应该要根据 Referer 的值来决定这个请求能不能处理。在 Java Servlet 中可以用 Filter（古老的技术）；用 Spring 的话可以建拦截器；在 Express 中是叫中间件，通过 request.get(‘referer’) 来取得这个值。每种技术它走的流程其实都一样。但要注意的是，Referer 是浏览器设置的，在浏览器兼容性大不相同的时代中，如果存在某种浏览器允许用户修改这个值，那么 CSRF 漏洞依然存在。 在请求参数中加入 csrf token讨论 GET 和 POST 两种请求，对于 GET，其实也没什么需要防范的。为什么？因为 GET 在“约定”当中，被认为是查询操作，查询的意思就是，你查一次，查两次，无数次，结果都不会改变（用户得到的数据可能会变），这不会对数据库造成任何影响，所以不需要加其他额外的参数。 所以这里要提醒各位的是，尽量遵从这些约定，不要在 GET 请求中出现 /delete, /update, /edit 这种单词。把“写”操作放到 POST 中。 对于 POST，服务端在创建表单的时候可以加一个隐藏字段，也是通过某种加密算法得到的。在处理请求时，验证这个字段是否合法，如果合法就继续处理，否则就认为是恶意操作。 1234&lt;form method="post" action="/delete"&gt; &lt;!-- 其他字段 --&gt; &lt;input type="hidden" name="csrftoken" value="由服务端生成"/&gt;&lt;/form&gt; 这个 html 片段由服务端生成，比如 JSP，PHP 等，对于 Node.js 的话可以是 Jade 。这的确是一个很好的防范措施，再增加一些处理的话，还能防止表单重复提交。可是对于一些新兴网站，很多都采用了“单页”的设计，或者退一步，无论是不是单页，它的 HTML 可能是由 JavaScript 拼接而成，并且表单也都是异步提交。所以这个办法有它的应用场景，也有局限性。 新增 HTTP Header思想是，将 token 放在请求头中，服务端可以像获取 Referer 一样获取这个请求头，不同的是，这个 token 是由服务端生成的，所以攻击者他没办法猜。这篇文章的另一个重点——JWT——就是基于这个方式。抛开 JWT 不谈，它的工作原理是这样的: 解释一下这四个请求，类型都是 POST 。 通过 /login 接口，用户登录，服务端传回一个 access_token，前端把它保存起来，可以是内存当中，如果你希望用来模拟 session 的话。也可以保存到 localStorage 中，这样可以实现自动登录。 调用 /delete 接口，参数是某样商品的 id。仔细看，在这个请求中，多了一个名为 Authoriaztion 的 header，它的值是之前从服务端传回来的 access_token，在前面加了一个“Bearer”（这是和服务端的约定，约定就是说，说好了加就一起加，不加就都不加……） 调用 /logout 接口，同样把 access_token 加在 header 中传过去。成功之后，服务端和前端都会把这个 token 置为失效，或直接删除。 再调用 /delete 接口，由于此时已经没有 access_token 了，所以服务端判断该请求没权限，返回 401 。 各位有没有发现，从头至尾，整个过程没有涉及 cookie，所以 CSRF 是不可能发生的！ 重放攻击加密机加密机解决信息的CIA问题，提供应用层加密、传输层、IP层加密（网络层）、数据链路层加密，主要应用于金融、社保等行业。96年，根据相关领导部门指示，由中国电子科技集团30研究所和总参56所研究生产加密机。分别推出型号：SJL05型（30所）、SJL06型（56所）。30所发起成立成都卫士通公司，推广SJL05型加密机；56所（军队不能经商）与江南科友合作，推广SJL06型。国内加密机厂商有江南天安等。美国Taclane、SafeNet公司也是加密机的生产厂商。 网络层 传输内容 物理层 高低电平:纯物理信号 数据链路层 数据帧:帧头+IP数据包+帧尾 (帧头包括源和目标主机MAC地址及类型，帧尾是校验字),这一层的加密需要在OS网卡驱动层进行处理(Windows:NDIS，在Linux上可以直接使用Socket操作数据链路层) 网络层 IP数据包:IP头部+TCP数据信息(IP头包括源和目标主机IP地址、类型、生存期等) 传输层 TCP数据信息:TCP头部+实际数据 (TCP头包括源和目标主机端口号、顺序号、确认号、校验字等)UDP数据信息:UDP报头+实际数据（UDP报头包括目标端口号、数据报长度、校验值） 相关的网络安全技术还有IPSEC等。 端到端加密端到端加密 (End-to-end encryption，E2EE)是一个只有参与通讯的用户可以读取信息的通信系统。总的来说，它可以防止潜在的窃听者——包括 电信供应商、互联网服务供应商甚至是该通讯系统的提供者——获取能够用以解密通讯的密钥。此类系统被设计为可以防止潜在的监视 或篡改企图，因为没有密钥的第三方难以破译系统中传输或储存的数据。 举例来说，使用端到端加密的通讯提供商，将无法将其客户的通讯数据提供给当局。 密钥交换在一个端到端加密的系统中，用于加解密的密钥必须被、且仅被参与通讯的各方掌握。为实现这一目的，端到端加密系统可以使用事先预定好的一串字符（称为“预共享密钥”）来加密数据（如PGP），也可以使用该字符串生成一次性密码来进行加密（如DUKPT）。此外，参与通讯的各方还可以通过协商（Diffie–Hellman迪菲-赫尔曼密钥交换协议）创建密钥（如OTR）。 中间人攻击端到端加密能确保数据安全保密地传输于通讯的两端之间。但对于不怀好意的窃听者而言，与其尝试破解加密，不如冒充的消息接受方（例如，在密钥交换期间冒名顶替，或是设法将收件人公布的公共密钥替换成自己的）来得方便，因为此后，发信人发出的信息将以一个窃听者掌握的密钥进行加密。在获取解密的信息后，监听者还可以冒充发信人，与实际的接收者进行密钥交换、发送讯息，以避免通讯双方察觉异常。由于攻击者处在通讯双方之间，因此这种攻击方式被称为中间人攻击的。 大多数端到端加密协议都设计了某种形式的终端认证机制，专门用来防御中间人攻击，例如依靠数字证书认证机构或信任网络进行验证。其他的技术包括的针对用户公钥或预共享密钥生成密码哈希（设备指纹）。 通讯各方可以通过外部（out-of-band）通信渠道来校验这一指纹，便可确认通讯的完整性和真实性（但不能保证机密性），之后再展开真实对话。如果指纹匹配的话，理论上可以确认不存在中间人攻击。 为了方便人工检查，指纹通常会显示为 十六进制字符串。 这些字符串通常会编排成特定格式并编组，以提高可读性。例如，128位MD5指纹会显示如下：143:51:43:a1：b5：fc：8b：b7：0a:3a：a9：b1：0f:66:73:a8 终端安全端到端加密并不能避免终端本身的安全风险。每个用户的计算机等设备上仍然存在密钥被盗（以进行中间人攻击），或是是被解密的信息被读取的可能性。 即使是最完美的加密通信，他的安全性仍然受制于两端“邮箱”的安全性。 提升端点安全性的手段主要有：将密钥的产生、储存和加解密操作独立到一个小的智能卡上，例如Google Project Vault。然而，由于明文输入和输出仍然对于用户设备来说依旧是可见的，因此恶意软件仍然可以实时窃听用户的对话。一个更强大的方式是将所有敏感数据隔离到一台由网闸完全限制的计算机上。 美国和以色列开发的“震网”病毒成功地通过离线渠道进入并瘫痪了伊朗在纳坦兹建设的核设施。为了避免恶意软件导致的密钥泄漏、一种方法是将可信计算基分散在两个单向连接的计算机上，以避免恶意软件感染及其导致的敏感数据泄漏。 金融行业密钥体系相关知识参照中国银联的密钥安全标准，各密钥长度至少 128bit。上层密钥提供对下层密钥的保护或维护。所有的密钥或数据保护都采用3DES。 TMK为终端主密钥，用来加密、解密需要传输的工作密钥TAK或TPK，实现工作密钥联机传送。要求每台POS终端的TMK不同，该TMK通过MK加密后保持在数据库中。TAK、TPK为工作密钥，是最底层的数据加密密钥，也是更新最频繁的密钥，包括TAK和TPK，TAK为终端信息完整性密钥，TPK为PIN保护密钥，这两个密钥的更新都是通过联机交易即签到来完成，使用TMK加密后进行传送。 在增加终端资料时，系统将通过加密机为每个终端随机产生不同的TMK，并获取TMK密文（通过MK加密）写入联机系统数据库的终端表中，同时该TMK需要传送给POS终端应用才能正常工作。 密钥基础知识我们知道金融行业有很多数据要在网络上传递，包括从前置到主机，从自助终端到前置等，这些数据在网络上传来传去，我们很容易就会想到安全性的问题，如果这些数据被人窃取或拦截下来，那我们怎么敢在银行存钱了。这个问题在计算机出现时就被前人考虑到了，所以出现了很多各种各样的加解密技术。抛开这些不管，假设当初由我们自己来设计怎样解决数据被窃取的情况。假设我们有一段数据，是ATM取款的报文，包括一个人的磁卡号、密码、取款金额，现在需要将这些数据从一台ATM机器传到前置机处理，这些数据是比较机密的，如果被人窃取了，就可以用该卡号和密码把账户中的钱取走。 首先，我们可以想到用专用的银行内部网络，外面的人无法获得网络的访问权。这个仔细想想显然不可行的，因为一是不能保证外人一定没办法进入银行内部网络，二是银行内部人员作案是没法防止的。 接着，我们很容易想到，既然保证数据不被窃取的可能性很小，那我们何不变换一下思路，数据避免不了被窃取，那我如果将数据处理下，让你即使窃取到数据，也是一些无用的乱码。这个想法比较接近现在的做法了，当前置机接收到了数据，它肯定是对数据进行反处理，即与ATM端完全步骤相反的数据处理，即可得到明文的数据。我们再进一步想想，如果因为某种原因，报文中的取款金额被改变了，这样就会导致ATM出的钱和前置扣账记录的钱不一致的情况，看来我们必须加上一个验证机制，当前置机收到ATM发送的一个报文时，能够确认报文中的数据在网络传输过程中没有被更改过。怎样实现？最简单的，对通讯数据每一位进行异或，得到0或1，把0或1放在在通讯数据后面，算是加上一个奇偶校验位，收到数据同样对数据每位进行异或，得到0或1，再判断下收到数据最后一位与算出来的是否一致。这种方式太简单了，对于上面提到的ATM到前置机的报文来说，没什么用处，不过我们可以将对数据每一位异或的算法改成一个比较复杂点的。因为DES算法已经出来了很多年了，并且在金融行业也有广泛的应用，我们使用DES算法进行处理，来解决上面的问题。 DES算法（此处指单DES）的入口参数有三个：Key、Data、Mode。其中Key为8个字节共64位，是DES算法的工作密钥；Data也为8个字节64位，是要被加密或被解密的数据；Mode为DES的工作方式，有两种：加密或解密。DES算法是这样工作的：如Mode为加密，则用Key去把数据Data进行加密，生成Data的密码形式（64位）作为DES的输出结果；如Mode为解密，则用Key去把密码形式的数据Data解密，还原为Data的明码形式（64位）作为DES的输出结果。在通信网络的两端，双方约定一致的Key，在通信的源点用Key对核心数据进行DES加密，然后以密码形式在公共通信网中传输到通信网络的终点，数据到达目的地后，用同样的Key对密码数据进行解密，便再现了明码形式的核心数据。这样，便保证了核心数据在公共通信网中传输的安全性和可靠性。通过定期在通信网络的源端和目的端同时改用新的Key，能更进一步提高数据的保密性。 我们用一个Key对前面提到的报文进行DES算法，得到加密后的64位数据，放到报文的最后，跟报文一起送到前置机，前置机收到报文后，同样用Key对数据（不包括最后的64位加密数据）进行DES加密，得出64位的数据，用该数据与ATM发送过来的报文最后的64位数据比较，如果两个数据相同，说明报文没有中途被更改过。 再进一步，因为DES只能够对64位的数据进行加密，一个报文可不止64位，哪我们怎么处理呢？只对报文开头的64位加密？这个是显然不够的。我们可以这样，先对报文的开始64位加密，接着对报文第二个64位加密，依次类推，不过这有问题，因为每个64位都会得到同样长度的加密后的数据，我不能把这些数据都放到报文的后面（报文的长度就变成两倍长了）。换个思路，我先对报文第一个64位加密，得到64位的加密后数据data1，接着再拿加密后的data1与报文第二个64位数据进行按位异或，得到同样长64位的数据data2，我再用Key对data2加密，得到加密后的数据data3，再拿data3与报文第三个64位数据进行按位异或，同样的处理依次类推。直到最后会得到一个64位的数据，将这个数据放到报文的最后发到前置机，这样报文的长度只增加了64位而已。这个算法就叫做MAC算法，MAC是一种校验算法。 好了，到目前为止我们已经知道了什么是MAC算法，为什么需要它，接着我们再看看经常被提起的另外一个名词。在上面说到MAC算法的时候，我们会注意到其中进行DES加密算法时提到了一个Key，这个用来参与MAC计算的Key就常被称为MacKey（MAK）。 我们继续来处理ATM和前置机间网络数据传输的问题。前面提到的MAC算法对传送的报文进行了处理，保证了在网络传输过程中数据不会被有意或无意的篡改，但是，我们再进一步想想，如果仍然是上面提到的一个取款报文，如果想作案的话，我不改报文的内容，而只是截取报文的内容，因为内容里面有卡号和密码，都是明文的形式，很容易就看出来哪些内容是卡号、哪些内容是密码。有了卡号和密码，找个读卡器就能够很快的制出一张磁卡，然后拿这个磁卡可以随便取钱了，根本不需要修改报文，这样你就算前置机对报文的MAC校验通过了，也只是保证了报文没被改动过，对于防止作案没有实质上的帮助。那我们很容易想到，再加上一道加密，这次我把整个取款的报文都用DES加密，将明文全部转换成密文，然后送到前置机，这下好了吧。即使你把报文截取了也没用，你拿着这些密文也没有用，你也没有DES的密钥来解密它，只有前置机才知道密钥。这是个好主意，确实防止了卡号和密码等被人获知的危险。这也是现在普遍采取的做法，不过我们需要对这个做法进行一些改进。 首先，我们要知道用DES对数据加解密是耗时间的，速度是比较慢的。我们来想想，整个取款报文有必要每个数据都DES加密吗？比如报文中的什么流水号、ATM号等信息，对它们加密没什么意义，进一步讲，取款金额加密也没意义，假设你取500块，但是你将报文改成了100块，导致主机只把你账户扣100块钱，你白赚了400块。这个听起来挺划算的，实际上是不可行的，因为这样造成了账务上的短款，银行当然会查账的，根据ATM记录的硬件出钞张数和主机扣款金额，肯定会把你查出来的，那这种掩耳盗铃的做法，下场显而易见。 我们来考虑一个报文中到底什么信息是需要加密的，目前一般的做法是只对账号和密码进行加密（也有只对密码加密的），其他的内容不加密的。对账号和密码加密有个术语，叫PinBlock，即PIN块，就是对账号和密码进行DES加密处理后的一个密文数据块。既然使用了DES算法来加密账号和密码，则必然有个Key来加密，那么我们就把这个Key称为PinKey（PIK），就是专门来加密用户账户和密码的Key。至于怎样进行加密形成最后的密文PinBlock，有很多标准的，比如IBM3624、ANSI、ISO、DIEBOLD等标准，其实它们大同小异，就是在对报文中的密码进行一个预处理，再用PinKey来DES加密，主要的差别就是怎样预处理而已，比如有的是密码后面补F，补够16 位，就是类似这样的预处理。到这里我们应该理解PinKey和PinBlock了。通过PinKey和MacKey对报文进行了两重处理，基本上报文就是安全的了。 如果我们对DES算法比较了解，就会知道，如果想对加密后的密文解密，必须要知道Key才行，所以说Key一定要保密。怎样来保密Key呢？我们前面提到的无论是算MAC还是算PIN块，都是直接拿明文的Key来计算的，那么这个Key很容易被窃取的，比如有人在机器上装了个黑客程序，只要检测到你在用Key加密数据，就把明文的Key获取了。 这样看来，我们还要对PinKey和MacKey本身进行加密，不要让人知道了。怎样实现，同样是DES算法大显身手的地方。我再找个Key对PinKey和MacKey进行一次加密，这样你就看不到PinKey和MacKey的明文了，好，解决问题了。这时用来对PinKey和MacKey进行加密的Key就被我们称为MasterKey，即主密钥，用来加密其他密钥的密钥。不过，那MasterKey怎么办，它是明文啊。再找个Key来加密MasterKey，那最终无论处理多少道，最后的那个Key肯定是明文，这样看来，安全的问题还没有解决。 既然此路不通，那我们需要换个思维角度，仔细想想怎样处理明文的MasterKey。黑客程序只能窃取软件上的东西，如果我把MasterKey放到硬件加密机里面，黑客是没能力跑到硬件加密机里面把MasterKey取出来的。这样只需要把加密级别最高的MasterKey放到硬件加密机里面，问题就解决了。这时存储在硬件加密机中受硬件设备保护的MasterKey（MK）就称为主密钥（根密钥），加解密PinKey和MacKey同时又受主密钥加密保护的密钥称为次主密钥（Member Master Key，MMK）。 还有个名词经常被提到，就是3DES。为什么要提出3DES的概念呢？其实推出3DES是因为原来的单DES算法随着计算机硬件的速度提升，已经出现被破解的可能性（DES算法中只用到64位密钥中的其中56位，而第8、16、24、……64位8个位并未参与DES运算，而56位长的密钥通过组合变化，其穷举空间最大为256，这意味着如果一台超高速计算机的速度是每一秒钟检测一亿个密钥，则它穷举完全部密钥只需要23年的时间，随着运算速度的不断提升，穷举用时会更短），所以将算法基于DES进行了改进，即对一块数据用三个不同的密钥进行三次加密，使强度更高。但是对于我们理解金融行业的密钥及加密机制来说，用什么算法都一样，不同算法的差别只是在于对数据进行移位变换等处理的方法不同而已。 密钥体系结构不同的信息需要使用不同的密钥加密，密钥分层的好处是有利于密钥的更新和传送，同时保证了密钥的安全性。当其中一级密钥的安全出现问题时，并不会影响其他信息的安全性。 下图以江南科友SJL06加密机为例，介绍硬件加密机的三层密钥结构： 第一层，加密机主密钥（Master Key - MK），是保存在硬件加密机内的由三个成分合成的一对最上层密钥，其作用是将所有存放在本地的其它密钥和加密数据进行加密，在硬件加密机以外的地方不会以明文形式存放，是三级密钥体系中最高级别的密钥。硬件加密机投入运行时，必须先产生和装载MK。由于DES算法依靠某一个密钥进行加密，同时所有密钥和数据都经由MK进行加密，所以MK必须通过一种安全的方法生成和维护。MK由三个成分（32位十六进制数）组成，需要银行三位主要的密钥管理人员参与产生，一般采用“背对背”形式依次录入，记录checkvalue，分开安全保存明文分量。MK以密文形式存储在加密机黑匣子中，且永远不以明文形式出现。一旦硬件加密机受到非授权的操作，主密钥会自动销毁。 第二层，次主密钥（BMK、ZMK），又被称为密钥加密密钥或密钥交换密钥（Key-encrypting Key或Key Exchange Key）。它的作用是加密在通讯线路上需要传递的工作密钥，从而实现工作密钥的自动分配。它可以在共享网络中两个（或多个）通讯网点之间进行人工分配且保持双方的对称性。次主密钥由两个成分（32位十六进制数）组成，其产生是由两位密钥管理员用“背对背”的方式共同完成。对于SJL06 RACAL型加密机（雷卡），次主密钥为ZMK（Zone Master Key），需要密钥管理员记录ZMK密钥密文和checkvalue，并将ZMK密文（从第一位“X”后的所有32位16进制数）录入加密机外部的主机数据库中保存；对于SJL06 JK&amp;IC型加密机（金卡），次主密钥为BMK（Bank Master Key），是以索引方式通过MK加密直接保存在硬件加密机中。 第三层，通常称为工作密钥或数据加密密钥，包括信息完整性密钥(MAK)、PIN保护密钥(PIK)、终端密钥(TMK)，它的作用是加密各种不同的数据，从而实现数据的保密，信息的认证，以及数字签名的功能。这些数据密钥在本地存放时,处于次主密钥的加密之下或直接保存在硬件加密机中。工作密钥需要经常性地定期更换，通常每天更换一次或在系统启动时更换新密钥。 如下图为终端更换密钥流程（终端维护人员需要持有传输密钥IC）： 硬件加密与软件加密的比较软件加密是不依靠硬件使用程序软件来实现的对数据的加密技术，而硬件加密是依靠硬件设备对传输的数据进行加密的技术。两者的相同点为：使用的加密算法相同，并且密钥体系也相同。 两者的不同点为： 软件加密时很多重要的信息（如用来做密码运算的密钥，或客户的PIN）都会在某时间清晰的出现于计算机的内存或磁盘上，而对计算机数据安全有一定研究的不法分子便有机会把这些资料读取、修改或删除，破坏系统的安全性。 硬件加密所有密码运算都在加密机内完成，在完整的加解密过程中，仅在硬件加密设备内部出现密钥和PIN的明文，有效防止了密钥和PIN的泄露，并且在受到非法攻击时，加密机内部保护的密钥会自动销毁。 鉴于软件加密不能提供一种有效的机制保护密钥和客户密码PIN的存储安全，国际银行卡组织（VISA、万事达）以及我国的银联组织均作出了在金融系统中必须使用硬件加密设备的规定。]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HEXO&Jekyllrb Tutorial]]></title>
    <url>%2F2017%2F11%2F20%2Fhexo-jekyllrb-tutorial%2F</url>
    <content type="text"><![CDATA[HEXO是一个静态BLOG APPS。 Hexo安装配置安装1cnpm install hexo-cli -g 启动1hexo server 配置语言配置1language: zh-Hans 部署12hexo cleanhexo generate NEXT主题12$ cd your-hexo-site$ git clone https://github.com/iissnan/hexo-theme-next themes/next 克隆/下载 完成后，打开 站点配置文件，找到theme字段，并将其值更改为next。 这里注意区分两个配置文件：站点配置文件：是你的 hexo 博客目录下面的 _config.yml 文件。主题配置文件：是 themes/next 目录下的 _config.yml 文件。 访问统计打开 Hexo 目录下的 \themes\next\ _config.yml 文件 打开侧边栏12sidebar: display: always 高级功能搜索12cnpm install hexo-generator-search --savecnpm install hexo-generator-searchdb --save 在站点配置中加入：12345search: path: search.xml field: post format: html limit: 10000 在NEXT主题配置文件中开启：12local_search: enable: true 关于我页面1hexo new page about 在NEXT主题中开启关于我页面即可 写作阅读全文在适当的位置加入如下标签即可：1&lt;!--more--&gt; 创建文章12hexo new [layout] &lt;title&gt;hexo new MyPage 插入图片修改_config.yml配置文件post_asset_folder项为true。创建文章使用命令如下：1hexo new 'article title' 使用完命令之后，在source/_post文件夹里面就会出现一个“article title.md”的文件和一个“article title”的文件夹。 Jekyllrb安装配置Jekyllrb依赖Ruby，需要安装Ruby环境 安装Minimal MistakesMinimal Mistakes（https://mademistakes.com/work/minimal-mistakes-jekyll-theme/）是一个Jekyllrb主题 评论服务Disqus第三方评论服务。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
</search>
