<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[POI两种读取Excel的方式]]></title>
    <url>%2F2017%2F12%2F18%2Fpoi-read-excel%2F</url>
    <content type="text"><![CDATA[前言在实际项目上遇到了上传 Excel 并解析到数据库中的需求，经分析后选择 Apache POI 来实现，故事也就开始了…… 常规模式123456789101112131415161718192021222324252627282930313233343536373839File file = new File(yourFilepath);FileInputStream is = new FileInputStream(file);Workbook workbook = WorkbookFactory.create(is);FormulaEvaluator formulaEvaluator = workbook.getCreationHelper().createFormulaEvaluator();for (Sheet sheet : workbook) &#123; for (Row row : sheet) &#123; for (Cell cell : row) &#123; // Alternatively, get the value and format it yourself switch (formulaEvaluator.evaluateInCell(cell).getCellTypeEnum()) &#123; case STRING: System.out.println(cell.getRichStringCellValue().getString()); break; case NUMERIC: if (DateUtil.isCellDateFormatted(cell)) &#123; System.out.println(cell.getDateCellValue()); &#125; else &#123; System.out.println(cell.getNumericCellValue()); &#125; break; case BOOLEAN: System.out.println(cell.getBooleanCellValue()); break; case FORMULA: System.out.println(cell.getCellFormula()); break; case BLANK: System.out.println(); break; default: System.out.println(); &#125; &#125; &#125;&#125; 优点：取值方便，可供调用方法多； 缺点：一次性读完值，在读取大量数据时可能会出现堆溢出。 事件驱动模式优点：逐个单元格读取，理论上多大数据都能处理； 缺点：调用方法较少，需要自己动手堆数据进行处理。 查看 Excel XML 映射关系——新增 Excel 后缀名 .zip，打开 xl &gt; worksheets &gt; sheet1.xml ，查看对应的标签节点信息，通过 POI 提供的方法来读取。 Excel XML 片段截取： 1234567891011121314151617181920212223242526&lt;row r="1" spans="1:8" s="4" customFormat="1" ht="18"&gt; &lt;c r="A1" s="3" t="s"&gt; &lt;v&gt;6&lt;/v&gt; &lt;/c&gt; &lt;c r="B1" s="3" t="s"&gt; &lt;v&gt;7&lt;/v&gt; &lt;/c&gt; &lt;c r="C1" s="3" t="s"&gt; &lt;v&gt;8&lt;/v&gt; &lt;/c&gt; &lt;c r="D1" s="3" t="s"&gt; &lt;v&gt;9&lt;/v&gt; &lt;/c&gt; &lt;c r="E1" s="3" t="s"&gt; &lt;v&gt;10&lt;/v&gt; &lt;/c&gt; &lt;c r="F1" s="3" t="s"&gt; &lt;v&gt;11&lt;/v&gt; &lt;/c&gt; &lt;c r="G1" s="3" t="s"&gt; &lt;v&gt;12&lt;/v&gt; &lt;/c&gt; &lt;c r="H1" s="3" t="s"&gt; &lt;v&gt;13&lt;/v&gt; &lt;/c&gt;&lt;/row&gt; 读取 row c r t 等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224public class TestEventModel &#123; // EXCEL 读取文件 public void processOneSheet(String filename) throws Exception &#123; OPCPackage pkg = OPCPackage.open(filename); XSSFReader r = new XSSFReader(pkg); SharedStringsTable sst = r.getSharedStringsTable(); XMLReader parser = fetchSheetParser(sst); InputStream sheet = r.getSheet("rId1"); InputSource sheetSource = new InputSource(sheet); parser.parse(sheetSource); sheet.close(); &#125; public XMLReader fetchSheetParser(SharedStringsTable sst) throws SAXException &#123; XMLReader parser = XMLReaderFactory.createXMLReader("org.apache.xerces.parsers.SAXParser"); ContentHandler handler = new SheetHandler(sst); parser.setContentHandler(handler); return parser; &#125; private static class SheetHandler extends DefaultHandler &#123; private SharedStringsTable sst; private String lastContents; private boolean nextIsString; private int curRowNum = 0; private char nextCell = 'A'; private Map&lt;String, String&gt; rowData = new HashMap&lt;String, String&gt;(); private SheetHandler(SharedStringsTable sst) &#123; this.sst = sst; &#125; // 开始读取 excel xml文件中的标签 public void startElement(String uri, String localName, String name, Attributes attributes) throws SAXException &#123; // 读到了一行 &lt;row&gt;&lt;/row&gt; if (name.equals("row")) &#123; // 取得当前的行数 curRowNum = Integer.parseInt(attributes.getValue("r")); // 将下一列数置为第一列，也就是 excel 中的 A nextCell = 'A'; &#125; // 开始读列数 if (name.equals("c")) &#123; // 取得要读取的列数，值为 EXCEL 的单元格位置 A1 B1 C1 D1... String readCell = attributes.getValue("r"); // 取得当前行的第一列 A1 String curCell = nextCell + String.valueOf(curRowNum); // 循环判断，解决单元格空值被跳过的问题（A4为空的话，A4就不会被 attributes.getValue("r") 取到） // 当被跳过，单元格会错位，这里就进行判断，不相等，那么单元格列数向后 + 1 为实际单元格 while (!curCell.equals(readCell)) &#123; // rowData——把一行单元格里的数据整合到一个 Map 中，key 为列数，值为对应的值 rowData.put(curCell, ""); // 单元格列数加一 nextCell = (char) ((int) nextCell + 1); // 取得当前正确的单元格 curCell = nextCell + String.valueOf(curRowNum); &#125; // 由于当前单元格加一，下一个单元格也要做出对应的改变 nextCell = (char) ((int) nextCell + 1); // 处理单元格数据类型，全当做 string 读出来，之后对应处理 String cellType = attributes.getValue("t"); if (cellType != null &amp;&amp; cellType.equals("s")) &#123; nextIsString = true; &#125; else &#123; nextIsString = false; &#125; &#125; lastContents = ""; &#125; public void endElement(String uri, String localName, String name) throws SAXException &#123; // 结束读取 if (nextIsString) &#123; // 取得单元格里的值作为字符串 int idx = Integer.parseInt(lastContents); lastContents = new XSSFRichTextString(sst.getEntryAt(idx)).toString(); nextIsString = false; &#125; if (name.equals("v")) &#123; // 取当前单元格的位置，并作为 key set 到 rowData 中，完成数据封装 String curCell = (char) ((int) nextCell - 1) + String.valueOf(curRowNum); rowData.put(curCell, lastContents); &#125; // 如果读到行结束 if (name.equals("row")) &#123; // 第一行为表头，不处理 if (curRowNum == 1) &#123; return; &#125; // 循环取 A-H 位置的值，这里要取到的值要写死在长度那，超出的不会写入到数据库 for (int i = (int) 'A'; i &lt;= (int) 'H'; i++) &#123; // 取当前列 String curCell = (char) i + String.valueOf(curRowNum); // 从 rowData 里取出值 String data = rowData.get(curCell); // 如果是单元格内是空格，会出现被置为 null 的情况，这里统一置成空字符串 data = data == null ? "" : data.trim(); switch ((char) i) &#123; case 'A': // 如果 A 列是日期，能处理 yyyy/MM/DD 和 yyyy-MM-dd 两种类型 if (data.equals("")) &#123; // do something setDate(null); &#125; else &#123; SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd"); Date date; try &#123; date = sdf.parse(data); &#125; catch (ParseException e) &#123; try &#123; date = calculateDate(data); &#125; catch (Exception e1) &#123; // do something for error message continue; &#125; &#125; // do something setDate(date); &#125; break; case 'B': System.out.printf(d); break; case 'C': System.out.printf(d); break; case 'D': System.out.printf(d); break; case 'E': System.out.printf(d); break; case 'F': System.out.printf(d); break; case 'G': System.out.printf(d); break; case 'H': System.out.printf(d); break; &#125; &#125; rowData.clear(); &#125; // 读完 excel 标志 if (name.equals("worksheet")) &#123; System.out.println("读取结束"); &#125; &#125; public void characters(char[] ch, int start, int length) throws SAXException &#123; lastContents += new String(ch, start, length); &#125; private Date calculateDate(String data) throws Exception &#123; if (null == data) &#123; return null; &#125; // 从 1900年到1970年的天数是25569天，减去之后再进行操作 long millisecond = (Long.parseLong(data) - 25569) * 24 * 60 * 60 * 1000; if (millisecond &lt; 0) &#123; return new Date(0); &#125; return new Date(millisecond); &#125; &#125; public static void main(String[] args) throws Exception &#123; TestEventModel testEventModel = new TestEventModel(); testEventModel.processOneSheet(yourFilePath); &#125;&#125;]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MySQL通识 - 1]]></title>
    <url>%2F2017%2F12%2F14%2Fmysql-tutorial-1%2F</url>
    <content type="text"><![CDATA[基础运维命令用户管理查询MySQL所有用户：12SELECT User, Host, Password FROM mysql.user;SELECT DISTINCT User FROM mysql.user; 添加MySQL用户：1234create user keaimo identified by 'keaimopw';grant all privileges on *.* to keaimo@'%' identified by 'keaimopw';show grants for 'keaimo'; 忘记root密码：方法一： 更改配置文件/etc/my.cnf,在[mysqld]的段上加上一句skip-grant-tables保存并退出； 重启MySQL； 登录并修改密码： 1234mysql&gt; USE mysql ; mysql&gt; UPDATE user SET Password=password( 'new-password' ) WHERE User='root'; mysql&gt; flush privileges ; mysql&gt; quit 将MySQL配置改回来； 重启MySQL； 方法二： KILL掉系统里的MySQL进程； 1killall -TERM mysqld 用以下命令启动MySQL，以不检查权限的方式启动(safe_mysqld是mysqld_safe的符号链接)； 1safe_mysqld --skip-grant-tables &amp; 然后用空密码方式使用root用户登录 MySQL； 1mysql -u root 修改root用户的密码； 123mysql&gt; update mysql.user set password=PASSWORD('新密码') where User='root';mysql&gt; flush privileges;mysql&gt; quit 方法三如果系统中没有safe_mysqld，可以使用如下方式恢复： 停止mysqld(您可能有其它的方法,总之停止mysqld的运行就可以了)； 1/etc/init.d/mysql stop 用以下命令启动MySQL，以不检查权限的方式启动； 1mysqld --skip-grant-tables &amp; 然后用空密码方式使用root用户登录 MySQL； 1mysql -u root 修改root用户的密码； 123mysql&gt; update mysql.user set password=PASSWORD('newpassword') where User='root'; mysql&gt; flush privileges; mysql&gt; quit 重新启动MySQL 1/etc/init.d/mysql restart 环境信息MySQL版本信息 Shell命令： 1mysql -V MySQL中： 1mysql&gt; status; help中查找: 1mysql --help | grep Distrib 使用mysql函数： 1mysql&gt; select version();]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL通识 - 2]]></title>
    <url>%2F2017%2F12%2F14%2Fmysql-tutorial-2%2F</url>
    <content type="text"><![CDATA[MySQL主从复制准备两台MySQL服务器，版本越接近越好]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存中的Cache]]></title>
    <url>%2F2017%2F12%2F12%2Flinux-cache%2F</url>
    <content type="text"><![CDATA[在Linux系统中，我们经常用free命令来查看系统内存的使用状态。在一个RHEL6的系统上，free命令的显示内容大概是这样一个状态：12345[root@tencent64 ~]# free total used free shared buffers cachedMem: 132256952 72571772 59685180 0 1762632 53034704-/+ buffers/cache: 17774436 114482516Swap: 2101192 508 2100684 这里的默认显示单位是kb，我的服务器是128G内存，所以数字显得比较大。这个命令几乎是每一个使用过Linux的人必会的命令，但越是这样的命令，似乎真正明白的人越少（我是说比例越少）。一般情况下，对此命令输出的理解可以分这几个层次： 不了解。这样的人的第一反应是：天啊，内存用了好多，70个多G，可是我几乎没有运行什么大程序啊？为什么会这样？Linux好占内存！ 自以为很了解。这样的人一般评估过会说：嗯，根据我专业的眼光看的出来，内存才用了17G左右，还有很多剩余内存可用。buffers/cache占用的较多，说明系统中有进程曾经读写过文件，但是不要紧，这部分内存是当空闲来用的。 真的很了解。这种人的反应反而让人感觉最不懂Linux，他们的反应是：free显示的是这样，好吧我知道了。神马？你问我这些内存够不够，我当然不知道啦！我特么怎么知道你程序怎么写的？ 根据目前网络上技术文档的内容，我相信绝大多数了解一点Linux的人应该处在第二种层次。大家普遍认为，buffers和cached所占用的内存空间是可以在内存压力较大的时候被释放当做空闲空间用的。但真的是这样么？在论证这个题目之前，我们先简要介绍一下buffers和cached是什么意思： 什么是buffer/cachebuffer和cache是两个在计算机技术中被用滥的名词，放在不通语境下会有不同的意义。在Linux的内存管理中，这里的buffer指Linux内存的：Buffer cache。这里的cache指Linux内存中的：Page cache。翻译成中文可以叫做缓冲区缓存和页面缓存。在历史上，它们一个（buffer）被用来当成对io设备写的缓存，而另一个（cache）被用来当作对io设备的读缓存，这里的io设备，主要指的是块设备文件和文件系统上的普通文件。但是现在，它们的意义已经不一样了。在当前的内核中，page cache顾名思义就是针对内存页的缓存，说白了就是，如果有内存是以page进行分配管理的，都可以使用page cache作为其缓存来管理使用。当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到cache功能，则都集中到buffer cache中来使用。（从这个角度出发，是不是buffer cache改名叫做block cache更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在X86上无论是32位还是64位都是4k。 明白了这两套缓存系统的区别，就可以理解它们究竟都可以用来做什么了。 什么是page cachePage cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read／write操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用：mmap是不是很自然的也应该用到page cache？在当前的系统实现里，page cache也被作为其它文件类型的缓存设备来用，所以事实上page cache也负责了大部分的块设备文件的缓存工作。 什么是buffer cacheBuffer cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用buffer cache进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache的内容会被改变，而buffer cache则可以用来将page标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个page写回，而只需要写回修改的部分即可。 如何回收cacheLinux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 但是这种清缓存的工作也并不是没有成本。理解cache是干什么的就可以明白清缓存必须保证cache中的数据跟对应文件中的数据一致，才能对cache进行释放。所以伴随着cache清除的行为的，一般都是系统IO飙高。因为内核要对比cache中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。 在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以使用下面这个文件来人工触发缓存清除的操作：12[root@tencent64 ~]# cat /proc/sys/vm/drop_caches 1 方法是：1echo 1 &gt; /proc/sys/vm/drop_caches 当然，这个文件可以设置的值分别为1、2、3。它们所表示的含义为：echo 1 &gt; /proc/sys/vm/drop_caches:表示清除pagecache。 echo 2 &gt; /proc/sys/vm/drop_caches:表示清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。 echo 3 &gt; /proc/sys/vm/drop_caches:表示清除pagecache和slab分配器中的缓存对象。 cache都能被回收么我们分析了cache能被回收的情况，那么有没有不能被回收的cache呢？当然有。我们先来看第一种情况： tmpfs大家知道Linux提供一种“临时”文件系统叫做tmpfs，它可以将内存的一部分空间拿来当做文件系统使用，使内存空间可以当做目录文件来用。现在绝大多数Linux系统都有一个叫做/dev/shm的tmpfs目录，就是这样一种存在。当然，我们也可以手工创建一个自己的tmpfs，方法如下： 12345678910[root@tencent64 ~]# mkdir /tmp/tmpfs[root@tencent64 ~]# mount -t tmpfs -o size=20G none /tmp/tmpfs/[root@tencent64 ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda1 10325000 3529604 6270916 37% //dev/sda3 20646064 9595940 10001360 49% /usr/local/dev/mapper/vg-data 103212320 26244284 71725156 27% /datatmpfs 66128476 14709004 51419472 23% /dev/shmnone 20971520 0 20971520 0% /tmp/tmpfs 于是我们就创建了一个新的tmpfs，空间是20G，我们可以在/tmp/tmpfs中创建一个20G以内的文件。如果我们创建的文件实际占用的空间是内存的话，那么这些数据应该占用内存空间的什么部分呢？根据pagecache的实现功能可以理解，既然是某种文件系统，那么自然该使用pagecache的空间来管理。我们试试是不是这样？123456789101112131415[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 36 89 0 1 19-/+ buffers/cache: 15 111Swap: 2 0 2[root@tencent64 ~]# dd if=/dev/zero of=/tmp/tmpfs/testfile bs=1G count=1313+0 records in13+0 records out13958643712 bytes (14 GB) copied, 9.49858 s, 1.5 GB/s[root@tencent64 ~]# [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 49 76 0 1 32-/+ buffers/cache: 15 110Swap: 2 0 2 我们在tmpfs目录下创建了一个13G的文件，并通过前后free命令的对比发现，cached增长了13G，说明这个文件确实放在了内存里并且内核使用的是cache作为存储。再看看我们关心的指标： -/+ buffers/cache那一行。我们发现，在这种情况下free命令仍然提示我们有110G内存可用，但是真的有这么多么？我们可以人工触发内存回收看看现在到底能回收多少内存：123456[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 43 82 0 0 29-/+ buffers/cache: 14 111Swap: 2 0 2 可以看到，cached占用的空间并没有像我们想象的那样完全被释放，其中13G的空间仍然被/tmp/tmpfs中的文件占用的。当然，我的系统中还有其他不可释放的cache占用着其余16G内存空间。那么tmpfs占用的cache空间什么时候会被释放呢？是在其文件被删除的时候.如果不删除文件，无论内存耗尽到什么程度，内核都不会自动帮你把tmpfs中的文件删除来释放cache空间。 123456[root@tencent64 ~]# rm /tmp/tmpfs/testfile [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 这是我们分析的第一种cache不能被回收的情况。还有其他情况，比如： 共享内存共享内存是系统提供给我们的一种常用的进程间通信（IPC）方式，但是这种通信方式不能在shell中申请和使用，所以我们需要一个简单的测试程序，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778[root@tencent64 ~]# cat shm.c #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;string.h&gt;#define MEMSIZE 2048*1024*1023intmain()&#123; int shmid; char *ptr; pid_t pid; struct shmid_ds buf; int ret; shmid = shmget(IPC_PRIVATE, MEMSIZE, 0600); if (shmid&lt;0) &#123; perror("shmget()"); exit(1); &#125; ret = shmctl(shmid, IPC_STAT, &amp;buf); if (ret &lt; 0) &#123; perror("shmctl()"); exit(1); &#125; printf("shmid: %d\n", shmid); printf("shmsize: %d\n", buf.shm_segsz); buf.shm_segsz *= 2; ret = shmctl(shmid, IPC_SET, &amp;buf); if (ret &lt; 0) &#123; perror("shmctl()"); exit(1); &#125; ret = shmctl(shmid, IPC_SET, &amp;buf); if (ret &lt; 0) &#123; perror("shmctl()"); exit(1); &#125; printf("shmid: %d\n", shmid); printf("shmsize: %d\n", buf.shm_segsz); pid = fork(); if (pid&lt;0) &#123; perror("fork()"); exit(1); &#125; if (pid==0) &#123; ptr = shmat(shmid, NULL, 0); if (ptr==(void*)-1) &#123; perror("shmat()"); exit(1); &#125; bzero(ptr, MEMSIZE); strcpy(ptr, "Hello!"); exit(0); &#125; else &#123; wait(NULL); ptr = shmat(shmid, NULL, 0); if (ptr==(void*)-1) &#123; perror("shmat()"); exit(1); &#125; puts(ptr); exit(0); &#125;&#125; 程序功能很简单，就是申请一段不到2G共享内存，然后打开一个子进程对这段共享内存做一个初始化操作，父进程等子进程初始化完之后输出一下共享内存的内容，然后退出。但是退出之前并没有删除这段共享内存。我们来看看这个程序执行前后的内存使用： 12345678910111213141516[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2[root@tencent64 ~]# ./shm shmid: 294918shmsize: 2145386496shmid: 294918shmsize: -4194304Hello![root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2 cached空间由16G涨到了18G。那么这段cache能被回收么？继续测试： 123456[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2 结果是仍然不可回收。大家可以观察到，这段共享内存即使没人使用，仍然会长期存放在cache中，直到其被删除。删除方法有两种，一种是程序中使用shmctl()去IPC_RMID，另一种是使用ipcrm命令。我们来删除试试： 1234567891011121314151617181920212223242526272829[root@tencent64 ~]# ipcs -m------ Shared Memory Segments --------key shmid owner perms bytes nattch status 0x00005feb 0 root 666 12000 4 0x00005fe7 32769 root 666 524288 2 0x00005fe8 65538 root 666 2097152 2 0x00038c0e 131075 root 777 2072 1 0x00038c14 163844 root 777 5603392 0 0x00038c09 196613 root 777 221248 0 0x00000000 294918 root 600 2145386496 0 [root@tencent64 ~]# ipcrm -m 294918[root@tencent64 ~]# ipcs -m------ Shared Memory Segments --------key shmid owner perms bytes nattch status 0x00005feb 0 root 666 12000 4 0x00005fe7 32769 root 666 524288 2 0x00005fe8 65538 root 666 2097152 2 0x00038c0e 131075 root 777 2072 1 0x00038c14 163844 root 777 5603392 0 0x00038c09 196613 root 777 221248 0 [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 删除共享内存后，cache被正常释放了。这个行为与tmpfs的逻辑类似。内核底层在实现共享内存（shm）、消息队列（msg）和信号量数组（sem）这些POSIX:XSI的IPC机制的内存存储时，使用的都是tmpfs。这也是为什么共享内存的操作逻辑与tmpfs类似的原因。当然，一般情况下是shm占用的内存更多，所以我们在此重点强调共享内存的使用。说到共享内存，Linux还给我们提供了另外一种共享内存的方法，就是： mmapmmap()是一个非常重要的系统调用，这仅从mmap本身的功能描述上是看不出来的。从字面上看，mmap就是将一个文件映射进进程的虚拟内存地址，之后就可以通过操作内存的方式对文件的内容进行操作。但是实际上这个调用的用途是很广泛的。当malloc申请内存时，小段内存内核使用sbrk处理，而大段内存就会使用mmap。当系统调用exec族函数执行时，因为其本质上是将一个可执行文件加载到内存执行，所以内核很自然的就可以使用mmap方式进行处理。我们在此仅仅考虑一种情况，就是使用mmap进行共享内存的申请时，会不会跟shmget()一样也使用cache？ 同样，我们也需要一个简单的测试程序：12345678910111213141516171819202122232425262728293031323334353637383940[root@tencent64 ~]# cat mmap.c #include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;strings.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#define MEMSIZE 1024*1024*1023*2#define MPFILE "./mmapfile"int main()&#123; void *ptr; int fd; fd = open(MPFILE, O_RDWR); if (fd &lt; 0) &#123; perror("open()"); exit(1); &#125; ptr = mmap(NULL, MEMSIZE, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANON, fd, 0); if (ptr == NULL) &#123; perror("malloc()"); exit(1); &#125; printf("%p\n", ptr); bzero(ptr, MEMSIZE); sleep(100); munmap(ptr, MEMSIZE); close(fd); exit(1);&#125; 这次我们干脆不用什么父子进程的方式了，就一个进程，申请一段2G的mmap共享内存，然后初始化这段空间之后等待100秒，再解除影射所以我们需要在它sleep这100秒内检查我们的系统内存使用，看看它用的是什么空间？当然在这之前要先创建一个2G的文件./mmapfile。结果如下：1234567[root@tencent64 ~]# dd if=/dev/zero of=mmapfile bs=1G count=2[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 然后执行测试程序： 123456789101112131415[root@tencent64 ~]# ./mmap &amp;[1] 191570x7f1ae3635000[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2[root@tencent64 ~]# echo 3 &gt; /proc/sys/vm/drop_caches[root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 32 93 0 0 18-/+ buffers/cache: 14 111Swap: 2 0 2 我们可以看到，在程序执行期间，cached一直为18G，比之前涨了2G，并且此时这段cache仍然无法被回收。然后我们等待100秒之后程序结束。 12345678[root@tencent64 ~]# [1]+ Exit 1 ./mmap[root@tencent64 ~]# [root@tencent64 ~]# free -g total used free shared buffers cachedMem: 126 30 95 0 0 16-/+ buffers/cache: 14 111Swap: 2 0 2 程序退出之后，cached占用的空间被释放。这样我们可以看到，使用mmap申请标志状态为MAP_SHARED的内存，内核也是使用的cache进行存储的。在进程对相关内存没有释放之前，这段cache也是不能被正常释放的。实际上，mmap的MAP_SHARED方式申请的内存，在内核中也是由tmpfs实现的。由此我们也可以推测，由于共享库的只读部分在内存中都是以mmap的MAP_SHARED方式进行管理，实际上它们也都是要占用cache且无法被释放的。 最后我们通过三个测试例子，发现Linux系统内存中的cache并不是在所有情况下都能被释放当做空闲空间用的。并且也也明确了，即使可以释放cache，也并不是对系统来说没有成本的。总结一下要点，我们应该记得这样几点： 当cache作为文件缓存被释放的时候会引发IO变高，这是cache加快文件访问速度所要付出的成本。 tmpfs中存储的文件会占用cache空间，除非文件删除否则这个cache不会被自动释放。 使用shmget方式申请的共享内存会占用cache空间，除非共享内存被ipcrm或者使用shmctl去IPC_RMID，否则相关的cache空间都不会被自动释放。 使用mmap方法申请的MAP_SHARED标志的内存会占用cache空间，除非进程将这段内存munmap，否则相关的cache空间都不会被自动释放。 实际上shmget、mmap的共享内存，在内核层都是通过tmpfs实现的，tmpfs实现的存储用的都是cache。 当理解了这些的时候，希望大家对free命令的理解可以达到我们说的第三个层次。我们应该明白，内存的使用并不是简单的概念，cache也并不是真的可以当成空闲空间用的。如果我们要真正深刻理解你的系统上的内存到底使用的是否合理，是需要理解清楚很多更细节知识，并且对相关业务的实现做更细节判断的。我们当前实验场景是Centos 6的环境，不同版本的Linux的free现实的状态可能不一样，大家可以自己去找出不同的原因。 当然，本文所述的也不是所有的cache不能被释放的情形。那么，在你的应用场景下，还有那些cache不能被释放的场景呢？]]></content>
      <categories>
        <category>Linux运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java关键字通识]]></title>
    <url>%2F2017%2F12%2F11%2Fjava-keywords%2F</url>
    <content type="text"><![CDATA[strictfpstrictfp的意思是FP-strict，也就是说精确浮点的意思。在Java虚拟机进行浮点运算时，如果没有指定strictfp关键字时，Java的编译器以及运行环境在对浮点运算的表达式是采取一种近似于我行我素的行为来完成这些操作，以致于得到的结果往往无法令你满意。而一旦使用了strictfp来声明一个类、接口或者方法时，那么所声明的范围内Java的编译器以及运行环境会完全依照浮点规范IEEE-754来执行。因此如果你想让你的浮点运算更加精确，而且不会因为不同的硬件平台所执行的结果不一致的话，那就请用关键字strictfp。 strictfp不能解决所谓”精确“问题，是用来保证可移植性的。如果没有加strictfp关键字，在不同的平台下面，可能会得到不同的结果。使用strictfp关键字的目的，是保证平台移植之后，浮点运算结果是一致的。如果要进行精确的金额计算，还是需要使用BigDecimal。 transient变量修饰符(只能修饰字段)。标记为transient的变量，在对象存储时，这些变量状态不会被持久化。当对象序列化的保存在存储器上时，不希望有些字段数据被保存，为了保证安全性，可以把这些字段声明为transient。 volatilevolatile修饰变量。在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 Java内存模型规定了所有变量都存储在主内存中，每条线程都有自己的工作内存，线程的工作内存保存了被该线程使用到变量的主内存副本拷贝，线程对变量的所有操作(读取,赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程也不能直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 当一个变量定义成volatile之后, 保证了此变量对所有线程的可见性,也就是说当一条线程修改了这个变量的值,新的值对于其它线程来说是可以立即得知的.此时,该变量的读写操作直接在主内存中完成。Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取－修改－写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。 在多线程并发的环境下, 各个线程的读/写操作可能有重叠现象, 在这个时候, volatile并不能保证数据同步。 volatile适用于简单的标志量的场景中。如：12345678910public class CheesyCounter &#123; private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; synchronized通过 synchronized 关键字来实现，所有加上synchronized 和 块语句，在多线程访问的时候，同一时刻只能有一个线程能够用。synchronized用来修饰方法或者代码块。]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java多线程常识]]></title>
    <url>%2F2017%2F12%2F09%2Fjava-multithreading-common-sense%2F</url>
    <content type="text"><![CDATA[Double Check在 Effecitve Java 一书的第 48 条中提到了双重检查模式，并指出这种模式在 Java 中通常并不适用。该模式的结构如下所示：12345678910public Resource getResource() &#123; if (resource == null) &#123; synchronized(this)&#123; if (resource==null) &#123; resource = new Resource(); &#125; &#125; &#125; return resource;&#125; 该模式是对下面的代码改进：123456public synchronized Resource getResource()&#123; if (resource == null)&#123; resource = new Resource(); &#125; return resource;&#125; 这段代码的目的是对 resource 延迟初始化。但是每次访问的时候都需要同步。为了减少同步的开销，于是有了双重检查模式。在 Java 中双重检查模式无效的原因是在不同步的情况下引用类型不是线程安全的。对于除了 long 和 double 的基本类型，双重检查模式是适用 的。比如下面这段代码就是正确的：1234567891011private int count;public int getCount()&#123; if (count == 0)&#123; synchronized(this)&#123; if (count == 0)&#123; count = computeCount(); //一个耗时的计算 &#125; &#125; &#125; return count;&#125; 上面就是关于java中双重检查模式（double-check idiom）的一般结论。但是事情还没有结束，因为java的内存模式也在改进中。Doug Lea 在他的文章中写道：“根据最新的 JSR133 的 Java 内存模型，如果将引用类型声明为 volatile，双重检查模式就可以工作了”，参见 http://gee.cs.oswego.edu/dl/cpj/updates.html 。所以以后要在 Java 中使用双重检查模式，可以使用下面的代码：1234567891011private volatile Resource resource;public Resource getResource()&#123; if (resource == null)&#123; synchronized(this)&#123; if (resource==null)&#123; resource = new Resource(); &#125; &#125; &#125; return resource;&#125; 当然了，得是在遵循 JSR133 规范的 Java 中。所以，double-check 在 J2SE 1.4 或早期版本在多线程或者 JVM 调优时由于 out-of-order writes，是不可用的。 这个问题在 J2SE 5.0 中已经被修复，可以使用 volatile 关键字来保证多线程下的单例。12345678910111213public class Singleton &#123; private volatile Singleton instance = null; public Singleton getInstance() &#123; if (instance == null) &#123; synchronized(this) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 推荐方法 是Initialization on Demand Holder（IODH），详见 http://en.wikipedia.org/wiki/Initialization_on_demand_holder_idiom12345678910public class Singleton &#123; static class SingletonHolder &#123; static Singleton instance = new Singleton(); &#125; public static Singleton getInstance()&#123; return SingletonHolder.instance; &#125;&#125; 编译并运行上述代码，运行结果为：true，即创建的单例对象s1和s2为同一对象。由于静态单例对象没有作为Singleton的成员变量直接实例化，因此类加载时不会实例化Singleton，第一次调用getInstance()时将加载内部类HolderClass，在该内部类中定义了一个static类型的变量instance，此时会首先初始化这个成员变量，由Java虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于getInstance()方法没有任何线程锁定，因此其性能不会造成任何影响。通过使用IoDH，我们既可以实现延迟加载，又可以保证线程安全，不影响系统性能，不失为一种最好的Java语言单例模式实现方式（其缺点是与编程语言本身的特性相关，很多面向对象语言不支持IoDH）。 线程池Java通过Executors提供四种线程池，分别为：newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。示例代码如下：123456789101112131415161718192021package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; try &#123; Thread.sleep(index * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cachedThreadPool.execute(new Runnable() &#123; public void run() &#123; System.out.println(index); &#125; &#125;); &#125; &#125; &#125; 线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。 newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。示例代码如下：123456789101112131415161718192021package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 因为线程池大小为3，每个任务输出index后sleep 2秒，所以每两秒打印3个数字。定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors() newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。延迟执行示例代码如下：1234567891011121314package test; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.schedule(new Runnable() &#123; public void run() &#123; System.out.println("delay 3 seconds"); &#125; &#125;, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟3秒执行。定期执行示例代码如下：1234567891011121314package test; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; public void run() &#123; System.out.println("delay 1 seconds, and excute every 3 seconds"); &#125; &#125;, 1, 3, TimeUnit.SECONDS); &#125; &#125; 表示延迟1秒后每3秒执行一次。 newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。示例代码如下：123456789101112131415161718192021package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 10; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(index); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; &#125; 结果依次输出，相当于顺序执行各个任务。你可以使用JDK自带的监控工具来监控我们创建的线程数量，运行一个不终止的线程，创建指定量的线程，来观察：工具目录：C:\Program Files\Java\jdk1.6.0_06\bin\jconsole.exe运行程序做稍微修改：12345678910111213141516171819202122232425262728package test; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class ThreadPoolExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService singleThreadExecutor = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; public void run() &#123; try &#123; while(true) &#123; System.out.println(index); Thread.sleep(10 * 1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java内存分析]]></title>
    <url>%2F2017%2F12%2F08%2Fjava-memory-analysis%2F</url>
    <content type="text"><![CDATA[内存分析通过top命令定位占用大内存的应用，通过jps命令找到应用进程号。打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。 jmapjmap命令(Java Memory Map) jmap -heap [pid] 查看整个JVM内存状态; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Attaching to process ID 22999, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.80-b11using thread-local object allocation.Parallel GC with 4 thread(s)Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2065694720 (1970.0MB) NewSize = 1310720 (1.25MB) MaxNewSize = 17592186044415 MB OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 21757952 (20.75MB) MaxPermSize = 85983232 (82.0MB) G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: capacity = 24117248 (23.0MB) used = 8397088 (8.008087158203125MB) free = 15720160 (14.991912841796875MB) 34.81777025305706% usedFrom Space: capacity = 524288 (0.5MB) used = 98304 (0.09375MB) free = 425984 (0.40625MB) 18.75% usedTo Space: capacity = 524288 (0.5MB) used = 0 (0.0MB) free = 524288 (0.5MB) 0.0% usedPS Old Generation capacity = 85983232 (82.0MB) used = 44148184 (42.102989196777344MB) free = 41835048 (39.897010803222656MB) 51.34510877655774% usedPS Perm Generation capacity = 39321600 (37.5MB) used = 39033120 (37.224884033203125MB) free = 288480 (0.275115966796875MB) 99.266357421875% used19166 interned Strings occupying 1688912 bytes. jmap -histo [pid] 查看JVM堆中对象详细占用情况 1234567891011121314151617num #instances #bytes class name---------------------------------------------- 1: 10823 3072312 [B 2: 16605 2318720 &lt;constMethodKlass&gt; 3: 18687 1388088 [C 4: 16605 1328608 &lt;methodKlass&gt; 5: 27595 1296832 &lt;symbolKlass&gt; 6: 1699 940392 &lt;constantPoolKlass&gt; 7: 2520 883408 [I 8: 1699 724944 &lt;instanceKlassKlass&gt; 9: 1472 565136 &lt;constantPoolCacheKlass&gt;10: 256 561152 [Lnet.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry;11: 12148 291552 java.lang.String12: 4505 288320 net.sf.ehcache.Element13: 7290 233280 java.lang.ThreadLocal$ThreadLocalMap$Entry14: 1946 186816 java.lang.Class15: 4509 180360 net.sf.ehcache.store.chm.SelectableConcurrentHashMap$HashEntry 其中[开头表示数组，[C [I [B 分别是char[] int[] byte[]。constMethodKlass、都实现自sun.jvm.hotspot.oops.Klass，用于在永久代里保存类的信息。 jmap -dump:format=b,file=文件名 [pid] 导出整个JVM 中内存信息,通过jhat启动一个Web Server（端口7000）查看分析结果：12jmap -dump:file=a.txt 22999jhat -J-Xmx512m a.txt kill -3 [pid]在Linux 上找到Java所在的进程号，然后执行以上命令，线程的相关信息就输出到console。inux的kill -3指令可以帮我们输出当前进程中所有线程的状态，如哪些线程在运行，哪些在等待，因为什么等待，代码哪一行等待。kill -3会将信息输出至控制台，所以使用时，被kill -3的进程最好是nohup启动的。kill -3并不会影响程序运行，不用担心他把程序杀死了。PS: 需要-Xrs JVM选择被使用。 jstackjstack 是sun JDK 自带的工具，通过该工具可以看到JVM 中线程的运行状况，包括锁等待，线程是否在运行。]]></content>
      <categories>
        <category>软件开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux运维基础]]></title>
    <url>%2F2017%2F12%2F08%2Flinux-ops-base%2F</url>
    <content type="text"><![CDATA[磁盘管理查看文件(夹)所在分区(挂载点)1234df /pathcat /etc/mtabmountfdisk -l 运行状态TOP查看系统运行情况： 输入大写P，结果按CPU占用降序排序； 输入大写M，结果按内存占用降序排序； 网络安全当VPS暴露在外网中，就会有人不断暴力破解你的SSH登录。于是就有必要使用SSH密钥来登录。并关闭密码登录。用以下命令可以查看别人暴力破解你SSH密码登录的大概情况：1grep "Failed password for invalid user" /var/log/secure | awk '&#123;print $13&#125;' | sort | uniq -c | sort -nr | more 这时可以使用SSH秘钥登录来防止暴力破解。]]></content>
      <categories>
        <category>Linux运维</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[iframe无刷新跨域上传文件并获取返回值]]></title>
    <url>%2F2017%2F12%2F08%2Fweb-upfile-iframe%2F</url>
    <content type="text"><![CDATA[通常我们会有一个统一的上传接口，这个接口会被其他的服务调用。如果出现不同域，还需要无刷新上传文件，并且获取返回值，这就有点麻烦了。比如，新浪微博启用了新域名www.weibo.com，但接口还是使用原来的域：picupload.t.sina.com.cn。 研究了一下新浪微博的处理方法，这里大概演示一下。 首先是一个正常的上传页面 upload.html 123456789101112131415&lt;script&gt; // 这个函数将来会被iframe用到 function getIframeVal(val) &#123; alert(val); &#125;&lt;/script&gt;&lt;!-- 我把upload.com指向了127.0.0.1 --&gt;&lt;form method="post" target="if" enctype="multipart/form-data" action="http://upload.com/playground/js/deal.php?cb=http://localhost/playground/js/deal_cd.html"&gt; &lt;input type="file" name="file" /&gt; &lt;input type="SUBMIT" value="upload" /&gt;&lt;/form&gt;&lt;IFRAME id="if" name="if" src="about:blank" frameborder='0'&gt;&lt;/IFRAME&gt; 这里有一个关键点是form的target要指向iframe，同时把iframe隐藏起来，这样上传的处理结果就会显示在该iframe里。action里的cb(callback)参数表示处理完成后要跳转的url，因为我们的目标是iframe，所以只会把跳转的页面输出到iframe，而不会让当前页面跳转。 还有一点，callback url要和当前页面同域。跨域的iframe无法调用父页面的内容。 再来看看deal.php，也就是form的action 1234&lt;?php// deal upload file// and get file id, you can pass other params eitherheader('location:'.$_GET['cb'].'?file_id=123'); 这里可以处理文件，然后入库。操作完成后，把文件的id及其他信息都放在url里，最后跳转到这个url。 最后来看看deal_cd.html，也就是刚刚deal.php跳转到的url，这个文件的内容会填充到页面的iframe里。 1234&lt;script type="text/javascript"&gt; var rs = window.location.search.split('?').slice(1); window.parent.getIframeVal(rs.toString().split('=').slice(1));&lt;/script&gt; 这里调用了父窗口的getIframeVal方法，这样父页面就获得了文件的id。]]></content>
      <tags>
        <tag>软件开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find命令-print0和xargs中-0的奥妙]]></title>
    <url>%2F2017%2F12%2F08%2Flinux-find-xargs%2F</url>
    <content type="text"><![CDATA[-print0默认情况下, find 每输出一个文件名, 后面都会接着输出一个换行符 (‘\n’), 因此我们看到的 find 的输出都是一行一行的: 12345678[bash-4.1.5] ; ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:09 file1.log-rw-r--r-- 1 root root 0 2010-08-02 18:09 file2.log[bash-4.1.5] ; find -name '*.log'./file2.log./file1.log 比如我想把所有的 .log 文件删掉, 可以这样配合 xargs 一起用:12345[bash-4.1.5] ; find -name '*.log'./file2.log./file1.log[bash-4.1.5] ; find -name '*.log' | xargs rm[bash-4.1.5] ; find -name '*.log' find+xargs 真的很强大. 然而: 123456789101112[bash-4.1.5] ; ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 1.log-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 2.log[bash-4.1.5] ; find -name '*.log'./file 1.log./file 2.log[bash-4.1.5] ; find -name '*.log' | xargs rmrm: cannot remove `./file': No such file or directoryrm: cannot remove `1.log': No such file or directoryrm: cannot remove `./file': No such file or directoryrm: cannot remove `2.log': No such file or directory 原因其实很简单, xargs 默认是以空白字符 (空格, TAB, 换行符) 来分割记录的, 因此文件名 ./file 1.log 被解释成了两个记录 ./file 和 1.log, 不幸的是 rm 找不到这两个文件. 为了解决此类问题, 聪明的人想出了一个办法, 让 find 在打印出一个文件名之后接着输出一个 NULL 字符 (‘\0’) 而不是换行符, 然后再告诉 xargs 也用 NULL 字符来作为记录的分隔符. 这就是 find 的 -print0 和 xargs 的 -0 的来历吧. 1234567891011[bash-4.1.5] ; ls -ltotal 0-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 1.log-rw-r--r-- 1 root root 0 2010-08-02 18:12 file 2.log[bash-4.1.5] ; find -name '*.log' -print0 | hd 0 1 2 3 4 5 6 7 8 9 A B C D E F |0123456789ABCDEF|--------+--+--+--+--+---+--+--+--+---+--+--+--+---+--+--+--+--+----------------|00000000: 2e 2f 66 69 6c 65 20 31 2e 6c 6f 67 00 2e 2f 66 |./file 1.log../f|00000010: 69 6c 65 20 32 2e 6c 6f 67 00 |ile 2.log. |[bash-4.1.5] ; find -name '*.log' -print0 | xargs -0 rm[bash-4.1.5] ; find -name '*.log' 你可能要问了, 为什么要选 ‘\0’ 而不是其他字符做分隔符呢? 这个也容易理解: 一般的编程语言中都用 ‘\0’ 来作为字符串的结束标志, 文件的路径名中不可能包含 ‘\0’ 字符. find|xargs实例查找当前目录大文件并按大小排序：1234find . -type f -size +800Mfind . -type f -size +800M -print0 | xargs -0 ls -lfind . -type f -size +800M -print0 | xargs -0 du -hfind . -type f -size +800M -print0 | xargs -0 du -h | sort -nr 查找Linux下大目录：1234du -h --max-depth=1du -h --max-depth=2 | sort -ndu -hm --max-depth=2 | sort -ndu -hm --max-depth=2 | sort -nr | head -12 删除以html结尾的10天前的文件，包括带空格的文件：12find /usr/local/backups -name &quot;*.html&quot; -mtime +10 -print0 |xargs -0 rm -rfvfind /usr/local/backups -mtime +10 -name &quot;*.html&quot; -exec rm -rf &#123;&#125; \; 当前目录下文件从大到小排序（包括隐藏文件），文件名不为”.”：12find . -maxdepth 1 ! -name &quot;.&quot; -print0 | xargs -0 du -b | sort -nr | head -10 | nlnl：可以为输出列加上编号,与cat -n相似，但空行不编号 以下功能同上，但不包括隐藏文件：1for file in *; do du -b "$file"; done|sort -nr|head -10|nl xargs结合sed替换：1find . -name "*.txt" -print0 | xargs -0 sed -i 's/aaa/bbb/g' xargs结合grep：1find . -name '*.txt' -type f -print0 |xargs -0 grep -n 'aaa' #“-n”输出行号 用rm删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用xargs去避免这个问题(xargs -0将\0作为定界符)：1find . -type f -name "*.log" -print0 | xargs -0 rm -f]]></content>
      <categories>
        <category>Linux命令</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[单点登录解决方案]]></title>
    <url>%2F2017%2F12%2F05%2Fsso-arch%2F</url>
    <content type="text"><![CDATA[什么是SSOWeb应用系统的演化总是从简单到复杂，从单功能到多功能模块再到多子系统方向发展。当前的大中型Web互联网应用基本都是多系统组成的应用群，由多个web系统协同为用户提供服务。多系统应用群，必然意味着各系统间既相对独立，又保持着某种联系。独立，意味着给用户提供一个相对完整的功能服务，比如C2C商城，比如B2C商城。联系，意味着从用户角度看，不管企业提供的服务如何多样化、系列化，在用户看来，仍旧是一个整体，用户体验不能受到影响。譬如用户的账号管理，用户应该有一个统一账号，不应该让用户在每个子系统分别注册、分别登录、再分别登出。系统的复杂性不应该让用户承担。登录用户使用系统服务，可以看做是一次用户会话过程。在单Web应用中，用户登录、登录状态判断、用户登出等操作，已有很常规的解决方案实现。在多系统应用群中，这个问题就变得有些复杂，以前本不是问题的问题，现在可能就变成了一个重大技术问题。我们要用技术手段，屏蔽系统底层本身的技术复杂性，给用户提供自然超爽的用户体验。这就是的单点登录问题，即SSO(Single Sign On)。我们这里主要讨论Web系统，应该叫Web SSO。 实际案例例如阿里系统种类繁多，典型系统应用www.taobao.com 淘宝应用、www.tmall.com 天猫应用、www.alitrip.com 阿里旅游。这些应用，当用户访问时，都需要登录。当我在一个应用如淘宝上登录后，再访问阿里旅游、天猫等其它系统，我们发现，系统都显示已登录状态。当在任意一系统退出登录后，再刷新访问其它系统，均已显示登出状态。可以看出，阿里实现了SSO。实际上，几乎所有提供复杂服务的互联网公司，都实现了SSO，如阿里、百度、新浪、网易、腾讯、58…SSO问题，是大中型Web应用经常碰到的问题，是Java架构师需要掌握的必备技能之一，中高级以上Web工程师都应对它有个了解。 SSO技术难点SSO有啥技术难点？为什么我们不能像解决单Web应用系统登录那样自然解决？为说清楚这一问题，我们得先了解下单应用系统下，用户登录的解决方案。 单应用系统登录我们讨论的应用是Web应用，大家知道，对于Web应用，系统是Browser/Server架构，Browser和Server之间的通信协议是HTTP协议。HTTP是一个无状态协议。即对服务器来说，每次收到的浏览器HTTP请求都是单一独立的，服务器并不考虑两次HTTP请求是否来自同一会话，即HTTP协议是非连接会话状态协议。对于Web应用登录，意味着登录成功后的后续访问，可以看做是登录用户和服务端的一次会话交互过程，直到用户登出结束会话。如何在非连接会话协议之上，实现这种会话的管理？ 我们需要额外的手段。通常有两种做法，一种是通过使用HTTP请求参数传递，这种方式对应用侵入性较大，一般不使用。另一种方式就是通过cookie。cookie是HTTP提供的一种机制，cookie代表一小撮数据。服务端通过HTTP响应创建好cookie后，浏览器会接收下来，下次请求会自动携带上返回给服务端。利用这个机制，我们可以实现应用层的登录会话状态管理。例如我们可以把登录状态信息保存在cookie中，这是客户端保存方式。由于会话信息在客户端，需要维护其安全性、需要加密保存、携带量会变大，这样会影响http的处理效率，同时cookie的数据携带量也有一定的限制。比较好的方式是服务端保存，cookie只保存会话信息的句柄。即在登录成功后，服务端可以创建一个唯一登录会话，并把会话标识ID通过cookie返回给浏览器，浏览器下次访问时会自动带上这个ID，服务端根据ID即可判断是此会话中的请求，从而判断出是该用户，这种操作直到登出销毁会话为止。令人高兴的是，我们使用的Web应用服务器一般都会提供这种会话基础服务，如Tomcat的Session机制。也就是说，应用开发人员不必利用Cookie亲自代码实现会话的创建、维护和销毁等整个生命周期管理，这些内容服务器Session已经提供好了，我们只需正确使用即可。当然，为了灵活性和效率，开发人员也可直接使用cookie实现自己的这种会话管理。对于Cookie，处于安全性考虑，它有一个作用域问题，这个作用域由属性Domain和Path共同决定的。也就是说，如果浏览器发送的请求不在此Cookie的作用域范围内，请求是不会带上此Cookie的。Path是访问路径，我们可以定义/根路径让其作用所有路径，Domain就不一样了。我们不能定义顶级域名如.com，让此Cookie对于所有的com网站都起作用，最大范围我们只能定义到二级域名如.taobao.com，而通常，企业的应用群可能包含有多个二级域名，如taobao.com、tmail.com、alitrip.com等等。这时，解决单系统会话问题的Cookie机制不起作用了，多系统不能共享同一会话，这就是问题的所在！ 当然，有的同学会说：我把所有的应用统一用三级域名来表示，如a.taobao.com、b.taobao.com、c.taobao.com或干脆用路径来区分不同的应用如www.taobao.com\a、www.taobao.com\b、www.taobao.com\c，这样cookie不就可以共享了么？事实是成立的，但现实应用中，多域名策略是普遍存在的，也有商业角度的考虑，这些我们必须要面对。退一步讲，即使cookie可以共享了，服务端如何识别处理这个会话？这时，我们是不能直接使用服务器所提供的Session机制的，Session是在单一应用范围内，共享Session需要特殊处理。更复杂的情况是，通常这些子系统可能是异构的，session实现机制并不相同，如有的是Java系统，有的是PHP系统。共享Session对原系统入侵性很大。至此，SSO技术问题这里讲清楚了。那我们有没有更好的通用解决方案？答案肯定是有的，但比较复杂，这也是我们专题讨论的理由。总体来说，我们需要一个中央认证服务器，来统一集中处理各子系统的登录请求。 SSO实现基本思路单Web应用登录，主要涉及到认证（用户名密码）、授权（权限定义）、会话建立（Cookie&amp;Session）、取消会话（删除Session）等几个关键环节。推广到多系统，每个系统也会涉及到认证、授权、会话建立取消等工作。那我们能不能把每个系统的认证工作抽象出来，放到单独的服务应用中取处理，是不是就能解决单点登录问题？ 思考方向是正确的，我们把这个统一处理认证服务的应用叫认证中心。当用户访问子系统需要登录时，我们把它引到认证中心，让用户到认证中心去登录认证，认证通过后返回并告知系统用户已登录。当用户再访问另一系统应用时，我们同样引导到认证中心，发现已经登录过，即返回并告知该用户已登录 三大关键问题登录信息传递问题应用系统将登录请求转给认证中心，这个很好解决，我们一个HTTP重定向即可实现。现在的问题是，用户在认证中心登录后，认证中心如何将消息转回给该系统？这是在单web系统中不存在的问题。我们知道HTTP协议传递消息只能通过请求参数方式或cookie方式，cookie跨域问题不能解决，我们只能通过URL请求参数。我们可以将认证通过消息做成一个令牌(token)再利用HTTP重定向传递给应用系统。但现在的关键是：该系统如何判断这个令牌的真伪？如果判断这个令牌确实是由认证中心发出的，且是有效的？我们还需要应用系统和认证中心之间再来个直接通信，来验证这个令牌确实是认证中心发出的，且是有效的。由于应用系统和认证中心是属于服务端之间的通信，不经过用户浏览器，相对是安全的。 用户首次登录时流程如下： 用户浏览器访问系统A需登录受限资源。 系统A发现该请求需要登录，将请求重定向到认证中心，进行登录。 认证中心呈现登录页面，用户登录，登录成功后，认证中心重定向请求到系统A，并附上认证通过令牌。 系统A与认证中心通信，验证令牌有效,证明用户已登录。 系统A将受限资源返给用户。 已登录用户首次访问应用群中系统B时： 浏览器访问另一应用B需登录受限资源。 系统B发现该请求需要登录，将请求重定向到认证中心，进行登录。 认证中心发现已经登录，即重定向请求响应到系统B，附带上认证令牌。 系统B与认证中心通信，验证令牌有效,证明用户已登录。 系统B将受限资源返回给客户端。 登录状态判断问题用户到认证中心登录后，用户和认证中心之间建立起了会话，我们把这个会话称为全局会话。当用户后续访问系统应用时，我们不可能每次应用请求都到认证中心去判定是否登录，这样效率非常低下，这也是单Web应用不需要考虑的。我们可以在系统应用和用户浏览器之间建立起局部会话，局部会话保持了客户端与该系统应用的登录状态，局部会话依附于全局会话存在，全局会话消失，局部会话必须消失。用户访问应用时，首先判断局部会话是否存在，如存在，即认为是登录状态，无需再到认证中心去判断。如不存在，就重定向到认证中心判断全局会话是否存在，如存在，按1提到的方式通知该应用，该应用与客户端就建立起它们之间局部会话，下次请求该应用，就不去认证中心验证了。 登出问题用户在一个系统登出了，访问其它子系统，也应该是登出状态。要想做到这一点，应用除结束本地局部会话外，还应该通知认证中心该用户登出。认证中心接到登出通知，即可结束全局会话，同时需要通知所有已建立局部会话的子系统，将它们的局部会话销毁。这样，用户访问其它应用时，都显示已登出状态。整个登出流程如下： 客户端向应用A发送登出Logout请求。 应用A取消本地会话，同时通知认证中心，用户已登出。 应用A返回客户端登出请求。 认证中心通知所有用户登录访问的应用，用户已登出。 实现SSO实现分成两大部分，一个是SSO Server，代表认证中心，另一个是SSO Client，代表使用SSO系统应用的登录登出组件。 登录令牌token实现前面我们讨论了，系统把用户重定向导向认证中心并登录后，认证中心要把登录成功信息通过令牌方式告诉给应用系统。认证中心会记录下来自某个应用系统的某个用户本次通过了认证中心的认证所涉及的基本信息，并生成一个登录令牌token，认证中心需要通过URL参数的形式把token传递回应用系统，由于经过客户端浏览器，故令牌token的安全性很重要。因此令牌token的实现要满足三个条件： 首先，token具有唯一性，它代表着来自某应用系统用户的一次成功登录。我们可以利用java util包工具直接生成一个32位唯一字符串来实现。1String token = UUID.randomUUID().toString(); 同时，我们定义一个javabean， TokenInfo 来承载token所表示的具体内容，即某个应用系统来的某个用户本次通过了认证中心123456public class TokenInfo &#123; private int userId; //用户唯一标识ID private String username; //用户登录名 private String ssoClient; //来自登录请求的某应用系统标识 private String globalId; //本次登录成功的全局会话sessionId ... &#125; token和tokenInfo形成了一个&lt;key,value&gt;形式的键值对，后续应用系统向认证中心验证token时还会用到。其次，token存在的有效期间不能过长，这是出于安全的角度，例如token生存最大时长为60秒。我们可以直接利用redis特性来实现这一功能。redis本质就是&lt;key,value&gt;键值对形式的内存数据库，并且这个键值对可以设置有效时长。第三，token只能使用一次，用完即作废，不能重复使用。这也是保证系统安全性。我们可以定义一个TokenUtil工具类，来实现&lt;token,tokenInfo&gt;键值对在redis中的操作，主要接口如下：123456789public class TokenUtil &#123; ... // 存储临时令牌到redis中，存活期60秒 public static void setToken(String tokenId, TokenInfo tokenInfo)&#123; ... &#125; //根据token键取TokenInfo public static TokenInfo getToken(String tokenId)&#123; ... &#125; //删除某个 token键值 public static void delToken(String tokenId)&#123; ... &#125; &#125; 全局会话和本地会话的实现用户登录成功后，在浏览器用户和认证中心之间会建立全局会话，浏览器用户与访问的应用系统之间，会建立本地局部会话。为简便可以使用web应用服务器(如tomcat)提供的session功能来直接实现。这里需要注意的是，我们需要根据会话ID(即sessionId)能访问到这个session。因为根据前面登出流程说明，认证中心的登出请求不是直接来自连接的浏览器用户，可能来自某应用系统。认证中心也会通知注册的系统应用进行登出。这些请求，都是系统之间的交互，不经过用户浏览器。系统要有根据sessionId访问session的能力。同时，在认证中心中，还需要维护全局会话ID和已登录系统本地局部会话ID的关系，以便认证中心能够通知已登录的系统进行登出处理。为了安全，目前的web应用服务器，如tomcat，是不提供根据sessionId访问session的能力的，那是容器级范围内的能力。我们需要在自己的应用中，自己维护一个sessionId和session直接的对应关系，我们把它放到一个Map中，方便需要时根据sessionId找到对应的session。同时，我们借助web容器提供的session事件监听能力，程序来维护这种对应关系。认证中心涉及到两个类，GlobalSessions和GlobalSessionListener，相关代码如下：12345678910111213141516171819202122232425public class GlobalSessions &#123; //存放所有全局会话 private static Map&lt;String, HttpSession&gt; sessions = new HashMap&lt;String,HttpSession&gt;(); public static void addSession(String sessionId, HttpSession session) &#123; sessions.put(sessionId, session); &#125; public static void delSession(String sessionId) &#123; sessions.remove(sessionId); &#125; //根据id得到session public static HttpSession getSession(String sessionId) &#123; return sessions.get(sessionId); &#125;&#125; public class GlobalSessionListener implements HttpSessionListener &#123; public void sessionCreated(HttpSessionEvent httpSessionEvent) &#123; GlobalSessions.addSession( httpSessionEvent.getSession().getId(), httpSessionEvent.getSession()); &#125; public void sessionDestroyed(HttpSessionEvent httpSessionEvent) &#123; GlobalSessions.delSession(httpSessionEvent.getSession().getId()); &#125; &#125; SSO Client对应的是LocalSessions和LocalSessionListener,实现方式同上。 应用系统和认证中心之间的通信根据SSO实现流程，应用系统和认证中心之间需要直接通信。如应用系统需要向认证中心验证令牌token的真伪，应用系统通知认证中心登出，认证中心通知所有已注册应用系统登出等。这是Server之间的通信，如何实现呢？我们可以使用HTTP进行通信，返回的消息应答格式可采用JSON格式。Java的net包，提供了http访问服务器的能力。这里，我们使用apache提供的一个更强大的开源框架，httpclient，来实现应用系统和认证中心之间的直接通信。JSON和JavaBean之间的转换，目前常用的有两个工具包，一个是json-lib，还有一个是Jackson，Jackson效率较高，依赖包少，社区活跃度大，这里我们使用Jackson这个工具包。如应用系统向认证中心发送token验证请求的代码片段如下： 123456789101112131415161718192021222324252627282930//向认证中心发送验证token请求 String verifyURL = "http://" + server + PropertiesConfigUtil.getProperty("sso.server.verify"); HttpClient httpClient = new DefaultHttpClient(); //serverName作为本应用标识 HttpGet httpGet = new HttpGet(verifyURL + "?token=" + token + "&amp;localId=" + request.getSession().getId()); try&#123; HttpResponse httpResponse = httpClient.execute(httpGet); int statusCode = httpResponse.getStatusLine().getStatusCode(); if (statusCode == HttpStatus.SC_OK) &#123; String result = EntityUtils.toString(httpResponse.getEntity(), "utf-8"); //解析json数据 ObjectMapper objectMapper = new ObjectMapper(); VerifyBean verifyResult = objectMapper.readValue(result, VerifyBean.class); //验证通过,应用返回浏览器需要验证的页面 if(verifyResult.getRet().equals("0")) &#123; Auth auth = new Auth(); auth.setUserId(verifyResult.getUserId()); auth.setUsername(verifyResult.getUsername()); auth.setGlobalId(verifyResult.getGlobalId()); request.getSession().setAttribute("auth", auth); //建立本地会话 return "redirect:http://" + returnURL; &#125; &#125; &#125; catch (Exception e) &#123; return "redirect:" + loginURL; &#125; SSO Server接口核心实现细节讨论清楚了，我们就可以根据登录登出操作流程，定义SSO Server和SSO Client所提供的接口。SSO Server认证中心包含4个重要接口，分别如下： 接口一： /page/login。此接口主要接受来自应用系统的认证请求，此时，returnURL参数需加上，用以向认证中心标识是哪个应用系统，以及返回该应用的URL。如用户没有登录，应用中心向浏览器用户显示登录页面。如已登录，则产生临时令牌token，并重定向回该系统。上面登录时序交互图中的2和此接口有关。当然，该接口也同时接受用户直接向认证中心登录，此时没有returnURL参数，认证中心直接返回登录页面。123接口名称：/page/login入参： returnURL (系统URL，可选)返回： 1.显示登录页面；2.产生临时认证token并重定向回系统； 接口二： /auth/login。处理浏览器用户登录认证请求。如带有returnURL参数，认证通过后，将产生临时认证令牌token，并携带此token重定向回系统。如没有带returnURL参数，说明用户是直接从认证中心发起的登录请求，认证通过后，返回认证中心首页提示用户已登录。上面登录时序交互图中的3和此接口有关。123接口名称：/auth/login入参： username[*用户名]、password[*密码]、returnURL返回： 1.产生临时认证token并重定向回系统；2.返回认证中心首页提示登录成功； 接口三： /auth/verify。认证应用系统来的token是否有效，如有效，应用系统向认证中心注册，同时认证中心会返回该应用系统登录用户的相关信息，如ID,username等。上面登录时序交互图中的4和此接口有关。12345678910接口名称：/auth/verify入参： token、localid返回： JSON格式消息 &#123; ret: 返回结果字符串，0表示成功； msg: 返回结果文字说明字符串； userid: 用户ID; username: 用户登录名; globalid: 全局会话ID,登出时使用; &#125; 接口四： /auth/logout。登出接口处理两种情况，一是直接从认证中心登出，一是来自应用重定向的登出请求。这个根据gId来区分，无gId参数说明直接从认证中心注销，有，说明从应用中来。接口首先取消当前全局登录会话，其次根据注册的已登录应用，通知它们进行登出操作。123接口名称：/auth/logout入参： gid[全局会话id,可选]返回： 1.返回OK; 2.返回认证中心首页; SSO Client接口接口一： /auth/check。接收来自认证中心携带临时令牌token的重定向，向认证中心/auth/verify接口去验证此token的有效性，如有效，即建立本地会话，根据returnURL返回浏览器用户的实际请求。如验证失败，再重定向到认证中心登录页面。123接口名称：/auth/check入参： token[*登录token]返回： 成功重定向returnURL，失败重定向到登录页面; 接口二： /auth/logout。处理两种情况，一种是浏览器向本应用接口发出的直接登出请求，应用会消除本地会话，调用认证服务器/auth/logout接口，通知认证中心删除全局会话和其它已登录应用的本地会话。 如果是从认证中心来的登出请求，此时带有localId参数，接口实现会直接删除本地会话，返回字符串”ok”。123接口名称：/auth/logout入参： localid[本地会话id,可选]返回： 1.首页; 2.'ok'字符串; CASCAS是中央认证服务Central Authentication Service的简称。最初由耶鲁大学的Shawn Bayern 开发，后由Jasig社区维护，经过十多年发展，目前已成为影响最大、广泛使用的、基于Java实现的、开源SSO解决方案。2012年，Jasig和另一个有影响的组织Sakai Foundation合并，组成Apereo。Apereo是一个由高等学术教育机构发起组织的联盟，旨在为学术教育机构提供高质量软件，当然很多软件也被大量应用于商业环境，譬如CAS。目前CAS由Apereo社区维护。CAS的官方网址是： https://www.apereo.org/projects/cas工程代码网址：https://github.com/Jasig/cas CAS也提供了一个认证中心，叫CAS Server，参与登录的应用系统都会引导到CAS Server进行登录。各应用系统与CAS Server交互通信的登录组件叫CAS Client。如CAS Client，已经提供了包括Java、.net、php、ruby、perl等多种语言的实现，非常适合异构系统的单点登录使用场景。再比如认证方式，除了常见的基于数据库认证，还提供LDAP使用场景,同时支持各种常见认证协议，如spnego、OpenId、X509等等。对于全局会话，CAS基于Cookie使用了自己的实现方式，而服务端的会话存储，除了缺省基于内存模式，还提供了基于ehcache、memcached等多种实现，同时提供了灵活接口便于自己定制扩展，这非常适合某些高可用性、高性能的应用场景。因此，在一般场景下，我们不需要重新发明轮子，直接在成熟技术框架基础上开发使用即可。这也是CAS在很多互联网和企业应用中广泛使用的原因。当然，对于某些场景，如安全性因素、更特殊更高效的应用场景，在技术实力许可的情况下，通常都自己实现SSO。]]></content>
      <categories>
        <category>系统架构</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开发者的网络安全技术]]></title>
    <url>%2F2017%2F11%2F29%2Fnetsafe-technology%2F</url>
    <content type="text"><![CDATA[本文主要对软件开发者相关的系统安全问题进行总结。 攻击类型XSSCSRF产生原理 想要攻击成功，这三步缺一不可。 第一，登录受害者网站。如果受害者网站是基于 cookie 的用户验证机制，那么当用户登录成功后，浏览器就会保存一份服务端的 SESSIONID。 第二，这时候在同一个浏览器打开攻击者网站，虽然说它无法获取 SESSIONID 是什么（因为设置了 http only 的 cookie 是无法被 JavaScript 获取的），但是从浏览器向受害者网站发出的任何请求中，都会携带它的 cookie，无论是从哪个网站发出。 第三，利用这个原理，在攻击者网站发出一个请求，命令受害者网站进行一些敏感操作。由于此时发出的请求是处于 session 中的，所以只要该用户有权限，那么任何请求都会被执行。 比如，打开优酷，并登录。再打开攻击者网站，它里面有个 &lt;img&gt; 标签是这样的： &lt;img src="http://api.youku.com/follow/123" /&gt; 这个 api 只是个例子，具体的 url 和参数都可以通过浏览器的开发者工具（Network 功能）事先确定。假如它的作用是让该登录的用户关注由 123 确定的一个节目或者用户，那么通过 CSRF 攻击，这个节目的关注量就会不断上升。 解释两点。第一，为什么举这个例子，而不是银行这种和金钱有关的操作？很简单，因为它容易猜。对于攻击者来说，没有什么是一定能成功的，比如 SQL 注入，攻击者他不知道某网站的数据库是怎么设计的，但是他一般会通过个人经验去尝试，比如很多网站把用户的主键设置为 user_id，或 sys_id 等。 银行的操作往往经过多重确认，比如图形验证码、手机验证码等，光靠 CSRF 完成一次攻击基本上是天方夜谭。但其他类型的网站往往不会刻意去防范这些问题。虽然金钱上的利益很难得到，但 CSRF 能办到的事情还是很多，比如利用别人发虚假微博、加好友等，这些都能对攻击者产生利益。 第二，如何确保用户打开优酷之后，又打开攻击者网站？做不到。否则任何人打开优酷之后，都会莫名其妙地去关注某个节目了。但是你要知道，这个攻击成本仅仅是一条 API 调用而已，它在哪里都能出现，你从任何地方下载一张图片，让你请求这个地址，看也不看就点确定，请求不就发出去了吗？ 防范手段对于如何防范 CSRF，一般有三种手段。 判断请求头Referer这个字段记录的是请求的来源。比如 http://www.example.com 上调用了百度的接口 http://api.map.baidu.com/service 那么在百度的服务端，就可以通过 Referer 判断这个请求是来自哪里。 在实际应用中，这些跟业务逻辑无关的操作往往会放在拦截器中（或者说过滤器，不同技术使用的名词可能不同）。意思是说，在进入到业务逻辑之前，就应该要根据 Referer 的值来决定这个请求能不能处理。 在 Java Servlet 中可以用 Filter（古老的技术）；用 Spring 的话可以建拦截器；在 Express 中是叫中间件，通过 request.get(‘referer’) 来取得这个值。每种技术它走的流程其实都一样。 但要注意的是，Referer 是浏览器设置的，在浏览器兼容性大不相同的时代中，如果存在某种浏览器允许用户修改这个值，那么 CSRF 漏洞依然存在。 在请求参数中加入 csrf token讨论 GET 和 POST 两种请求，对于 GET，其实也没什么需要防范的。为什么？因为 GET 在“约定”当中，被认为是查询操作，查询的意思就是，你查一次，查两次，无数次，结果都不会改变（用户得到的数据可能会变），这不会对数据库造成任何影响，所以不需要加其他额外的参数。 所以这里要提醒各位的是，尽量遵从这些约定，不要在 GET 请求中出现 /delete, /update, /edit 这种单词。把“写”操作放到 POST 中。 对于 POST，服务端在创建表单的时候可以加一个隐藏字段，也是通过某种加密算法得到的。在处理请求时，验证这个字段是否合法，如果合法就继续处理，否则就认为是恶意操作。 &lt;form method="post" action="/delete"&gt; &lt;!-- 其他字段 --&gt; &lt;input type="hidden" name="csrftoken" value="由服务端生成"/&gt; &lt;/form&gt; 这个 html 片段由服务端生成，比如 JSP，PHP 等，对于 Node.js 的话可以是 Jade 。 这的确是一个很好的防范措施，再增加一些处理的话，还能防止表单重复提交。 可是对于一些新兴网站，很多都采用了“单页”的设计，或者退一步，无论是不是单页，它的 HTML 可能是由 JavaScript 拼接而成，并且表单也都是异步提交。所以这个办法有它的应用场景，也有局限性。 新增 HTTP Header思想是，将 token 放在请求头中，服务端可以像获取 Referer 一样获取这个请求头，不同的是，这个 token 是由服务端生成的，所以攻击者他没办法猜。这篇文章的另一个重点——JWT——就是基于这个方式。抛开 JWT 不谈，它的工作原理是这样的: 解释一下这四个请求，类型都是 POST 。 1.通过 /login 接口，用户登录，服务端传回一个 access_token，前端把它保存起来，可以是内存当中，如果你希望用来模拟 session 的话。也可以保存到 localStorage 中，这样可以实现自动登录。2.调用 /delete 接口，参数是某样商品的 id。仔细看，在这个请求中，多了一个名为 Authoriaztion 的 header，它的值是之前从服务端传回来的 access_token，在前面加了一个“Bearer”（这是和服务端的约定，约定就是说，说好了加就一起加，不加就都不加……）3.调用 /logout 接口，同样把 access_token 加在 header 中传过去。成功之后，服务端和前端都会把这个 token 置为失效，或直接删除。4.再调用 /delete 接口，由于此时已经没有 access_token 了，所以服务端判断该请求没权限，返回 401 。 各位有没有发现，从头至尾，整个过程没有涉及 cookie，所以 CSRF 是不可能发生的！ 重放攻击]]></content>
      <categories>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HEXO&Jekyllrb Tutorial]]></title>
    <url>%2F2017%2F11%2F20%2Fhexo-jekyllrb-tutorial%2F</url>
    <content type="text"><![CDATA[HEXO是一个静态BLOG APPS。 Hexo安装配置安装1cnpm install hexo-cli -g 启动1hexo server 配置语言配置1language: zh-Hans 部署12hexo cleanhexo generate NEXT主题12$ cd your-hexo-site$ git clone https://github.com/iissnan/hexo-theme-next themes/next 克隆/下载 完成后，打开 站点配置文件，找到theme字段，并将其值更改为next。 这里注意区分两个配置文件：站点配置文件：是你的 hexo 博客目录下面的 _config.yml 文件。主题配置文件：是 themes/next 目录下的 _config.yml 文件。 打开侧边栏12sidebar: display: always 高级功能搜索12cnpm install hexo-generator-search --savecnpm install hexo-generator-searchdb --save 在站点配置中加入：12345search: path: search.xml field: post format: html limit: 10000 在NEXT主题配置文件中开启：12local_search: enable: true 关于我页面1hexo new page about 在NEXT主题中开启关于我页面即可 写作阅读全文在适当的位置加入如下标签即可：1&lt;!--more--&gt; 创建文章12hexo new [layout] &lt;title&gt;hexo new MyPage 插入图片修改_config.yml配置文件post_asset_folder项为true。创建文章使用命令如下：1hexo new 'article title' 使用完命令之后，在source/_post文件夹里面就会出现一个“article title.md”的文件和一个“article title”的文件夹。 Jekyllrb安装配置Jekyllrb依赖Ruby，需要安装Ruby环境 安装Minimal MistakesMinimal Mistakes（https://mademistakes.com/work/minimal-mistakes-jekyll-theme/）是一个Jekyllrb主题]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
  </entry>
</search>
